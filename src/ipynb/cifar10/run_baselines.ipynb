{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "import umap\n",
    "import time\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "import utils.papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 asym 0.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "# type of noise\n",
    "# asym: classes flip to a single other class\n",
    "# sym: classes flip uniformly to any other class\n",
    "TYPE = CONFIG[\"experiment_configs\"][DATASET][\"type\"]\n",
    " # chance of flip\n",
    "NOISE_P = CONFIG[\"experiment_configs\"][DATASET][\"noise_p\"]\n",
    "HYPER_VAL_SPLIT = CONFIG[\"experiment_configs\"][DATASET][\"hyper_val_split\"]\n",
    "\n",
    "EPOCHS = CONFIG[\"experiment_configs\"][DATASET][\"epochs\"]\n",
    "BATCH_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"batch_size\"]\n",
    "IMAGE_X = CONFIG[\"experiment_configs\"][DATASET][\"image_x_size\"]\n",
    "IMAGE_Y = CONFIG[\"experiment_configs\"][DATASET][\"image_y_size\"]\n",
    "IMAGE_SIZE = (IMAGE_Y, IMAGE_X)\n",
    "\n",
    "print(RANDOM_SEED, TYPE, NOISE_P)\n",
    "\n",
    "# folders for processed, models\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}')\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, DATASET, \".npz\", t=TYPE, np=NOISE_P)\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"base\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "if not os.path.exists(BASE_MODEL_SAVEPATH):\n",
    "    print(f\"warning: model has not been run for rs={RANDOM_SEED}_t={TYPE}_np={NOISE_P}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSED_SAVEPATH, 'rb') as f:\n",
    "    dat = np.load(f)\n",
    "\n",
    "    x_train = dat['x_train']\n",
    "    y_train = dat['y_train']\n",
    "\n",
    "    x_hyper_train = dat['x_hyper_train']\n",
    "    y_hyper_train = dat['y_hyper_train']\n",
    "    \n",
    "    x_val = dat['x_val']\n",
    "    y_val = dat['y_val']\n",
    "    \n",
    "    x_hyper_val = dat['x_hyper_val']\n",
    "    y_hyper_val = dat['y_hyper_val']\n",
    "\n",
    "    x_test = dat['x_test']\n",
    "    y_test = dat['y_test']\n",
    "\n",
    "x_train_full = np.concatenate([x_train, x_hyper_train])\n",
    "y_train_full = np.concatenate([y_train, y_hyper_train])\n",
    "\n",
    "x_val_full = np.concatenate([x_val, x_hyper_val])\n",
    "y_val_full = np.concatenate([y_val, y_hyper_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_hyper_train = tf.keras.utils.to_categorical(y_hyper_train)\n",
    "y_train_full = tf.keras.utils.to_categorical(y_train_full)\n",
    "\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "y_hyper_val = tf.keras.utils.to_categorical(y_hyper_val)\n",
    "y_val_full = tf.keras.utils.to_categorical(y_val_full)\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.utils.make_resnet(\n",
    "    2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=10,\n",
    ")\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012894736842106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train acc\n",
    "preds_train = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_train, axis=1) == np.argwhere(y_train)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds_val = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_val_full,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_val, axis=1) == np.argwhere(y_val_full)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5772"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds_test = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_test, axis=1) == np.argwhere(y_test)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: Fine-Tune\n",
    "This is a very widely used technique in deep learning. The idea is simple: do a little bit more training on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the base weights\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"ft\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=FT_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch > 80:\n",
    "        return 1e-6\n",
    "    elif epoch > 40:\n",
    "        return 1e-5\n",
    "    else:\n",
    "        return 1e-4\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# callbacks = [lr_scheduler, save_best]\n",
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9461 - accuracy: 0.5380\n",
      "Epoch 00001: val_loss improved from inf to 0.86047, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 1s 293ms/step - loss: 0.9461 - accuracy: 0.5380 - val_loss: 0.8605 - val_accuracy: 0.5940\n",
      "Epoch 2/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9350 - accuracy: 0.5500\n",
      "Epoch 00002: val_loss improved from 0.86047 to 0.85845, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.9350 - accuracy: 0.5500 - val_loss: 0.8585 - val_accuracy: 0.5940\n",
      "Epoch 3/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9170 - accuracy: 0.5440\n",
      "Epoch 00003: val_loss improved from 0.85845 to 0.85625, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 0.9170 - accuracy: 0.5440 - val_loss: 0.8562 - val_accuracy: 0.5960\n",
      "Epoch 4/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9209 - accuracy: 0.5320\n",
      "Epoch 00004: val_loss improved from 0.85625 to 0.85346, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.9209 - accuracy: 0.5320 - val_loss: 0.8535 - val_accuracy: 0.6000\n",
      "Epoch 5/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9077 - accuracy: 0.5500\n",
      "Epoch 00005: val_loss improved from 0.85346 to 0.85051, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.9077 - accuracy: 0.5500 - val_loss: 0.8505 - val_accuracy: 0.6000\n",
      "Epoch 6/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9080 - accuracy: 0.5440\n",
      "Epoch 00006: val_loss improved from 0.85051 to 0.84759, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.9080 - accuracy: 0.5440 - val_loss: 0.8476 - val_accuracy: 0.6000\n",
      "Epoch 7/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8971 - accuracy: 0.5580\n",
      "Epoch 00007: val_loss improved from 0.84759 to 0.84465, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.8971 - accuracy: 0.5580 - val_loss: 0.8446 - val_accuracy: 0.6040\n",
      "Epoch 8/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.5480\n",
      "Epoch 00008: val_loss improved from 0.84465 to 0.84141, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.9305 - accuracy: 0.5480 - val_loss: 0.8414 - val_accuracy: 0.6040\n",
      "Epoch 9/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9068 - accuracy: 0.5700\n",
      "Epoch 00009: val_loss improved from 0.84141 to 0.83845, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.9068 - accuracy: 0.5700 - val_loss: 0.8384 - val_accuracy: 0.6060\n",
      "Epoch 10/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.5660\n",
      "Epoch 00010: val_loss improved from 0.83845 to 0.83545, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.9092 - accuracy: 0.5660 - val_loss: 0.8355 - val_accuracy: 0.6120\n",
      "Epoch 11/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9097 - accuracy: 0.5820\n",
      "Epoch 00011: val_loss improved from 0.83545 to 0.83289, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.9097 - accuracy: 0.5820 - val_loss: 0.8329 - val_accuracy: 0.6200\n",
      "Epoch 12/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9123 - accuracy: 0.5640\n",
      "Epoch 00012: val_loss improved from 0.83289 to 0.82988, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.9123 - accuracy: 0.5640 - val_loss: 0.8299 - val_accuracy: 0.6200\n",
      "Epoch 13/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8566 - accuracy: 0.6000\n",
      "Epoch 00013: val_loss improved from 0.82988 to 0.82712, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.8566 - accuracy: 0.6000 - val_loss: 0.8271 - val_accuracy: 0.6260\n",
      "Epoch 14/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8939 - accuracy: 0.5700\n",
      "Epoch 00014: val_loss improved from 0.82712 to 0.82467, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.8939 - accuracy: 0.5700 - val_loss: 0.8247 - val_accuracy: 0.6300\n",
      "Epoch 15/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8485 - accuracy: 0.5980\n",
      "Epoch 00015: val_loss improved from 0.82467 to 0.82197, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.8485 - accuracy: 0.5980 - val_loss: 0.8220 - val_accuracy: 0.6340\n",
      "Epoch 16/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8605 - accuracy: 0.5840\n",
      "Epoch 00016: val_loss improved from 0.82197 to 0.81919, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.8605 - accuracy: 0.5840 - val_loss: 0.8192 - val_accuracy: 0.6380\n",
      "Epoch 17/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8627 - accuracy: 0.5960\n",
      "Epoch 00017: val_loss improved from 0.81919 to 0.81644, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.8627 - accuracy: 0.5960 - val_loss: 0.8164 - val_accuracy: 0.6380\n",
      "Epoch 18/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8782 - accuracy: 0.5920\n",
      "Epoch 00018: val_loss improved from 0.81644 to 0.81399, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.8782 - accuracy: 0.5920 - val_loss: 0.8140 - val_accuracy: 0.6420\n",
      "Epoch 19/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8476 - accuracy: 0.6100\n",
      "Epoch 00019: val_loss improved from 0.81399 to 0.81159, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.8476 - accuracy: 0.6100 - val_loss: 0.8116 - val_accuracy: 0.6400\n",
      "Epoch 20/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8223 - accuracy: 0.6020\n",
      "Epoch 00020: val_loss improved from 0.81159 to 0.80927, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.8223 - accuracy: 0.6020 - val_loss: 0.8093 - val_accuracy: 0.6400\n",
      "Epoch 21/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8501 - accuracy: 0.6180\n",
      "Epoch 00021: val_loss improved from 0.80927 to 0.80689, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.8501 - accuracy: 0.6180 - val_loss: 0.8069 - val_accuracy: 0.6380\n",
      "Epoch 22/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9114 - accuracy: 0.5880\n",
      "Epoch 00022: val_loss improved from 0.80689 to 0.80468, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.9114 - accuracy: 0.5880 - val_loss: 0.8047 - val_accuracy: 0.6400\n",
      "Epoch 23/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8148 - accuracy: 0.6160\n",
      "Epoch 00023: val_loss improved from 0.80468 to 0.80246, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.8148 - accuracy: 0.6160 - val_loss: 0.8025 - val_accuracy: 0.6380\n",
      "Epoch 24/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8101 - accuracy: 0.6220\n",
      "Epoch 00024: val_loss improved from 0.80246 to 0.80013, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.8101 - accuracy: 0.6220 - val_loss: 0.8001 - val_accuracy: 0.6420\n",
      "Epoch 25/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7948 - accuracy: 0.6180\n",
      "Epoch 00025: val_loss improved from 0.80013 to 0.79781, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.7948 - accuracy: 0.6180 - val_loss: 0.7978 - val_accuracy: 0.6440\n",
      "Epoch 26/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.6020\n",
      "Epoch 00026: val_loss improved from 0.79781 to 0.79580, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.8511 - accuracy: 0.6020 - val_loss: 0.7958 - val_accuracy: 0.6480\n",
      "Epoch 27/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8367 - accuracy: 0.6480\n",
      "Epoch 00027: val_loss improved from 0.79580 to 0.79377, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.8367 - accuracy: 0.6480 - val_loss: 0.7938 - val_accuracy: 0.6540\n",
      "Epoch 28/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.6380\n",
      "Epoch 00028: val_loss improved from 0.79377 to 0.79164, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.7916 - accuracy: 0.6380 - val_loss: 0.7916 - val_accuracy: 0.6580\n",
      "Epoch 29/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8268 - accuracy: 0.6360\n",
      "Epoch 00029: val_loss improved from 0.79164 to 0.78939, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.8268 - accuracy: 0.6360 - val_loss: 0.7894 - val_accuracy: 0.6620\n",
      "Epoch 30/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.6240\n",
      "Epoch 00030: val_loss improved from 0.78939 to 0.78725, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.8180 - accuracy: 0.6240 - val_loss: 0.7873 - val_accuracy: 0.6700\n",
      "Epoch 31/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7906 - accuracy: 0.6440\n",
      "Epoch 00031: val_loss improved from 0.78725 to 0.78523, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7906 - accuracy: 0.6440 - val_loss: 0.7852 - val_accuracy: 0.6720\n",
      "Epoch 32/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7722 - accuracy: 0.6620\n",
      "Epoch 00032: val_loss improved from 0.78523 to 0.78342, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7722 - accuracy: 0.6620 - val_loss: 0.7834 - val_accuracy: 0.6740\n",
      "Epoch 33/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7820 - accuracy: 0.6380\n",
      "Epoch 00033: val_loss improved from 0.78342 to 0.78135, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7820 - accuracy: 0.6380 - val_loss: 0.7814 - val_accuracy: 0.6760\n",
      "Epoch 34/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7880 - accuracy: 0.6320\n",
      "Epoch 00034: val_loss improved from 0.78135 to 0.77943, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.7880 - accuracy: 0.6320 - val_loss: 0.7794 - val_accuracy: 0.6800\n",
      "Epoch 35/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7717 - accuracy: 0.6440\n",
      "Epoch 00035: val_loss improved from 0.77943 to 0.77765, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7717 - accuracy: 0.6440 - val_loss: 0.7777 - val_accuracy: 0.6820\n",
      "Epoch 36/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8153 - accuracy: 0.6420\n",
      "Epoch 00036: val_loss improved from 0.77765 to 0.77584, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.8153 - accuracy: 0.6420 - val_loss: 0.7758 - val_accuracy: 0.6840\n",
      "Epoch 37/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8293 - accuracy: 0.6600\n",
      "Epoch 00037: val_loss improved from 0.77584 to 0.77428, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.8293 - accuracy: 0.6600 - val_loss: 0.7743 - val_accuracy: 0.6840\n",
      "Epoch 38/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.6500\n",
      "Epoch 00038: val_loss improved from 0.77428 to 0.77267, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.7701 - accuracy: 0.6500 - val_loss: 0.7727 - val_accuracy: 0.6840\n",
      "Epoch 39/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7912 - accuracy: 0.6600\n",
      "Epoch 00039: val_loss improved from 0.77267 to 0.77107, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7912 - accuracy: 0.6600 - val_loss: 0.7711 - val_accuracy: 0.6880\n",
      "Epoch 40/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7802 - accuracy: 0.6780\n",
      "Epoch 00040: val_loss improved from 0.77107 to 0.76949, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7802 - accuracy: 0.6780 - val_loss: 0.7695 - val_accuracy: 0.6860\n",
      "Epoch 41/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.6620\n",
      "Epoch 00041: val_loss improved from 0.76949 to 0.76785, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7829 - accuracy: 0.6620 - val_loss: 0.7678 - val_accuracy: 0.6880\n",
      "Epoch 42/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.6820\n",
      "Epoch 00042: val_loss improved from 0.76785 to 0.76610, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.7552 - accuracy: 0.6820 - val_loss: 0.7661 - val_accuracy: 0.6900\n",
      "Epoch 43/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.6800\n",
      "Epoch 00043: val_loss improved from 0.76610 to 0.76438, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7608 - accuracy: 0.6800 - val_loss: 0.7644 - val_accuracy: 0.6900\n",
      "Epoch 44/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7563 - accuracy: 0.6700\n",
      "Epoch 00044: val_loss improved from 0.76438 to 0.76283, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 115ms/step - loss: 0.7563 - accuracy: 0.6700 - val_loss: 0.7628 - val_accuracy: 0.6960\n",
      "Epoch 45/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.6700\n",
      "Epoch 00045: val_loss improved from 0.76283 to 0.76108, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.7328 - accuracy: 0.6700 - val_loss: 0.7611 - val_accuracy: 0.6980\n",
      "Epoch 46/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.6740\n",
      "Epoch 00046: val_loss improved from 0.76108 to 0.75963, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.7222 - accuracy: 0.6740 - val_loss: 0.7596 - val_accuracy: 0.7000\n",
      "Epoch 47/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.8058 - accuracy: 0.6460\n",
      "Epoch 00047: val_loss improved from 0.75963 to 0.75797, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.8058 - accuracy: 0.6460 - val_loss: 0.7580 - val_accuracy: 0.7000\n",
      "Epoch 48/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7372 - accuracy: 0.6820\n",
      "Epoch 00048: val_loss improved from 0.75797 to 0.75647, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7372 - accuracy: 0.6820 - val_loss: 0.7565 - val_accuracy: 0.7000\n",
      "Epoch 49/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.6880\n",
      "Epoch 00049: val_loss improved from 0.75647 to 0.75491, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7654 - accuracy: 0.6880 - val_loss: 0.7549 - val_accuracy: 0.7000\n",
      "Epoch 50/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7316 - accuracy: 0.6980\n",
      "Epoch 00050: val_loss improved from 0.75491 to 0.75346, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.7316 - accuracy: 0.6980 - val_loss: 0.7535 - val_accuracy: 0.7020\n",
      "Epoch 51/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.6860\n",
      "Epoch 00051: val_loss improved from 0.75346 to 0.75207, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.7007 - accuracy: 0.6860 - val_loss: 0.7521 - val_accuracy: 0.7040\n",
      "Epoch 52/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7462 - accuracy: 0.6960\n",
      "Epoch 00052: val_loss improved from 0.75207 to 0.75047, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7462 - accuracy: 0.6960 - val_loss: 0.7505 - val_accuracy: 0.7060\n",
      "Epoch 53/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7497 - accuracy: 0.6940\n",
      "Epoch 00053: val_loss improved from 0.75047 to 0.74897, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7497 - accuracy: 0.6940 - val_loss: 0.7490 - val_accuracy: 0.7060\n",
      "Epoch 54/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7285 - accuracy: 0.6960\n",
      "Epoch 00054: val_loss improved from 0.74897 to 0.74771, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7285 - accuracy: 0.6960 - val_loss: 0.7477 - val_accuracy: 0.7080\n",
      "Epoch 55/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7616 - accuracy: 0.6820\n",
      "Epoch 00055: val_loss improved from 0.74771 to 0.74650, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.7616 - accuracy: 0.6820 - val_loss: 0.7465 - val_accuracy: 0.7080\n",
      "Epoch 56/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7020 - accuracy: 0.7160\n",
      "Epoch 00056: val_loss improved from 0.74650 to 0.74534, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.7020 - accuracy: 0.7160 - val_loss: 0.7453 - val_accuracy: 0.7100\n",
      "Epoch 57/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.7200\n",
      "Epoch 00057: val_loss improved from 0.74534 to 0.74414, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6886 - accuracy: 0.7200 - val_loss: 0.7441 - val_accuracy: 0.7100\n",
      "Epoch 58/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7442 - accuracy: 0.6900\n",
      "Epoch 00058: val_loss improved from 0.74414 to 0.74294, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7442 - accuracy: 0.6900 - val_loss: 0.7429 - val_accuracy: 0.7100\n",
      "Epoch 59/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7201 - accuracy: 0.7080\n",
      "Epoch 00059: val_loss improved from 0.74294 to 0.74167, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.7201 - accuracy: 0.7080 - val_loss: 0.7417 - val_accuracy: 0.7120\n",
      "Epoch 60/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.7220\n",
      "Epoch 00060: val_loss improved from 0.74167 to 0.74031, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6986 - accuracy: 0.7220 - val_loss: 0.7403 - val_accuracy: 0.7140\n",
      "Epoch 61/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.7300\n",
      "Epoch 00061: val_loss improved from 0.74031 to 0.73901, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7081 - accuracy: 0.7300 - val_loss: 0.7390 - val_accuracy: 0.7160\n",
      "Epoch 62/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7102 - accuracy: 0.7260\n",
      "Epoch 00062: val_loss improved from 0.73901 to 0.73778, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7102 - accuracy: 0.7260 - val_loss: 0.7378 - val_accuracy: 0.7220\n",
      "Epoch 63/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.7140\n",
      "Epoch 00063: val_loss improved from 0.73778 to 0.73647, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.6967 - accuracy: 0.7140 - val_loss: 0.7365 - val_accuracy: 0.7260\n",
      "Epoch 64/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7177 - accuracy: 0.7160\n",
      "Epoch 00064: val_loss improved from 0.73647 to 0.73521, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7177 - accuracy: 0.7160 - val_loss: 0.7352 - val_accuracy: 0.7280\n",
      "Epoch 65/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.7360\n",
      "Epoch 00065: val_loss improved from 0.73521 to 0.73398, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6798 - accuracy: 0.7360 - val_loss: 0.7340 - val_accuracy: 0.7300\n",
      "Epoch 66/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7035 - accuracy: 0.7400\n",
      "Epoch 00066: val_loss improved from 0.73398 to 0.73298, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.7035 - accuracy: 0.7400 - val_loss: 0.7330 - val_accuracy: 0.7300\n",
      "Epoch 67/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7365 - accuracy: 0.7000\n",
      "Epoch 00067: val_loss improved from 0.73298 to 0.73191, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.7365 - accuracy: 0.7000 - val_loss: 0.7319 - val_accuracy: 0.7300\n",
      "Epoch 68/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7174 - accuracy: 0.7100\n",
      "Epoch 00068: val_loss improved from 0.73191 to 0.73086, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.7174 - accuracy: 0.7100 - val_loss: 0.7309 - val_accuracy: 0.7340\n",
      "Epoch 69/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7380\n",
      "Epoch 00069: val_loss improved from 0.73086 to 0.72972, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.6780 - accuracy: 0.7380 - val_loss: 0.7297 - val_accuracy: 0.7340\n",
      "Epoch 70/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.7240\n",
      "Epoch 00070: val_loss improved from 0.72972 to 0.72882, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6915 - accuracy: 0.7240 - val_loss: 0.7288 - val_accuracy: 0.7340\n",
      "Epoch 71/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7240\n",
      "Epoch 00071: val_loss improved from 0.72882 to 0.72767, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.7182 - accuracy: 0.7240 - val_loss: 0.7277 - val_accuracy: 0.7340\n",
      "Epoch 72/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.7340\n",
      "Epoch 00072: val_loss improved from 0.72767 to 0.72644, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6701 - accuracy: 0.7340 - val_loss: 0.7264 - val_accuracy: 0.7360\n",
      "Epoch 73/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7106 - accuracy: 0.7320\n",
      "Epoch 00073: val_loss improved from 0.72644 to 0.72540, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.7106 - accuracy: 0.7320 - val_loss: 0.7254 - val_accuracy: 0.7380\n",
      "Epoch 74/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6376 - accuracy: 0.7360\n",
      "Epoch 00074: val_loss improved from 0.72540 to 0.72454, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 0.6376 - accuracy: 0.7360 - val_loss: 0.7245 - val_accuracy: 0.7380\n",
      "Epoch 75/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.7300\n",
      "Epoch 00075: val_loss improved from 0.72454 to 0.72373, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.6464 - accuracy: 0.7300 - val_loss: 0.7237 - val_accuracy: 0.7420\n",
      "Epoch 76/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6753 - accuracy: 0.7220\n",
      "Epoch 00076: val_loss improved from 0.72373 to 0.72266, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.6753 - accuracy: 0.7220 - val_loss: 0.7227 - val_accuracy: 0.7420\n",
      "Epoch 77/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.7440\n",
      "Epoch 00077: val_loss improved from 0.72266 to 0.72190, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.6596 - accuracy: 0.7440 - val_loss: 0.7219 - val_accuracy: 0.7420\n",
      "Epoch 78/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7068 - accuracy: 0.7240\n",
      "Epoch 00078: val_loss improved from 0.72190 to 0.72113, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.7068 - accuracy: 0.7240 - val_loss: 0.7211 - val_accuracy: 0.7420\n",
      "Epoch 79/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6661 - accuracy: 0.7300\n",
      "Epoch 00079: val_loss improved from 0.72113 to 0.72042, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6661 - accuracy: 0.7300 - val_loss: 0.7204 - val_accuracy: 0.7420\n",
      "Epoch 80/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.7480\n",
      "Epoch 00080: val_loss improved from 0.72042 to 0.71954, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6845 - accuracy: 0.7480 - val_loss: 0.7195 - val_accuracy: 0.7420\n",
      "Epoch 81/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7320\n",
      "Epoch 00081: val_loss improved from 0.71954 to 0.71842, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6794 - accuracy: 0.7320 - val_loss: 0.7184 - val_accuracy: 0.7440\n",
      "Epoch 82/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.7360\n",
      "Epoch 00082: val_loss improved from 0.71842 to 0.71740, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6665 - accuracy: 0.7360 - val_loss: 0.7174 - val_accuracy: 0.7440\n",
      "Epoch 83/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.7560\n",
      "Epoch 00083: val_loss improved from 0.71740 to 0.71657, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.6381 - accuracy: 0.7560 - val_loss: 0.7166 - val_accuracy: 0.7460\n",
      "Epoch 84/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6607 - accuracy: 0.7540\n",
      "Epoch 00084: val_loss improved from 0.71657 to 0.71561, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.6607 - accuracy: 0.7540 - val_loss: 0.7156 - val_accuracy: 0.7460\n",
      "Epoch 85/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.7400\n",
      "Epoch 00085: val_loss improved from 0.71561 to 0.71480, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.6781 - accuracy: 0.7400 - val_loss: 0.7148 - val_accuracy: 0.7480\n",
      "Epoch 86/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6564 - accuracy: 0.7440\n",
      "Epoch 00086: val_loss improved from 0.71480 to 0.71386, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6564 - accuracy: 0.7440 - val_loss: 0.7139 - val_accuracy: 0.7480\n",
      "Epoch 87/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6765 - accuracy: 0.7520\n",
      "Epoch 00087: val_loss improved from 0.71386 to 0.71315, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.6765 - accuracy: 0.7520 - val_loss: 0.7132 - val_accuracy: 0.7520\n",
      "Epoch 88/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.7280\n",
      "Epoch 00088: val_loss improved from 0.71315 to 0.71247, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.6925 - accuracy: 0.7280 - val_loss: 0.7125 - val_accuracy: 0.7520\n",
      "Epoch 89/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6495 - accuracy: 0.7560\n",
      "Epoch 00089: val_loss improved from 0.71247 to 0.71185, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6495 - accuracy: 0.7560 - val_loss: 0.7119 - val_accuracy: 0.7540\n",
      "Epoch 90/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.7320\n",
      "Epoch 00090: val_loss improved from 0.71185 to 0.71119, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 0.6829 - accuracy: 0.7320 - val_loss: 0.7112 - val_accuracy: 0.7560\n",
      "Epoch 91/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6268 - accuracy: 0.7500\n",
      "Epoch 00091: val_loss improved from 0.71119 to 0.71053, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.6268 - accuracy: 0.7500 - val_loss: 0.7105 - val_accuracy: 0.7560\n",
      "Epoch 92/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6296 - accuracy: 0.7560\n",
      "Epoch 00092: val_loss improved from 0.71053 to 0.70977, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.6296 - accuracy: 0.7560 - val_loss: 0.7098 - val_accuracy: 0.7560\n",
      "Epoch 93/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.7580\n",
      "Epoch 00093: val_loss improved from 0.70977 to 0.70908, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.7580 - val_loss: 0.7091 - val_accuracy: 0.7560\n",
      "Epoch 94/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.7480\n",
      "Epoch 00094: val_loss improved from 0.70908 to 0.70832, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6681 - accuracy: 0.7480 - val_loss: 0.7083 - val_accuracy: 0.7560\n",
      "Epoch 95/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6276 - accuracy: 0.7680\n",
      "Epoch 00095: val_loss improved from 0.70832 to 0.70746, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6276 - accuracy: 0.7680 - val_loss: 0.7075 - val_accuracy: 0.7560\n",
      "Epoch 96/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6425 - accuracy: 0.7480\n",
      "Epoch 00096: val_loss improved from 0.70746 to 0.70674, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.6425 - accuracy: 0.7480 - val_loss: 0.7067 - val_accuracy: 0.7560\n",
      "Epoch 97/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.7720\n",
      "Epoch 00097: val_loss improved from 0.70674 to 0.70604, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6261 - accuracy: 0.7720 - val_loss: 0.7060 - val_accuracy: 0.7600\n",
      "Epoch 98/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7580\n",
      "Epoch 00098: val_loss improved from 0.70604 to 0.70533, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.6173 - accuracy: 0.7580 - val_loss: 0.7053 - val_accuracy: 0.7600\n",
      "Epoch 99/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.7540\n",
      "Epoch 00099: val_loss improved from 0.70533 to 0.70471, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.6549 - accuracy: 0.7540 - val_loss: 0.7047 - val_accuracy: 0.7620\n",
      "Epoch 100/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.7540\n",
      "Epoch 00100: val_loss improved from 0.70471 to 0.70389, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 0.6205 - accuracy: 0.7540 - val_loss: 0.7039 - val_accuracy: 0.7620\n",
      "Epoch 101/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.7440\n",
      "Epoch 00101: val_loss improved from 0.70389 to 0.70334, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6162 - accuracy: 0.7440 - val_loss: 0.7033 - val_accuracy: 0.7620\n",
      "Epoch 102/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.7640\n",
      "Epoch 00102: val_loss improved from 0.70334 to 0.70268, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6517 - accuracy: 0.7640 - val_loss: 0.7027 - val_accuracy: 0.7620\n",
      "Epoch 103/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.7660\n",
      "Epoch 00103: val_loss improved from 0.70268 to 0.70200, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6438 - accuracy: 0.7660 - val_loss: 0.7020 - val_accuracy: 0.7620\n",
      "Epoch 104/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6126 - accuracy: 0.7520\n",
      "Epoch 00104: val_loss improved from 0.70200 to 0.70143, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 0.6126 - accuracy: 0.7520 - val_loss: 0.7014 - val_accuracy: 0.7620\n",
      "Epoch 105/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.7720\n",
      "Epoch 00105: val_loss improved from 0.70143 to 0.70093, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.6305 - accuracy: 0.7720 - val_loss: 0.7009 - val_accuracy: 0.7620\n",
      "Epoch 106/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.7500\n",
      "Epoch 00106: val_loss improved from 0.70093 to 0.70026, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.6343 - accuracy: 0.7500 - val_loss: 0.7003 - val_accuracy: 0.7620\n",
      "Epoch 107/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7680\n",
      "Epoch 00107: val_loss improved from 0.70026 to 0.69963, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.6047 - accuracy: 0.7680 - val_loss: 0.6996 - val_accuracy: 0.7660\n",
      "Epoch 108/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.7780\n",
      "Epoch 00108: val_loss improved from 0.69963 to 0.69899, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6050 - accuracy: 0.7780 - val_loss: 0.6990 - val_accuracy: 0.7700\n",
      "Epoch 109/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7740\n",
      "Epoch 00109: val_loss improved from 0.69899 to 0.69859, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 0.5932 - accuracy: 0.7740 - val_loss: 0.6986 - val_accuracy: 0.7720\n",
      "Epoch 110/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.7840\n",
      "Epoch 00110: val_loss improved from 0.69859 to 0.69821, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.6002 - accuracy: 0.7840 - val_loss: 0.6982 - val_accuracy: 0.7720\n",
      "Epoch 111/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6364 - accuracy: 0.7520\n",
      "Epoch 00111: val_loss improved from 0.69821 to 0.69765, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.6364 - accuracy: 0.7520 - val_loss: 0.6977 - val_accuracy: 0.7720\n",
      "Epoch 112/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.7720\n",
      "Epoch 00112: val_loss improved from 0.69765 to 0.69745, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6070 - accuracy: 0.7720 - val_loss: 0.6975 - val_accuracy: 0.7720\n",
      "Epoch 113/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.7480\n",
      "Epoch 00113: val_loss improved from 0.69745 to 0.69701, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.6206 - accuracy: 0.7480 - val_loss: 0.6970 - val_accuracy: 0.7720\n",
      "Epoch 114/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5955 - accuracy: 0.7840\n",
      "Epoch 00114: val_loss improved from 0.69701 to 0.69652, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.5955 - accuracy: 0.7840 - val_loss: 0.6965 - val_accuracy: 0.7740\n",
      "Epoch 115/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6096 - accuracy: 0.7800\n",
      "Epoch 00115: val_loss improved from 0.69652 to 0.69613, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 0.6096 - accuracy: 0.7800 - val_loss: 0.6961 - val_accuracy: 0.7760\n",
      "Epoch 116/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6152 - accuracy: 0.7620\n",
      "Epoch 00116: val_loss improved from 0.69613 to 0.69579, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6152 - accuracy: 0.7620 - val_loss: 0.6958 - val_accuracy: 0.7760\n",
      "Epoch 117/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.7720\n",
      "Epoch 00117: val_loss improved from 0.69579 to 0.69526, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.5842 - accuracy: 0.7720 - val_loss: 0.6953 - val_accuracy: 0.7760\n",
      "Epoch 118/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5892 - accuracy: 0.7560\n",
      "Epoch 00118: val_loss improved from 0.69526 to 0.69490, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.5892 - accuracy: 0.7560 - val_loss: 0.6949 - val_accuracy: 0.7760\n",
      "Epoch 119/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.7720\n",
      "Epoch 00119: val_loss improved from 0.69490 to 0.69431, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 0.5923 - accuracy: 0.7720 - val_loss: 0.6943 - val_accuracy: 0.7780\n",
      "Epoch 120/120\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.7700\n",
      "Epoch 00120: val_loss improved from 0.69431 to 0.69388, saving model to ../../../models/cifar10/rs=55/cifar10_mt=ft_np=0.6_t=asym.h5\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 0.6070 - accuracy: 0.7700 - val_loss: 0.6939 - val_accuracy: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f83509d9a10>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=data_generator.flow(\n",
    "        x_val,\n",
    "        y_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED,\n",
    "    ),\n",
    "    validation_data=(x_hyper_val, y_hyper_val),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the best saved\n",
    "model.load_weights(FT_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds_val = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_hyper_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_val, axis=1) == np.argwhere(y_hyper_val)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds_test = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_test, axis=1) == np.argwhere(y_test)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: Forward Correct\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1609.03683.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload trained weights\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T[i,j] means the probabilty that class i is flipped to class j.\n",
    "T_hat = utils.papers.forward_correct_est_T(\n",
    "    model,\n",
    "    x_train_full,\n",
    "    nc=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.6 , 0.  , 0.4 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.59, 0.  , 0.41, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.01, 0.41, 0.01, 0.  , 0.58, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.35, 0.  , 0.65, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  ],\n",
       "       [0.  , 0.53, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.47]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(T_hat, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = utils.papers.make_forward_correct_loss(T_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"fc\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=FC_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    ")\n",
    "\n",
    "callbacks = [save_best, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5450 - accuracy: 0.7575\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=fc_np=0.6_t=asym.h5\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5450 - accuracy: 0.7575 - val_loss: 0.8389 - val_accuracy: 0.7540\n",
      "Epoch 2/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.7331\n",
      "Epoch 00002: val_accuracy improved from 0.75400 to 0.76200, saving model to ../../../models/cifar10/rs=15/cifar10_mt=fc_np=0.6_t=asym.h5\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5373 - accuracy: 0.7331 - val_loss: 0.8085 - val_accuracy: 0.7620\n",
      "Epoch 3/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.7329\n",
      "Epoch 00003: val_accuracy improved from 0.76200 to 0.76400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=fc_np=0.6_t=asym.h5\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5314 - accuracy: 0.7329 - val_loss: 0.8052 - val_accuracy: 0.7640\n",
      "Epoch 4/120\n",
      "386/387 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.7313\n",
      "Epoch 00004: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 49ms/step - loss: 0.5310 - accuracy: 0.7313 - val_loss: 0.7897 - val_accuracy: 0.7580\n",
      "Epoch 5/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.7306\n",
      "Epoch 00005: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 49ms/step - loss: 0.5302 - accuracy: 0.7306 - val_loss: 0.7995 - val_accuracy: 0.7560\n",
      "Epoch 6/120\n",
      "386/387 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.7325\n",
      "Epoch 00006: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5262 - accuracy: 0.7324 - val_loss: 0.7961 - val_accuracy: 0.7540\n",
      "Epoch 7/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7308\n",
      "Epoch 00007: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 23s 61ms/step - loss: 0.5269 - accuracy: 0.7308 - val_loss: 0.7927 - val_accuracy: 0.7520\n",
      "Epoch 8/120\n",
      "386/387 [============================>.] - ETA: 0s - loss: 0.5282 - accuracy: 0.7299\n",
      "Epoch 00008: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 23s 59ms/step - loss: 0.5280 - accuracy: 0.7299 - val_loss: 0.7953 - val_accuracy: 0.7580\n",
      "Epoch 9/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.7292\n",
      "Epoch 00009: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5262 - accuracy: 0.7292 - val_loss: 0.7928 - val_accuracy: 0.7560\n",
      "Epoch 10/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.7268\n",
      "Epoch 00010: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5269 - accuracy: 0.7268 - val_loss: 0.7943 - val_accuracy: 0.7520\n",
      "Epoch 11/120\n",
      "386/387 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7312 ETA: 2s - los\n",
      "Epoch 00011: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5250 - accuracy: 0.7311 - val_loss: 0.7926 - val_accuracy: 0.7580\n",
      "Epoch 12/120\n",
      "387/387 [==============================] - ETA: 0s - loss: 0.5265 - accuracy: 0.7300\n",
      "Epoch 00012: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 50ms/step - loss: 0.5265 - accuracy: 0.7300 - val_loss: 0.7926 - val_accuracy: 0.7580\n",
      "Epoch 13/120\n",
      "386/387 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.7286\n",
      "Epoch 00013: val_accuracy did not improve from 0.76400\n",
      "387/387 [==============================] - 19s 49ms/step - loss: 0.5249 - accuracy: 0.7286 - val_loss: 0.7963 - val_accuracy: 0.7520\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "# there are other ways to do this, namely\n",
    "# fit to x_train, y_train and see what minimizes the loss on x_hyper_train\n",
    "# because the paper says to minimize the modified loss\n",
    "history = model.fit(\n",
    "    x=data_generator.flow(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED,\n",
    "    ),\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    validation_data=(x_hyper_train, y_hyper_train),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(FC_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds_val = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_val_full,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_val, axis=1) == np.argwhere(y_val_full)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7711"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds_test = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_test, axis=1) == np.argwhere(y_test)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 3: Learn to Weigh Examples\n",
    "Paper: https://arxiv.org/pdf/1803.09050.pdf\n",
    "\n",
    "This is a type of meta-learning, which doesn't quite work with the keras API. We will need to manually implement the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.9, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator to generate data\n",
    "itr = data_generator.flow(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction.NONE means the cross entropy is computed per entry in the batch\n",
    "# but is not aggregated. Traditional cross entropy will average the results.\n",
    "ce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322e4c212d244ed7ac9cb3566e144bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.190139353275299075\n",
      "Val Test Acc: 0.544\n",
      "Val Test Loss: 0.19013935327529907\n",
      "\n",
      "Saving new best weights to ../../../models/cifar10/rs=15/cifar10_mt=lrw_np=0.6_t=asym.h5\n",
      "Epoch 1:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a679e67037544dbb85d1efa36b0d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16814349591732025\n",
      "Val Test Acc: 0.576\n",
      "Val Test Loss: 0.16814349591732025\n",
      "\n",
      "Saving new best weights to ../../../models/cifar10/rs=15/cifar10_mt=lrw_np=0.6_t=asym.h5\n",
      "Epoch 2:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31e57817205448f85a19e4832e74e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.145715013146400454\n",
      "Val Test Acc: 0.556\n",
      "Val Test Loss: 0.14571501314640045\n",
      "\n",
      "Saving new best weights to ../../../models/cifar10/rs=15/cifar10_mt=lrw_np=0.6_t=asym.h5\n",
      "Epoch 3:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e86a36eec374e98af48334bbd1a36d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17932464182376862\n",
      "Val Test Acc: 0.568\n",
      "Val Test Loss: 0.17932464182376862\n",
      "\n",
      "Epoch 4:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f4e6f3614f41b79b0da03cfb93a727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15067510306835175\n",
      "Val Test Acc: 0.584\n",
      "Val Test Loss: 0.15067510306835175\n",
      "\n",
      "Epoch 5:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b1b33cd4aa4d14b3cb8b2ed65e1a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13120216131210327\n",
      "Val Test Acc: 0.58\n",
      "Val Test Loss: 0.13120216131210327\n",
      "\n",
      "Saving new best weights to ../../../models/cifar10/rs=15/cifar10_mt=lrw_np=0.6_t=asym.h5\n",
      "Epoch 6:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96485cea477b42a28c2721856bee09d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16714365780353546\n",
      "Val Test Acc: 0.568\n",
      "Val Test Loss: 0.16714365780353546\n",
      "\n",
      "Epoch 7:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73233b9318b74441a2a2c7d569dcb13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20476475358009338\n",
      "Val Test Acc: 0.576\n",
      "Val Test Loss: 0.20476475358009338\n",
      "\n",
      "Epoch 8:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938d4af792414100929cf24d804fba2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20877778530120858\n",
      "Val Test Acc: 0.584\n",
      "Val Test Loss: 0.2087777853012085\n",
      "\n",
      "Epoch 9:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34fe58f784f4ca696452640855f0f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.164021193981170654\n",
      "Val Test Acc: 0.568\n",
      "Val Test Loss: 0.16402119398117065\n",
      "\n",
      "Epoch 10:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e6a5839ebb452ba43fca093fa00ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17996153235435486\n",
      "Val Test Acc: 0.568\n",
      "Val Test Loss: 0.17996153235435486\n",
      "\n",
      "Epoch 11:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e72c7c3e5de4a338b0a27411aadaf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18691381812095642\n",
      "Val Test Acc: 0.584\n",
      "Val Test Loss: 0.18691381812095642\n",
      "\n",
      "Epoch 12:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c122054e22430393db1c4c2b350c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19280989468097687\n",
      "Val Test Acc: 0.58\n",
      "Val Test Loss: 0.19280989468097687\n",
      "\n",
      "Epoch 13:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d34e0a7cc264f20bf5b5602062e9d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18195927143096924\n",
      "Val Test Acc: 0.58\n",
      "Val Test Loss: 0.18195927143096924\n",
      "\n",
      "Epoch 14:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f907a58544e04abca6a808356abfeff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16227981448173523\n",
      "Val Test Acc: 0.592\n",
      "Val Test Loss: 0.16227981448173523\n",
      "\n",
      "Epoch 15:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44abacc8a83b483b9d48a53e94075d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.22039318084716797\n",
      "Val Test Acc: 0.564\n",
      "Val Test Loss: 0.22039318084716797\n",
      "\n",
      "no improvement for 10 epochs, ending training\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "LRW_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"lrw\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "total_batches = len(itr)\n",
    "\n",
    "# custom train loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # implements a train loop\n",
    "    print(f\"\\nEpoch {epoch}:\\n----------\")\n",
    "    \n",
    "    batch_c = 0\n",
    "    loss_sum = 0\n",
    "    for batch, labels in tqdm(itr):\n",
    "        # most of the details are abstracted away in this function\n",
    "        loss = utils.papers.train_step(model, batch, labels, x_val, y_val, ce, optimizer)\n",
    "        loss_sum += loss\n",
    "        batch_c += 1\n",
    "        # print ongoing avg loss\n",
    "        print(f\"Loss: {loss_sum / batch_c}\", end='\\r')\n",
    "        \n",
    "        # we need to tally this ourselves because the iterator simply restarts another epoch\n",
    "        if batch_c >= total_batches:\n",
    "            break\n",
    "    \n",
    "    # compute validation accuracy\n",
    "    preds = utils.utils.compute_preds(\n",
    "        model,\n",
    "        x_hyper_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    val_acc = (np.argmax(preds, axis=1) == np.argwhere(y_hyper_val)[:,1]).mean()\n",
    "    loss_avg = loss_sum / total_batches\n",
    "    \n",
    "    print(f\"Hyper Val Acc: {val_acc}\")\n",
    "    print(f\"Hyper Val Loss: {loss_avg}\")\n",
    "    \n",
    "    # implements save best logic\n",
    "    if loss_avg < best_loss:\n",
    "        best_loss = loss_avg\n",
    "        print(f\"Saving new best weights to {LRW_MODEL_SAVEPATH}\")\n",
    "        model.save_weights(\n",
    "            filepath=LRW_MODEL_SAVEPATH,\n",
    "            save_format=\"h5\",\n",
    "        )\n",
    "        last_best_epoch = epoch\n",
    "    \n",
    "    # because this takes a long time (roughly 3x the normal train time)\n",
    "    # we use early stopping \n",
    "    early_stop = 10\n",
    "    if last_best_epoch + early_stop <= epoch:\n",
    "        print(f\"no improvement for {early_stop} epochs, ending training\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(LRW_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds_val = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_hyper_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_val, axis=1) == np.argwhere(y_hyper_val)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds_test = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_test, axis=1) == np.argwhere(y_test)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 4: Just Train on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fresh model\n",
    "model = utils.utils.make_resnet(\n",
    "    depth=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 16)   448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 16)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 16)   2320        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 16)   64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 16)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 16)   2320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 16)   0           activation_26[0][0]              \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 16)   64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 16)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 16)   2320        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 16)   0           add_12[0][0]                     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 32)   4640        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 32)   544         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 32)   0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 32)   9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 32)   9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 32)   0           add_14[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 64)     18496       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 64)     2112        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 64)     0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 64)     0           add_16[0][0]                     \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 176,554\n",
      "Trainable params: 175,626\n",
      "Non-trainable params: 928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch > 80:\n",
    "        return 0.001\n",
    "    elif epoch > 40:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.1\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "JV_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"jv\", t=TYPE, np=NOISE_P)\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=JV_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [lr_scheduler, save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.5918 - accuracy: 0.1080\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10000, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.5918 - accuracy: 0.1080 - val_loss: 56.5558 - val_accuracy: 0.1000\n",
      "Epoch 2/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4779 - accuracy: 0.1328\n",
      "Epoch 00002: val_accuracy improved from 0.10000 to 0.10400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 2.3948 - accuracy: 0.1760 - val_loss: 33.3243 - val_accuracy: 0.1040\n",
      "Epoch 3/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.2398 - accuracy: 0.2320\n",
      "Epoch 00003: val_accuracy improved from 0.10400 to 0.11200, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.2398 - accuracy: 0.2320 - val_loss: 37.5751 - val_accuracy: 0.1120\n",
      "Epoch 4/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.1615 - accuracy: 0.3280\n",
      "Epoch 00004: val_accuracy improved from 0.11200 to 0.13200, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 2.1615 - accuracy: 0.3280 - val_loss: 44.8631 - val_accuracy: 0.1320\n",
      "Epoch 5/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1073 - accuracy: 0.3438\n",
      "Epoch 00005: val_accuracy improved from 0.13200 to 0.14000, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 2.1056 - accuracy: 0.3320 - val_loss: 56.3958 - val_accuracy: 0.1400\n",
      "Epoch 6/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 2.0527 - accuracy: 0.3080\n",
      "Epoch 00006: val_accuracy improved from 0.14000 to 0.15600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 2.0527 - accuracy: 0.3080 - val_loss: 59.6107 - val_accuracy: 0.1560\n",
      "Epoch 7/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0678 - accuracy: 0.2869\n",
      "Epoch 00007: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.9947 - accuracy: 0.3040 - val_loss: 59.8792 - val_accuracy: 0.1560\n",
      "Epoch 8/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8803 - accuracy: 0.3279\n",
      "Epoch 00008: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.9174 - accuracy: 0.3320 - val_loss: 60.1395 - val_accuracy: 0.1280\n",
      "Epoch 9/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.8810 - accuracy: 0.3680\n",
      "Epoch 00009: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.8810 - accuracy: 0.3680 - val_loss: 63.0387 - val_accuracy: 0.1280\n",
      "Epoch 10/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9123 - accuracy: 0.3359\n",
      "Epoch 00010: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.8359 - accuracy: 0.3920 - val_loss: 63.7822 - val_accuracy: 0.1560\n",
      "Epoch 11/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8031 - accuracy: 0.4219\n",
      "Epoch 00011: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.8193 - accuracy: 0.4040 - val_loss: 63.9978 - val_accuracy: 0.1280\n",
      "Epoch 12/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.7644 - accuracy: 0.4440\n",
      "Epoch 00012: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.7644 - accuracy: 0.4440 - val_loss: 67.7227 - val_accuracy: 0.1400\n",
      "Epoch 13/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6910 - accuracy: 0.4844\n",
      "Epoch 00013: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.7295 - accuracy: 0.4360 - val_loss: 60.7342 - val_accuracy: 0.1160\n",
      "Epoch 14/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5688 - accuracy: 0.4754\n",
      "Epoch 00014: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.6864 - accuracy: 0.4440 - val_loss: 65.8352 - val_accuracy: 0.1000\n",
      "Epoch 15/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5984 - accuracy: 0.5078\n",
      "Epoch 00015: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.6334 - accuracy: 0.4960 - val_loss: 49.0019 - val_accuracy: 0.1160\n",
      "Epoch 16/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.6741 - accuracy: 0.4720\n",
      "Epoch 00016: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.6741 - accuracy: 0.4720 - val_loss: 48.2449 - val_accuracy: 0.1440\n",
      "Epoch 17/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6279 - accuracy: 0.4766\n",
      "Epoch 00017: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.6165 - accuracy: 0.4840 - val_loss: 40.4834 - val_accuracy: 0.1440\n",
      "Epoch 18/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6864 - accuracy: 0.4609\n",
      "Epoch 00018: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.6423 - accuracy: 0.4840 - val_loss: 39.7681 - val_accuracy: 0.1440\n",
      "Epoch 19/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5631 - accuracy: 0.5000\n",
      "Epoch 00019: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.5631 - accuracy: 0.5000 - val_loss: 48.6267 - val_accuracy: 0.1520\n",
      "Epoch 20/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5578 - accuracy: 0.4720\n",
      "Epoch 00020: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.5578 - accuracy: 0.4720 - val_loss: 32.3766 - val_accuracy: 0.1480\n",
      "Epoch 21/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5532 - accuracy: 0.4766\n",
      "Epoch 00021: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.5076 - accuracy: 0.4920 - val_loss: 30.2244 - val_accuracy: 0.1040\n",
      "Epoch 22/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4529 - accuracy: 0.5082\n",
      "Epoch 00022: val_accuracy did not improve from 0.15600\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1.4447 - accuracy: 0.5240 - val_loss: 32.8157 - val_accuracy: 0.1080\n",
      "Epoch 23/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4319 - accuracy: 0.5078\n",
      "Epoch 00023: val_accuracy improved from 0.15600 to 0.20000, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.4515 - accuracy: 0.5120 - val_loss: 35.5489 - val_accuracy: 0.2000\n",
      "Epoch 24/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4520 - accuracy: 0.5480\n",
      "Epoch 00024: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.4520 - accuracy: 0.5480 - val_loss: 29.2244 - val_accuracy: 0.1320\n",
      "Epoch 25/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4174 - accuracy: 0.5240\n",
      "Epoch 00025: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.4174 - accuracy: 0.5240 - val_loss: 33.4223 - val_accuracy: 0.1000\n",
      "Epoch 26/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3739 - accuracy: 0.5234\n",
      "Epoch 00026: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.4055 - accuracy: 0.5360 - val_loss: 26.0521 - val_accuracy: 0.1080\n",
      "Epoch 27/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.3696 - accuracy: 0.6000\n",
      "Epoch 00027: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1.3696 - accuracy: 0.6000 - val_loss: 27.2299 - val_accuracy: 0.1240\n",
      "Epoch 28/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3197 - accuracy: 0.5547\n",
      "Epoch 00028: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.3280 - accuracy: 0.5800 - val_loss: 24.5087 - val_accuracy: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3041 - accuracy: 0.5820\n",
      "Epoch 00029: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.3517 - accuracy: 0.5600 - val_loss: 21.2465 - val_accuracy: 0.1320\n",
      "Epoch 30/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3078 - accuracy: 0.5984\n",
      "Epoch 00030: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.2942 - accuracy: 0.6240 - val_loss: 19.1975 - val_accuracy: 0.1360\n",
      "Epoch 31/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.2598 - accuracy: 0.6200\n",
      "Epoch 00031: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.2598 - accuracy: 0.6200 - val_loss: 21.8771 - val_accuracy: 0.1400\n",
      "Epoch 32/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2255 - accuracy: 0.6719\n",
      "Epoch 00032: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2256 - accuracy: 0.6520 - val_loss: 25.0041 - val_accuracy: 0.1040\n",
      "Epoch 33/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1961 - accuracy: 0.6200\n",
      "Epoch 00033: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.1961 - accuracy: 0.6200 - val_loss: 24.9191 - val_accuracy: 0.1160\n",
      "Epoch 34/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0017 - accuracy: 0.7377\n",
      "Epoch 00034: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.1360 - accuracy: 0.6600 - val_loss: 30.1128 - val_accuracy: 0.1160\n",
      "Epoch 35/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0380 - accuracy: 0.7031\n",
      "Epoch 00035: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1582 - accuracy: 0.6320 - val_loss: 19.6382 - val_accuracy: 0.1400\n",
      "Epoch 36/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0667 - accuracy: 0.6719\n",
      "Epoch 00036: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.0673 - accuracy: 0.6880 - val_loss: 24.0817 - val_accuracy: 0.1160\n",
      "Epoch 37/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1525 - accuracy: 0.5938\n",
      "Epoch 00037: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0970 - accuracy: 0.6400 - val_loss: 27.7438 - val_accuracy: 0.1720\n",
      "Epoch 38/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0179 - accuracy: 0.7500\n",
      "Epoch 00038: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0578 - accuracy: 0.6840 - val_loss: 33.0915 - val_accuracy: 0.1080\n",
      "Epoch 39/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.0190 - accuracy: 0.7000\n",
      "Epoch 00039: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0190 - accuracy: 0.7000 - val_loss: 25.3919 - val_accuracy: 0.1200\n",
      "Epoch 40/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9777 - accuracy: 0.6920\n",
      "Epoch 00040: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9777 - accuracy: 0.6920 - val_loss: 31.6840 - val_accuracy: 0.1000\n",
      "Epoch 41/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9349 - accuracy: 0.7120\n",
      "Epoch 00041: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.9349 - accuracy: 0.7120 - val_loss: 25.0785 - val_accuracy: 0.1080\n",
      "Epoch 42/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0829 - accuracy: 0.6641\n",
      "Epoch 00042: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.3095 - accuracy: 0.5720 - val_loss: 35.2446 - val_accuracy: 0.1080\n",
      "Epoch 43/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7779 - accuracy: 0.4375\n",
      "Epoch 00043: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.0237 - accuracy: 0.4160 - val_loss: 44.7670 - val_accuracy: 0.1000\n",
      "Epoch 44/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0511 - accuracy: 0.3852\n",
      "Epoch 00044: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.9685 - accuracy: 0.4080 - val_loss: 48.6359 - val_accuracy: 0.1000\n",
      "Epoch 45/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8779 - accuracy: 0.4141\n",
      "Epoch 00045: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.7801 - accuracy: 0.4360 - val_loss: 47.9548 - val_accuracy: 0.1000\n",
      "Epoch 46/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5251 - accuracy: 0.5078\n",
      "Epoch 00046: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.6227 - accuracy: 0.4800 - val_loss: 43.6042 - val_accuracy: 0.1040\n",
      "Epoch 47/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.5351 - accuracy: 0.4960\n",
      "Epoch 00047: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.5351 - accuracy: 0.4960 - val_loss: 36.6571 - val_accuracy: 0.1400\n",
      "Epoch 48/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3828 - accuracy: 0.5391\n",
      "Epoch 00048: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.4325 - accuracy: 0.5360 - val_loss: 31.8632 - val_accuracy: 0.1440\n",
      "Epoch 49/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4320 - accuracy: 0.6016\n",
      "Epoch 00049: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.2997 - accuracy: 0.6280 - val_loss: 28.3334 - val_accuracy: 0.1400\n",
      "Epoch 50/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2285 - accuracy: 0.6230\n",
      "Epoch 00050: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2903 - accuracy: 0.5840 - val_loss: 24.8948 - val_accuracy: 0.1320\n",
      "Epoch 51/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2057 - accuracy: 0.6016\n",
      "Epoch 00051: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1777 - accuracy: 0.6560 - val_loss: 21.3070 - val_accuracy: 0.1360\n",
      "Epoch 52/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1081 - accuracy: 0.6641\n",
      "Epoch 00052: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.1197 - accuracy: 0.6520 - val_loss: 17.9449 - val_accuracy: 0.1440\n",
      "Epoch 53/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0572 - accuracy: 0.7109\n",
      "Epoch 00053: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0626 - accuracy: 0.6560 - val_loss: 15.3063 - val_accuracy: 0.1520\n",
      "Epoch 54/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0743 - accuracy: 0.6885\n",
      "Epoch 00054: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1.0649 - accuracy: 0.6720 - val_loss: 13.2578 - val_accuracy: 0.1600\n",
      "Epoch 55/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9668 - accuracy: 0.7240\n",
      "Epoch 00055: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.9668 - accuracy: 0.7240 - val_loss: 11.7472 - val_accuracy: 0.1720\n",
      "Epoch 56/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0124 - accuracy: 0.6953\n",
      "Epoch 00056: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9577 - accuracy: 0.7400 - val_loss: 10.5217 - val_accuracy: 0.1800\n",
      "Epoch 57/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.9110 - accuracy: 0.7400\n",
      "Epoch 00057: val_accuracy did not improve from 0.20000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.9110 - accuracy: 0.7400 - val_loss: 9.5993 - val_accuracy: 0.1960\n",
      "Epoch 58/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8618 - accuracy: 0.7812\n",
      "Epoch 00058: val_accuracy improved from 0.20000 to 0.21600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 84ms/step - loss: 0.9096 - accuracy: 0.7440 - val_loss: 8.9411 - val_accuracy: 0.2160\n",
      "Epoch 59/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8064 - accuracy: 0.8125\n",
      "Epoch 00059: val_accuracy improved from 0.21600 to 0.22400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.8800 - accuracy: 0.7560 - val_loss: 8.3250 - val_accuracy: 0.2240\n",
      "Epoch 60/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.8422 - accuracy: 0.7720\n",
      "Epoch 00060: val_accuracy improved from 0.22400 to 0.23600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8422 - accuracy: 0.7720 - val_loss: 7.7049 - val_accuracy: 0.2360\n",
      "Epoch 61/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.8498 - accuracy: 0.7891\n",
      "Epoch 00061: val_accuracy improved from 0.23600 to 0.24000, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.8128 - accuracy: 0.7960 - val_loss: 7.0784 - val_accuracy: 0.2400\n",
      "Epoch 62/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7230 - accuracy: 0.8203\n",
      "Epoch 00062: val_accuracy did not improve from 0.24000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7900 - accuracy: 0.7960 - val_loss: 6.4635 - val_accuracy: 0.2240\n",
      "Epoch 63/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7218 - accuracy: 0.8125\n",
      "Epoch 00063: val_accuracy did not improve from 0.24000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7549 - accuracy: 0.8240 - val_loss: 5.9281 - val_accuracy: 0.2320\n",
      "Epoch 64/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7513 - accuracy: 0.7969\n",
      "Epoch 00064: val_accuracy improved from 0.24000 to 0.24400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.7580 - accuracy: 0.8120 - val_loss: 5.4456 - val_accuracy: 0.2440\n",
      "Epoch 65/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7100 - accuracy: 0.8359\n",
      "Epoch 00065: val_accuracy did not improve from 0.24400\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7157 - accuracy: 0.8360 - val_loss: 5.0510 - val_accuracy: 0.2440\n",
      "Epoch 66/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7758 - accuracy: 0.8281\n",
      "Epoch 00066: val_accuracy did not improve from 0.24400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7425 - accuracy: 0.8240 - val_loss: 4.7068 - val_accuracy: 0.2400\n",
      "Epoch 67/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7795 - accuracy: 0.7812\n",
      "Epoch 00067: val_accuracy improved from 0.24400 to 0.26800, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.7525 - accuracy: 0.8040 - val_loss: 4.4772 - val_accuracy: 0.2680\n",
      "Epoch 68/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7681 - accuracy: 0.8203\n",
      "Epoch 00068: val_accuracy did not improve from 0.26800\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7372 - accuracy: 0.8200 - val_loss: 4.2358 - val_accuracy: 0.2640\n",
      "Epoch 69/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6327 - accuracy: 0.8750\n",
      "Epoch 00069: val_accuracy improved from 0.26800 to 0.27600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6466 - accuracy: 0.8680 - val_loss: 4.0595 - val_accuracy: 0.2760\n",
      "Epoch 70/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5962 - accuracy: 0.8594\n",
      "Epoch 00070: val_accuracy did not improve from 0.27600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6679 - accuracy: 0.8400 - val_loss: 3.8981 - val_accuracy: 0.2680\n",
      "Epoch 71/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6855 - accuracy: 0.8359\n",
      "Epoch 00071: val_accuracy did not improve from 0.27600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6594 - accuracy: 0.8560 - val_loss: 3.7716 - val_accuracy: 0.2760\n",
      "Epoch 72/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.8400\n",
      "Epoch 00072: val_accuracy did not improve from 0.27600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6593 - accuracy: 0.8400 - val_loss: 3.6434 - val_accuracy: 0.2720\n",
      "Epoch 73/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.8760\n",
      "Epoch 00073: val_accuracy improved from 0.27600 to 0.30400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.6165 - accuracy: 0.8760 - val_loss: 3.5411 - val_accuracy: 0.3040\n",
      "Epoch 74/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6286 - accuracy: 0.8607\n",
      "Epoch 00074: val_accuracy improved from 0.30400 to 0.31600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6240 - accuracy: 0.8680 - val_loss: 3.4297 - val_accuracy: 0.3160\n",
      "Epoch 75/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.8880\n",
      "Epoch 00075: val_accuracy did not improve from 0.31600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5850 - accuracy: 0.8880 - val_loss: 3.3527 - val_accuracy: 0.3040\n",
      "Epoch 76/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6181 - accuracy: 0.8750\n",
      "Epoch 00076: val_accuracy improved from 0.31600 to 0.32800, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.6106 - accuracy: 0.8760 - val_loss: 3.3031 - val_accuracy: 0.3280\n",
      "Epoch 77/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6174 - accuracy: 0.8594\n",
      "Epoch 00077: val_accuracy improved from 0.32800 to 0.33600, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.5904 - accuracy: 0.8800 - val_loss: 3.2582 - val_accuracy: 0.3360\n",
      "Epoch 78/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5492 - accuracy: 0.9016\n",
      "Epoch 00078: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5660 - accuracy: 0.8920 - val_loss: 3.1978 - val_accuracy: 0.3280\n",
      "Epoch 79/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5880 - accuracy: 0.8906\n",
      "Epoch 00079: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5785 - accuracy: 0.8880 - val_loss: 3.1553 - val_accuracy: 0.3280\n",
      "Epoch 80/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5996 - accuracy: 0.8525\n",
      "Epoch 00080: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5616 - accuracy: 0.8760 - val_loss: 3.1124 - val_accuracy: 0.3280\n",
      "Epoch 81/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5049 - accuracy: 0.9062\n",
      "Epoch 00081: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5362 - accuracy: 0.9040 - val_loss: 3.0649 - val_accuracy: 0.3280\n",
      "Epoch 82/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5409 - accuracy: 0.9141\n",
      "Epoch 00082: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5609 - accuracy: 0.9120 - val_loss: 3.0237 - val_accuracy: 0.3200\n",
      "Epoch 83/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5479 - accuracy: 0.9120\n",
      "Epoch 00083: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5479 - accuracy: 0.9120 - val_loss: 2.9957 - val_accuracy: 0.3240\n",
      "Epoch 84/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.9040\n",
      "Epoch 00084: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5474 - accuracy: 0.9040 - val_loss: 2.9765 - val_accuracy: 0.3280\n",
      "Epoch 85/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.9120\n",
      "Epoch 00085: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5472 - accuracy: 0.9120 - val_loss: 2.9623 - val_accuracy: 0.3320\n",
      "Epoch 86/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.9160\n",
      "Epoch 00086: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5342 - accuracy: 0.9160 - val_loss: 2.9516 - val_accuracy: 0.3320\n",
      "Epoch 87/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5568 - accuracy: 0.8750\n",
      "Epoch 00087: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5279 - accuracy: 0.9160 - val_loss: 2.9434 - val_accuracy: 0.3320\n",
      "Epoch 88/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.9080\n",
      "Epoch 00088: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5039 - accuracy: 0.9080 - val_loss: 2.9340 - val_accuracy: 0.3320\n",
      "Epoch 89/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5722 - accuracy: 0.8984\n",
      "Epoch 00089: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5355 - accuracy: 0.9000 - val_loss: 2.9267 - val_accuracy: 0.3240\n",
      "Epoch 90/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5201 - accuracy: 0.8984\n",
      "Epoch 00090: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4946 - accuracy: 0.9120 - val_loss: 2.9201 - val_accuracy: 0.3280\n",
      "Epoch 91/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5267 - accuracy: 0.9240\n",
      "Epoch 00091: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5267 - accuracy: 0.9240 - val_loss: 2.9115 - val_accuracy: 0.3280\n",
      "Epoch 92/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.9200\n",
      "Epoch 00092: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4892 - accuracy: 0.9200 - val_loss: 2.9019 - val_accuracy: 0.3320\n",
      "Epoch 93/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4924 - accuracy: 0.9016\n",
      "Epoch 00093: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4957 - accuracy: 0.9160 - val_loss: 2.8910 - val_accuracy: 0.3320\n",
      "Epoch 94/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.9040\n",
      "Epoch 00094: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5277 - accuracy: 0.9040 - val_loss: 2.8767 - val_accuracy: 0.3240\n",
      "Epoch 95/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4338 - accuracy: 0.9426\n",
      "Epoch 00095: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4882 - accuracy: 0.9360 - val_loss: 2.8633 - val_accuracy: 0.3280\n",
      "Epoch 96/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5227 - accuracy: 0.9040\n",
      "Epoch 00096: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5227 - accuracy: 0.9040 - val_loss: 2.8496 - val_accuracy: 0.3280\n",
      "Epoch 97/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.9200\n",
      "Epoch 00097: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4928 - accuracy: 0.9200 - val_loss: 2.8349 - val_accuracy: 0.3320\n",
      "Epoch 98/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.9200\n",
      "Epoch 00098: val_accuracy did not improve from 0.33600\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5166 - accuracy: 0.9200 - val_loss: 2.8219 - val_accuracy: 0.3360\n",
      "Epoch 99/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.9000\n",
      "Epoch 00099: val_accuracy improved from 0.33600 to 0.34000, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.5091 - accuracy: 0.9000 - val_loss: 2.8092 - val_accuracy: 0.3400\n",
      "Epoch 100/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.9040\n",
      "Epoch 00100: val_accuracy improved from 0.34000 to 0.34400, saving model to ../../../models/cifar10/rs=15/cifar10_mt=jv_np=0.6_t=asym.h5\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.4865 - accuracy: 0.9040 - val_loss: 2.7963 - val_accuracy: 0.3440\n",
      "Epoch 101/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5126 - accuracy: 0.9262\n",
      "Epoch 00101: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4905 - accuracy: 0.9320 - val_loss: 2.7857 - val_accuracy: 0.3440\n",
      "Epoch 102/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.9160\n",
      "Epoch 00102: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4723 - accuracy: 0.9160 - val_loss: 2.7762 - val_accuracy: 0.3440\n",
      "Epoch 103/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.9280\n",
      "Epoch 00103: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4832 - accuracy: 0.9280 - val_loss: 2.7671 - val_accuracy: 0.3440\n",
      "Epoch 104/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8880\n",
      "Epoch 00104: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5196 - accuracy: 0.8880 - val_loss: 2.7587 - val_accuracy: 0.3400\n",
      "Epoch 105/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5020 - accuracy: 0.9180\n",
      "Epoch 00105: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4944 - accuracy: 0.9240 - val_loss: 2.7517 - val_accuracy: 0.3400\n",
      "Epoch 106/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5225 - accuracy: 0.9141\n",
      "Epoch 00106: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5065 - accuracy: 0.9200 - val_loss: 2.7445 - val_accuracy: 0.3440\n",
      "Epoch 107/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4938 - accuracy: 0.9297\n",
      "Epoch 00107: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4979 - accuracy: 0.9240 - val_loss: 2.7388 - val_accuracy: 0.3440\n",
      "Epoch 108/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4945 - accuracy: 0.9219\n",
      "Epoch 00108: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4908 - accuracy: 0.9160 - val_loss: 2.7322 - val_accuracy: 0.3440\n",
      "Epoch 109/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4950 - accuracy: 0.9141\n",
      "Epoch 00109: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4812 - accuracy: 0.9280 - val_loss: 2.7247 - val_accuracy: 0.3400\n",
      "Epoch 110/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5006 - accuracy: 0.9016\n",
      "Epoch 00110: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5000 - accuracy: 0.9160 - val_loss: 2.7173 - val_accuracy: 0.3440\n",
      "Epoch 111/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5184 - accuracy: 0.8934\n",
      "Epoch 00111: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5298 - accuracy: 0.9040 - val_loss: 2.7110 - val_accuracy: 0.3440\n",
      "Epoch 112/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5225 - accuracy: 0.9098\n",
      "Epoch 00112: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4979 - accuracy: 0.9240 - val_loss: 2.7038 - val_accuracy: 0.3440\n",
      "Epoch 113/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4513 - accuracy: 0.9344\n",
      "Epoch 00113: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4677 - accuracy: 0.9280 - val_loss: 2.6977 - val_accuracy: 0.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.9200\n",
      "Epoch 00114: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4838 - accuracy: 0.9200 - val_loss: 2.6914 - val_accuracy: 0.3400\n",
      "Epoch 115/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.9240\n",
      "Epoch 00115: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4840 - accuracy: 0.9240 - val_loss: 2.6857 - val_accuracy: 0.3440\n",
      "Epoch 116/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4896 - accuracy: 0.9219\n",
      "Epoch 00116: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4708 - accuracy: 0.9280 - val_loss: 2.6815 - val_accuracy: 0.3400\n",
      "Epoch 117/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5030 - accuracy: 0.8852\n",
      "Epoch 00117: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4751 - accuracy: 0.9160 - val_loss: 2.6763 - val_accuracy: 0.3440\n",
      "Epoch 118/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4474 - accuracy: 0.9531\n",
      "Epoch 00118: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4974 - accuracy: 0.9120 - val_loss: 2.6717 - val_accuracy: 0.3440\n",
      "Epoch 119/120\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4540 - accuracy: 0.9375\n",
      "Epoch 00119: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4761 - accuracy: 0.9360 - val_loss: 2.6691 - val_accuracy: 0.3440\n",
      "Epoch 120/120\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.9280\n",
      "Epoch 00120: val_accuracy did not improve from 0.34400\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4757 - accuracy: 0.9280 - val_loss: 2.6660 - val_accuracy: 0.3440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        x=data_generator.flow(\n",
    "            x_val,\n",
    "            y_val,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            seed=RANDOM_SEED,\n",
    "        ),\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_hyper_val, y_hyper_val),\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(JV_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds_val = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_hyper_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_val, axis=1) == np.argwhere(y_hyper_val)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3269"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds_test = utils.utils.compute_preds(\n",
    "    model,\n",
    "    x_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds_test, axis=1) == np.argwhere(y_test)[:,1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 asym 0.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "# type of noise\n",
    "# asym: classes flip to a single other class\n",
    "# sym: classes flip uniformly to any other class\n",
    "TYPE = CONFIG[\"experiment_configs\"][DATASET][\"type\"]\n",
    " # chance of flip\n",
    "NOISE_P = CONFIG[\"experiment_configs\"][DATASET][\"noise_p\"]\n",
    "HYPER_TRAIN_SPLIT = CONFIG[\"experiment_configs\"][DATASET][\"hyper_train_split\"]\n",
    "VAL_FULL_SPLIT = CONFIG[\"experiment_configs\"][DATASET][\"val_full_split\"]\n",
    "HYPER_VAL_SPLIT = CONFIG[\"experiment_configs\"][DATASET][\"hyper_val_split\"]\n",
    "\n",
    "print(RANDOM_SEED, TYPE, NOISE_P)\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}')\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, DATASET, \".npz\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "# processing saved here\n",
    "if os.path.exists(PROCESSED_SAVEPATH):\n",
    "    print(f\"warning: processing has been done for rs={RANDOM_SEED}_t={TYPE}_np={NOISE_P}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    (x, y), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x = x.reshape(x.shape[0], 32, 32, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "    \n",
    "    # standardize data\n",
    "    means = x.mean(axis=0)\n",
    "    x = (x - means)\n",
    "    x_test = (x_test - means)\n",
    "    \n",
    "    # shuffle data\n",
    "    idx_perm = np.random.permutation(x.shape[0])\n",
    "    x, y = x[idx_perm], y[idx_perm]\n",
    "    \n",
    "    # 2D -> 1D\n",
    "    y = y.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "\n",
    "    return x, y, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000,), (10000, 32, 32, 3), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 2000\n"
     ]
    }
   ],
   "source": [
    "num_ht = int(HYPER_TRAIN_SPLIT * x.shape[0])\n",
    "num_v = int(VAL_FULL_SPLIT * x.shape[0])\n",
    "print(num_ht, num_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off train_full/val_full\n",
    "x_train_full, x_val_full, y_train_full, y_val_full = model_selection.train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=num_v,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# these variables are no longer needed\n",
    "del x, y\n",
    "\n",
    "# #TODO: trying, handle\n",
    "# x_test, x_val_full, y_test, y_val_full = model_selection.train_test_split(\n",
    "#     x_test,\n",
    "#     y_test,\n",
    "#     test_size=VAL_FULL_SPLIT,\n",
    "#     stratify=y_test,\n",
    "#     random_state=RANDOM_SEED,\n",
    "# )\n",
    "\n",
    "# split off hyper val from val\n",
    "x_val, x_hyper_val, y_val, y_hyper_val = model_selection.train_test_split(\n",
    "    x_val_full,\n",
    "    y_val_full,\n",
    "    test_size=HYPER_VAL_SPLIT,\n",
    "    stratify=y_val_full,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# these variables are no longer needed\n",
    "del x_val_full, y_val_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(y, nc):\n",
    "    '''\n",
    "    Adds noise to `y` labels with `nc` classes.\n",
    "    Uses NOISE_P global to determine the chance of flipping the label.\n",
    "    Uses TYPE global to determine how to apply the flip.\n",
    "        sym: flip to a different class randomly and uniformly\n",
    "        asym: flip to a specific class always (one with semantic meaning)\n",
    "    '''\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    y = np.copy(y)\n",
    "    \n",
    "    if TYPE == 'asym':\n",
    "        # mappings, from https://arxiv.org/pdf/1609.03683.pdf\n",
    "        # TRUCK → AUTOMOBILE (9, 1)\n",
    "        # BIRD → AIRPLANE (2, 0)\n",
    "        # DEER → HORSE (4, 7)\n",
    "        # CAT ↔ DOG (3, 5)\n",
    "\n",
    "        noise_transitions = {\n",
    "            9: 1,\n",
    "            2: 0,\n",
    "            4: 7,\n",
    "            3: 5,\n",
    "            5: 3,\n",
    "        }\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            yi_true = y[i]\n",
    "            if yi_true in noise_transitions and np.random.uniform() < NOISE_P:\n",
    "                # flip to corresponding asym noise transition\n",
    "                y[i] = noise_transitions[ yi_true ]\n",
    "                    \n",
    "    elif TYPE == 'sym':\n",
    "        for i in range(len(y)):\n",
    "            yi_true = y[i]\n",
    "            if np.random.uniform() < NOISE_P:\n",
    "                # flip to random class that is not the true class\n",
    "                rand_c = np.random.randint(0, nc - 1)\n",
    "                while rand_c == yi_true:\n",
    "                    rand_c = np.random.randint(0, nc - 1)\n",
    "                y[i] = rand_c\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"unrecognized type {TYPE}\")\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the true y to y_true\n",
    "y_train_full_true = y_train_full\n",
    "\n",
    "# deepcopies and creates y_train (noisy)\n",
    "y_train_full = add_noise(y_train_full, nc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off hyper train from train\n",
    "x_train, x_hyper_train, y_train, y_hyper_train, y_train_true, y_hyper_train_true = model_selection.train_test_split(\n",
    "    x_train_full,\n",
    "    y_train_full,\n",
    "    y_train_full_true,\n",
    "    test_size=num_ht,\n",
    "    stratify=y_train_full, # stratify on noisy label\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38000, 32, 32, 3) (10000, 32, 32, 3) (1000, 32, 32, 3) (1000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(38000,) (10000,) (1000,) (1000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_hyper_train.shape, x_val.shape, x_hyper_val.shape, x_test.shape)\n",
    "print(y_train.shape, y_hyper_train.shape, y_val.shape, y_hyper_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    PROCESSED_SAVEPATH,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    y_train_true=y_train_true,\n",
    "    \n",
    "    x_hyper_train=x_hyper_train,\n",
    "    y_hyper_train=y_hyper_train,\n",
    "    y_hyper_train_true=y_hyper_train_true,\n",
    "    \n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    \n",
    "    x_hyper_val=x_hyper_val,\n",
    "    y_hyper_val=y_hyper_val,\n",
    "    \n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

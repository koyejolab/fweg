{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "import umap\n",
    "import time\n",
    "import functools\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "import utils.fweg\n",
    "import utils.metrics\n",
    "import utils.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 asym 0.6\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "# type of noise\n",
    "# asym: classes flip to a single other class\n",
    "# sym: classes flip uniformly to any other class\n",
    "TYPE = CONFIG[\"experiment_configs\"][DATASET][\"type\"]\n",
    " # chance of flip\n",
    "NOISE_P = CONFIG[\"experiment_configs\"][DATASET][\"noise_p\"]\n",
    "HYPER_VAL_SPLIT = CONFIG[\"experiment_configs\"][DATASET][\"hyper_val_split\"]\n",
    "\n",
    "EPOCHS = CONFIG[\"experiment_configs\"][DATASET][\"epochs\"]\n",
    "BATCH_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"batch_size\"]\n",
    "IMAGE_X = CONFIG[\"experiment_configs\"][DATASET][\"image_x_size\"]\n",
    "IMAGE_Y = CONFIG[\"experiment_configs\"][DATASET][\"image_y_size\"]\n",
    "IMAGE_SIZE = (IMAGE_Y, IMAGE_X)\n",
    "\n",
    "print(RANDOM_SEED, TYPE, NOISE_P)\n",
    "\n",
    "# folders for processed, models\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, DATASET, \".npz\", t=TYPE, np=NOISE_P)\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"base\", t=TYPE, np=NOISE_P)\n",
    "\n",
    "if not os.path.exists(BASE_MODEL_SAVEPATH):\n",
    "    print(f\"warning: model has not been run for rs={RANDOM_SEED}_t={TYPE}_np={NOISE_P}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSED_SAVEPATH, 'rb') as f:\n",
    "    dat = np.load(f)\n",
    "    \n",
    "    x_train = dat['x_train']\n",
    "    y_train = dat['y_train']\n",
    "    \n",
    "    x_hyper_train = dat['x_hyper_train']\n",
    "    y_hyper_train = dat['y_hyper_train']\n",
    "\n",
    "    x_val = dat['x_val']\n",
    "    y_val = dat['y_val']\n",
    "    \n",
    "    x_hyper_val = dat['x_hyper_val']\n",
    "    y_hyper_val = dat['y_hyper_val']\n",
    "\n",
    "    x_test = dat['x_test']\n",
    "    y_test = dat['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = np.concatenate([x_train, x_hyper_train])\n",
    "y_train_full = np.concatenate([y_train, y_hyper_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full_flat = x_train_full.reshape(len(x_train_full), -1)\n",
    "x_val_flat = x_val.reshape(len(x_val), -1)\n",
    "x_hyper_val_flat = x_hyper_val.reshape(len(x_hyper_val), -1)\n",
    "x_test_flat = x_test.reshape(len(x_test), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49000, 3072), (500, 3072), (500, 3072), (10000, 3072))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full_flat.shape, x_val_flat.shape, x_hyper_val_flat.shape, x_test_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_FULL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_train_full_emb_V2\", \".npy\", t=TYPE, np=NOISE_P)\n",
    "X_VAL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_val_emb_V2\", \".npy\", t=TYPE, np=NOISE_P)\n",
    "X_HYPER_VAL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_hyper_val_emb_V2\", \".npy\", t=TYPE, np=NOISE_P)\n",
    "X_TEST_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_test_emb_V2\", \".npy\", t=TYPE, np=NOISE_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding already made, loading saved...\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(X_TRAIN_FULL_EMB_SAVEPATH):\n",
    "    print('embedding already made, loading saved...')\n",
    "    x_train_full_emb = np.load(\n",
    "        X_TRAIN_FULL_EMB_SAVEPATH,\n",
    "    )\n",
    "\n",
    "    x_val_emb = np.load(\n",
    "        X_VAL_EMB_SAVEPATH,\n",
    "    )\n",
    "\n",
    "    x_hyper_val_emb = np.load(\n",
    "        X_HYPER_VAL_EMB_SAVEPATH,\n",
    "    )\n",
    "    \n",
    "    x_test_emb = np.load(\n",
    "        X_TEST_EMB_SAVEPATH,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"Making embeddings with UMAP\")\n",
    "    \n",
    "    n_neighbors = 10\n",
    "    dim = 10\n",
    "    dim = 50\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    umap_emb = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=0.5, \n",
    "        n_components=dim,\n",
    "        metric='euclidean',\n",
    "        random_state = RANDOM_SEED,\n",
    "    )\n",
    "\n",
    "    umap_emb.fit(x_train_full_flat)\n",
    "    \n",
    "    x_train_full_emb = umap_emb.transform(x_train_full_flat)\n",
    "    x_val_emb = umap_emb.transform(x_val_flat)\n",
    "    x_hyper_val_emb = umap_emb.transform(x_hyper_val_flat)\n",
    "    x_test_emb = umap_emb.transform(x_test_flat)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    # 220 seconds on our machine, a GCP n1-highmem-2 (2 vCPUs, 13 GB memory)\n",
    "    print(f\"Took {end - start} sec\")\n",
    "\n",
    "    # save these to avoid running above again\n",
    "    np.save(\n",
    "        X_TRAIN_FULL_EMB_SAVEPATH,\n",
    "        x_train_full_emb,\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        X_VAL_EMB_SAVEPATH,\n",
    "        x_val_emb,\n",
    "    )\n",
    "    \n",
    "    np.save(\n",
    "        X_HYPER_VAL_EMB_SAVEPATH,\n",
    "        x_hyper_val_emb,\n",
    "    )\n",
    "\n",
    "    np.save(\n",
    "        X_TEST_EMB_SAVEPATH,\n",
    "        x_test_emb,\n",
    "    )\n",
    "    \n",
    "    # delete references to reclaim memory\n",
    "    del umap_emb, x_train_full_flat, x_val_flat, x_hyper_val_flat, x_test_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49000, 50), (500, 50), (500, 50), (10000, 50))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full_emb.shape, x_val_emb.shape, x_hyper_val_emb.shape, x_test_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model\n",
    "model = utils.utils.make_resnet(\n",
    "    depth=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=10,\n",
    ")\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_full = utils.utils.compute_preds(model, x_train_full, batch_size=BATCH_SIZE)\n",
    "preds_val = utils.utils.compute_preds(model, x_val, batch_size=BATCH_SIZE)\n",
    "preds_hyper_val = utils.utils.compute_preds(model, x_hyper_val, batch_size=BATCH_SIZE)\n",
    "preds_test = utils.utils.compute_preds(model, x_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width of the RBF kernel functions\n",
    "KER_WIDTH = 2\n",
    "kernel = RBF(KER_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute kernels with respect to x_val_emb\n",
    "kernel_train_full = kernel(x_train_full_emb, x_val_emb)\n",
    "kernel_val = kernel(x_val_emb, x_val_emb)\n",
    "kernel_hyper_val = kernel(x_hyper_val_emb, x_val_emb)\n",
    "kernel_test = kernel(x_test_emb, x_val_emb)\n",
    "\n",
    "kernel_train_full = np.clip(kernel_train_full, 0.01, 0.99)\n",
    "kernel_val = np.clip(kernel_val, 0.01, 0.99)\n",
    "kernel_hyper_val = np.clip(kernel_hyper_val, 0.01, 0.99)\n",
    "kernel_test = np.clip(kernel_test, 0.01, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_fns(\n",
    "    groups,\n",
    "    y_val,\n",
    "    kernel_train,\n",
    "    kernel_val,\n",
    "    kernel_hyper_val,\n",
    "    kernel_test,\n",
    "    add_all,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a separate dataset whose columns are RBF's or GROUPS or both, and\n",
    "    rows denote the membership value for a sample for that basis function.\n",
    "    \n",
    "    Args:\n",
    "        groups: number of groups to make. Must be 1 or 10.\n",
    "        y_val: the labels on the val set\n",
    "        kernel_train: kernel distance between each train sample and each val sample\n",
    "        kernel_val: kernel distance between each val sample and other val samples\n",
    "        kernel_hyper_val: kernel distance between each hyper val sample and each val sample\n",
    "        kernel_test: kernel distance between each test sample and each val train sample\n",
    "        add_all: True if a group should be made that holds all samples \n",
    "\n",
    "    Returns:\n",
    "        basis_train: membership of each train sample to each group\n",
    "        basis_val_train: membership of each val train sample to each group\n",
    "        basis_val_test: membership of each val test sample to each group\n",
    "        basis_test: membership of each test sample to each group\n",
    "    \"\"\"\n",
    "    assert groups in (1, 10)\n",
    "    if groups == 1:\n",
    "        assert add_all is False\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    if groups == 1:\n",
    "        basis_train = pd.DataFrame(np.ones(len(kernel_train)), columns=[\"All\"])\n",
    "        basis_val = pd.DataFrame(np.ones(len(kernel_val)), columns=[\"All\"])\n",
    "        basis_hyper_val = pd.DataFrame(np.ones(len(kernel_hyper_val)), columns=[\"All\"])\n",
    "        basis_test = pd.DataFrame(np.ones(len(kernel_test)), columns=[\"All\"])\n",
    "    else:\n",
    "        # Computing RBF kernel matrix centred at each validation points\n",
    "        basis_train = pd.DataFrame()\n",
    "        basis_val = pd.DataFrame()\n",
    "        basis_hyper_val = pd.DataFrame()\n",
    "        basis_test = pd.DataFrame()\n",
    "        \n",
    "        # 1 group per class\n",
    "        chosen_classes = list(range(CLASSES))\n",
    "        \n",
    "        for cc in chosen_classes:\n",
    "            choices = np.where(y_val == cc)[0]\n",
    "            basis_train[f\"cc={cc}\"] = kernel_train[:, choices].mean(axis=1)\n",
    "            basis_val[f\"cc={cc}\"] = kernel_val[:, choices].mean(axis=1)\n",
    "            basis_hyper_val[f\"cc={cc}\"] = kernel_hyper_val[:, choices].mean(axis=1)\n",
    "            basis_test[f\"cc={cc}\"] = kernel_test[:, choices].mean(axis=1)\n",
    "\n",
    "    if add_all:\n",
    "        basis_train['All'] = 1.0\n",
    "        basis_val['All'] = 1.0\n",
    "        basis_hyper_val['All'] = 1.0\n",
    "        basis_test['All'] = 1.0\n",
    "        \n",
    "    return basis_train, basis_val, basis_hyper_val, basis_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 10\n",
    "\n",
    "# number of groups to make \n",
    "NUM_GROUPS = 10\n",
    "\n",
    "ADD_ALL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_train_full, basis_val, basis_hyper_val, basis_test = get_basis_fns(\n",
    "    NUM_GROUPS,\n",
    "    y_val,\n",
    "    kernel_train_full,\n",
    "    kernel_val,\n",
    "    kernel_hyper_val,\n",
    "    kernel_test,\n",
    "    add_all = ADD_ALL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for fweg. See FWEG's docstrings for an explanation.\n",
    "\n",
    "EPSILON = 1e-1\n",
    "\n",
    "METRIC = \"Accuracy\" # choose from ['Accuracy', 'F-measure', 'G-mean']\n",
    "\n",
    "USE_LINEAR_VAL_METRIC = False\n",
    "\n",
    "NUM_ITERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.816: 100%|██████████| 5/5 [00:26<00:00,  5.25s/it]\n"
     ]
    }
   ],
   "source": [
    "fweg = utils.fweg.FWEG(\n",
    "    METRIC,\n",
    "    NUM_ITERS,\n",
    "    EPSILON,\n",
    "    CLASSES,\n",
    "    USE_LINEAR_VAL_METRIC,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "\n",
    "val_train_list, grad_norm_list, cond_list = fweg.fit(\n",
    "    preds_train_full,\n",
    "    y_train_full,\n",
    "    basis_train_full,\n",
    "    preds_val,\n",
    "    y_val,\n",
    "    basis_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val: 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "# apply to hyper val set\n",
    "preds_hyper_val_list, mval_hyper_val_list = fweg.predict(\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    basis_hyper_val,\n",
    "    deterministic=False,\n",
    ")\n",
    "\n",
    "best_idx = np.argmax(mval_hyper_val_list)\n",
    "print(f\"Hyper Val: {mval_hyper_val_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.8039000000000001\n"
     ]
    }
   ],
   "source": [
    "# apply to test set\n",
    "preds_test_list, mval_test_list = fweg.predict(\n",
    "    preds_test,\n",
    "    y_test,\n",
    "    basis_test,\n",
    "    deterministic=False,\n",
    ")\n",
    "print(f\"Test: {mval_test_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below to try many hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file exists, appending to it...\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "savepath = os.path.join(RESULTS_DIR, f\"results_{DATASET}.csv\")\n",
    "saver = utils.record.Results_Recorder(savepath, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 10\n",
    "NUM_ITERS = 5\n",
    "METRIC = \"Accuracy\"\n",
    "\n",
    "groups_list = [1, 10]\n",
    "groups_descr_list = [\"no groups\", \"group for each class\"]\n",
    "add_all_list = [False, True]\n",
    "epsilon_list = [0.0001, 0.001, 0.1, 1.0]\n",
    "# linearized metric for accuracy is the same as accuracy\n",
    "use_linear_val_metric_list = [False]\n",
    "\n",
    "# this fills in most of the arguments for our basis function creator\n",
    "# it is missing the `groups` arg and `add_all`. FWEG_Hyperparameter_Search\n",
    "# is given basis_fn_generator and will fill these in as it iterates over\n",
    "# the hyperparameters.\n",
    "basis_fn_generator = functools.partial(\n",
    "    get_basis_fns,\n",
    "    y_val = y_val,\n",
    "    kernel_train = kernel_train_full,\n",
    "    kernel_val = kernel_val,\n",
    "    kernel_hyper_val = kernel_hyper_val,\n",
    "    kernel_test = kernel_test,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.8, test: 0.8039: 100%|██████████| 16/16 [03:18<00:00, 12.43s/it]  \n"
     ]
    }
   ],
   "source": [
    "fweg_hp_s = utils.fweg.FWEG_Hyperparameter_Search(\n",
    "    saver,\n",
    "    CLASSES,\n",
    "    NUM_ITERS,\n",
    "    METRIC,\n",
    "    basis_fn_generator,\n",
    "    groups_list,\n",
    "    groups_descr_list,\n",
    "    add_all_list,\n",
    "    epsilon_list,\n",
    "    use_linear_val_metric_list,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "\n",
    "(best_groups, best_add_all, best_epsilon, best_use_linear_val_metric) = fweg_hp_s.search(\n",
    "        preds_train_full,\n",
    "        y_train_full,\n",
    "        preds_val,\n",
    "        y_val,\n",
    "        preds_hyper_val,\n",
    "        y_hyper_val,\n",
    "        preds_test,\n",
    "        y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the description for best_group\n",
    "best_groups_descr = None\n",
    "for groups, groups_descr in zip(groups_list, groups_descr_list):\n",
    "    if groups == best_groups:\n",
    "        best_groups_descr = groups_descr\n",
    "        break\n",
    "assert best_groups_descr is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basis assoicated with best parameters\n",
    "basis_train_full, basis_val, basis_hyper_val, basis_test = basis_fn_generator(\n",
    "    groups=best_groups,\n",
    "    add_all=best_add_all,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.816: 100%|██████████| 60/60 [05:14<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {\"groups\": 10, \"groups_descr\": \"group for each class\", \"add_all\": true, \"epsilon\": 0.1, \"FW_val_flag\": false}. hyper val: 0.7999999999999999, test: 0.8039000000000001\n"
     ]
    }
   ],
   "source": [
    "# we do this because running 60 iterations would increase how long the hyperparameter search\n",
    "# takes. more optimized code could do early stopping and paralellize the FWEG algorithm\n",
    "# but for now this extra code is simplest.\n",
    "\n",
    "# number of iterations for the best-found hyperparams\n",
    "BEST_NUM_ITERS = 60\n",
    "\n",
    "fweg = utils.fweg.FWEG(\n",
    "    METRIC,\n",
    "    BEST_NUM_ITERS,\n",
    "    best_epsilon,\n",
    "    CLASSES,\n",
    "    best_use_linear_val_metric,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "val_train_list, _, _ = fweg.fit(\n",
    "        preds_train_full,\n",
    "        y_train_full,\n",
    "        basis_train_full,\n",
    "        preds_val,\n",
    "        y_val,\n",
    "        basis_val,\n",
    "        verbose=True,\n",
    ")\n",
    "\n",
    "# apply to hyper val set\n",
    "preds_hyper_val_list, mval_hyper_val_list = fweg.predict(\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    basis_hyper_val,\n",
    "    deterministic=False,\n",
    ")\n",
    "\n",
    "best_idx = np.argmax(mval_hyper_val_list)\n",
    "val_score = val_train_list[best_idx]\n",
    "hyper_val_score = mval_hyper_val_list[best_idx]\n",
    "\n",
    "# apply to test set\n",
    "preds_test_list, mval_test_list = fweg.predict(\n",
    "    preds_test,\n",
    "    y_test,\n",
    "    basis_test,\n",
    "    deterministic=False,\n",
    ")\n",
    "test_score = mval_test_list[best_idx]\n",
    "\n",
    "fweg_params = utils.record.format_fweg_extra(\n",
    "    BEST_NUM_ITERS,\n",
    "    best_groups,\n",
    "    best_groups_descr,\n",
    "    best_add_all,\n",
    "    best_epsilon,\n",
    "    best_use_linear_val_metric,\n",
    ")\n",
    "print(f\"best params: {fweg_params}. hyper val: {hyper_val_score}, test: {test_score}\")\n",
    "\n",
    "# prefix fweg_params with BEST: for clear parsing\n",
    "saver.save(\n",
    "    RANDOM_SEED,\n",
    "    METRIC,\n",
    "    \"fweg\",\n",
    "    val_score,\n",
    "    hyper_val_score,\n",
    "    test_score,\n",
    "    \"BEST:\" + fweg_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

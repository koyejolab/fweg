{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "from utils.fweg import FWEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "BATCH_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"batch_size\"]\n",
    "\n",
    "print(RANDOM_SEED)\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/adult/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/adult/rs={RANDOM_SEED}')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"adult\", \".pkl\")\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult\", \".h5\", mt=\"base\") # mt = model_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"train.csv\"))\n",
    "hyper_train_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"hyper_train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"val.csv\"))\n",
    "# in this setting val = hyper_val. the separation is purely for consistency with\n",
    "# other experiments and using FWEG\n",
    "hyper_val_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"hyper_val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"test.csv\"))\n",
    "\n",
    "# concat the two for train\n",
    "train_full_df = pd.concat([train_df, hyper_train_df])\n",
    "\n",
    "del train_df, hyper_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = train_full_df.drop(['label'], axis=1).values\n",
    "y_train_full = train_full_df['label'].values\n",
    "\n",
    "x_val = val_df.drop(['label'], axis=1).values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "x_hyper_val = hyper_val_df.drop(['label'], axis=1).values\n",
    "y_hyper_val = hyper_val_df['label'].values\n",
    "\n",
    "x_test = test_df.drop(['label'], axis=1).values\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_train_full.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_full = model.predict(x_train_full)\n",
    "preds_val = model.predict(x_val)\n",
    "preds_hyper_val = model.predict(x_hyper_val)\n",
    "preds_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_fns(\n",
    "    groups,\n",
    "    train_df,\n",
    "    val_df,\n",
    "    hyper_val_df,\n",
    "    test_df,\n",
    "    add_all\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Get the basis functions for adult.\n",
    "    \"\"\"\n",
    "    all_groups = [\n",
    "        [],\n",
    "        ['private_workforce', 'non_private_workforce'],\n",
    "        ['private_workforce', 'non_private_workforce', 'income']\n",
    "    ]\n",
    "    assert groups in all_groups\n",
    "    if len(groups) == 0:\n",
    "        assert add_all is True\n",
    "        \n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    if len(groups) == 0:\n",
    "        basis_train = pd.DataFrame(np.ones(len(train_df)), columns=[\"All\"])\n",
    "        basis_val = pd.DataFrame(np.ones(len(val_df)), columns=[\"All\"])\n",
    "        basis_hyper_val = pd.DataFrame(np.ones(len(hyper_val_df)), columns=[\"All\"])\n",
    "        basis_test = pd.DataFrame(np.ones(len(test_df)), columns=[\"All\"])\n",
    "    else:\n",
    "        basis_train = train_df[groups].copy()\n",
    "        basis_val = val_df[groups].copy()\n",
    "        basis_hyper_val = hyper_val_df[groups].copy()\n",
    "        basis_test = test_df[groups].copy()\n",
    "    \n",
    "        if add_all:\n",
    "            basis_train['All'] = 1.0\n",
    "            basis_val['All'] = 1.0\n",
    "            basis_hyper_val['All'] = 1.0\n",
    "            basis_test['All'] = 1.0\n",
    "        \n",
    "    return basis_train, basis_val, basis_hyper_val, basis_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 2\n",
    "METRIC = 'G-mean'\n",
    "\n",
    "# must be one of:\n",
    "# []\n",
    "# ['private_workforce', 'non_private_workforce']\n",
    "# ['private_workforce', 'non_private_workforce', 'income']\n",
    "GROUPS = [\"private_workforce\", \"non_private_workforce\"]\n",
    "\n",
    "ADD_ALL = False\n",
    "EPSILON = 1e-4\n",
    "\n",
    "NUM_ITERS = 100\n",
    "\n",
    "USE_LINEAR_VAL_METRIC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_train_full, basis_val, basis_hyper_val, basis_test = get_basis_fns(\n",
    "    GROUPS,\n",
    "    train_full_df,\n",
    "    val_df,\n",
    "    hyper_val_df,\n",
    "    test_df,\n",
    "    ADD_ALL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val G-mean: 0.685: 100%|██████████| 100/100 [00:01<00:00, 51.58it/s]\n"
     ]
    }
   ],
   "source": [
    "fweg = utils.fweg.FWEG(\n",
    "    METRIC,\n",
    "    NUM_ITERS,\n",
    "    EPSILON,\n",
    "    CLASSES,\n",
    "    USE_LINEAR_VAL_METRIC,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "\n",
    "val_train_list, grad_norm_list, cond_list = fweg.fit(\n",
    "    preds_train_full,\n",
    "    y_train_full,\n",
    "    basis_train_full,\n",
    "    preds_val,\n",
    "    y_val,\n",
    "    basis_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val: 0.68476343839989\n"
     ]
    }
   ],
   "source": [
    "# apply to hyper val set\n",
    "preds_hyper_val_list, mval_hyper_val_list = fweg.predict(\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    basis_hyper_val,\n",
    "    deterministic=False,\n",
    ")\n",
    "\n",
    "start = len(mval_hyper_val_list)//2\n",
    "best_idx = start + np.argmax(mval_hyper_val_list[start:])\n",
    "print(f\"Hyper Val: {mval_hyper_val_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.6850109038751132\n"
     ]
    }
   ],
   "source": [
    "# apply to test set\n",
    "preds_test_list, mval_test_list = fweg.predict(\n",
    "    preds_test,\n",
    "    y_test,\n",
    "    basis_test,\n",
    "    deterministic=False,\n",
    ")\n",
    "print(f\"Test: {mval_test_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below to try many hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file exists, appending to it...\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "savepath = os.path.join(RESULTS_DIR, f\"results_{DATASET}.csv\")\n",
    "saver = utils.record.Results_Recorder(savepath, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 2\n",
    "NUM_ITERS = 100\n",
    "METRIC = \"G-mean\"\n",
    "\n",
    "groups_list = [\n",
    "    [],\n",
    "    ['private_workforce', 'non_private_workforce'],\n",
    "    ['private_workforce', 'non_private_workforce', 'income']\n",
    "]\n",
    "groups_descr_list = [\n",
    "    \"single_group\",\n",
    "    \"workforce, non-private workforce\",\n",
    "    \"workforce, non-private workforce, income\",\n",
    "]\n",
    "add_all_list = [False, True]\n",
    "epsilon_list = [0.0001, 0.001, 0.1, 1.0]\n",
    "use_linear_val_metric_list = [False, True]\n",
    "\n",
    "# this fills in most of the arguments for our basis function creator\n",
    "# it is missing the `groups` arg and `add_all`. FWEG_Hyperparameter_Search\n",
    "# is given basis_fn_generator and will fill these in as it iterates over\n",
    "# the hyperparameters.\n",
    "basis_fn_generator = functools.partial(\n",
    "    get_basis_fns,\n",
    "    train_df = train_full_df,\n",
    "    val_df = val_df,\n",
    "    hyper_val_df = hyper_val_df,\n",
    "    test_df = test_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  50%|█████     | 24/48 [00:22<00:43,  1.80s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  52%|█████▏    | 25/48 [00:25<00:48,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  56%|█████▋    | 27/48 [00:30<00:52,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  60%|██████    | 29/48 [00:36<00:51,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  65%|██████▍   | 31/48 [00:42<00:47,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  67%|██████▋   | 32/48 [00:45<00:45,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  69%|██████▉   | 33/48 [00:48<00:42,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  71%|███████   | 34/48 [00:51<00:40,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  73%|███████▎  | 35/48 [00:53<00:37,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  77%|███████▋  | 37/48 [00:59<00:31,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  81%|████████▏ | 39/48 [01:05<00:26,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  83%|████████▎ | 40/48 [01:08<00:23,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  85%|████████▌ | 41/48 [01:13<00:23,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  88%|████████▊ | 42/48 [01:17<00:21,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  90%|████████▉ | 43/48 [01:21<00:19,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  92%|█████████▏| 44/48 [01:25<00:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  94%|█████████▍| 45/48 [01:29<00:11,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  96%|█████████▌| 46/48 [01:34<00:08,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791:  98%|█████████▊| 47/48 [01:38<00:04,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNEXPECTED - already had a trivial classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.721, test: 0.6791: 100%|██████████| 48/48 [01:42<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "fweg_hp_s = utils.fweg.FWEG_Hyperparameter_Search(\n",
    "    saver,\n",
    "    CLASSES,\n",
    "    NUM_ITERS,\n",
    "    METRIC,\n",
    "    basis_fn_generator,\n",
    "    groups_list,\n",
    "    groups_descr_list,\n",
    "    add_all_list,\n",
    "    epsilon_list,\n",
    "    use_linear_val_metric_list,\n",
    "    RANDOM_SEED,\n",
    "    use_convergence=True\n",
    ")\n",
    "\n",
    "(best_groups, best_add_all, best_epsilon, best_use_linear_val_metric) = fweg_hp_s.search(\n",
    "    preds_train_full,\n",
    "    y_train_full,\n",
    "    preds_val,\n",
    "    y_val,\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    preds_test,\n",
    "    y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

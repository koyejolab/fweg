{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tqdm import notebook \n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "VAL_FULL_SPLIT = CONFIG['experiment_configs'][DATASET]['val_full_split']\n",
    "HYPER_VAL_SPLIT = CONFIG['experiment_configs'][DATASET]['hyper_val_split']\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}')\n",
    "# original data folder\n",
    "DATA_F = os.path.join(BASE_DIR, f\"data/adience/\")\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symlink the model\n",
    "src = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'models/adience/rs={RANDOM_SEED}/adience_mt=base.h5')\n",
    ")\n",
    "dest = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'models/adience_ablation/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}/adience_ablation_mt=base.h5')\n",
    ")\n",
    "os.symlink(src, dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symlink the train/hyper train processing because that is invariant of VAL_SPLIT\n",
    "\n",
    "# symlink train.csv\n",
    "src = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience/rs={RANDOM_SEED}/train.csv')\n",
    ")\n",
    "dest = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience_ablation/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}/train.csv')\n",
    ")\n",
    "os.symlink(src, dest)\n",
    "\n",
    "# symlink train folder\n",
    "src = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience/rs={RANDOM_SEED}/train')\n",
    ")\n",
    "dest = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience_ablation/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}/train')\n",
    ")\n",
    "os.symlink(src, dest, target_is_directory = True)\n",
    "\n",
    "# symlink hyper_train csv\n",
    "src = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience/rs={RANDOM_SEED}/hyper_train.csv')\n",
    ")\n",
    "dest = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience_ablation/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}/hyper_train.csv')\n",
    ")\n",
    "os.symlink(src, dest)\n",
    "\n",
    "# symlink hyper train folder\n",
    "src = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience/rs={RANDOM_SEED}/hyper_train')\n",
    ")\n",
    "dest = os.path.abspath(\n",
    "    os.path.join(BASE_DIR, f'processed/adience_ablation/rs={RANDOM_SEED}/vs={VAL_FULL_SPLIT}/hyper_train')\n",
    ")\n",
    "os.symlink(src, dest, target_is_directory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can be clever here... we need do the following:\n",
    "# setup val (different per val split), hyper_val (different per val split), test (consistent across val splits)\n",
    "# we can load the existing val, hyper_val, test computed by adience and reshuffle\n",
    "# them to match the new conditions. we can use the existing embedding features so that\n",
    "# FWEG runs faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing dfs for manupilation\n",
    "adience_processed_f = os.path.join(BASE_DIR, f'processed/adience/rs={RANDOM_SEED}/')\n",
    "adience_val_df = utils.utils.load_sorted_df(adience_processed_f, \"val\")\n",
    "adience_hyper_val_df = utils.utils.load_sorted_df(adience_processed_f, \"hyper_val\")\n",
    "adience_test_df = utils.utils.load_sorted_df(adience_processed_f, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing embeddings for manipulation\n",
    "ADIENCE_X_TRAIN_FULL_EMB_SAVEPATH = utils.utils.get_savepath(adience_processed_f, \"x_train_full_emb\", \".npy\")\n",
    "ADIENCE_X_VAL_EMB_SAVEPATH = utils.utils.get_savepath(adience_processed_f, \"x_val_emb\", \".npy\")\n",
    "ADIENCE_X_HYPER_VAL_EMB_SAVEPATH = utils.utils.get_savepath(adience_processed_f, \"x_hyper_val_emb\", \".npy\")\n",
    "ADIENCE_X_TEST_EMB_SAVEPATH = utils.utils.get_savepath(adience_processed_f, \"x_test_emb\", \".npy\")\n",
    "\n",
    "assert os.path.exists(ADIENCE_X_TRAIN_FULL_EMB_SAVEPATH)\n",
    "\n",
    "x_train_full_emb = np.load(\n",
    "    ADIENCE_X_TRAIN_FULL_EMB_SAVEPATH,\n",
    ")\n",
    "\n",
    "x_val_emb = np.load(\n",
    "    ADIENCE_X_VAL_EMB_SAVEPATH,\n",
    ")\n",
    "\n",
    "x_hyper_val_emb = np.load(\n",
    "    ADIENCE_X_HYPER_VAL_EMB_SAVEPATH,\n",
    ")\n",
    "\n",
    "x_test_emb = np.load(\n",
    "    ADIENCE_X_TEST_EMB_SAVEPATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([adience_val_df, adience_hyper_val_df, adience_test_df])\n",
    "all_emb = np.concatenate([x_val_emb, x_hyper_val_emb, x_test_emb])\n",
    "\n",
    "def get_age_and_gender(df):\n",
    "    age_and_gender = [(df['age'].values[i], df['gender'].values[i]) for i in range(len(df))]\n",
    "    return age_and_gender\n",
    "\n",
    "# to keep the test set consistent, we split val/test deterministically\n",
    "# then depending on the current val_split, we choose subset of val\n",
    "# to make val/hyper_val\n",
    "max_val_split = 0.5\n",
    "expected_val_full_size = int(len(all_df) * VAL_FULL_SPLIT)\n",
    "\n",
    "# this executes the same for a particular random seed, independent of val split\n",
    "age_and_gender = get_age_and_gender(all_df)\n",
    "df_faces_test, df_faces_val_full, x_test_emb, x_val_full_emb = model_selection.train_test_split(\n",
    "    all_df,\n",
    "    all_emb,\n",
    "    test_size=max_val_split,\n",
    "    stratify=age_and_gender,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "if expected_val_full_size < len(df_faces_val_full):\n",
    "    # reduce val_full set to the expected size. the remaining samples are just dropped\n",
    "    age_and_gender = get_age_and_gender(df_faces_val_full)\n",
    "    _, df_faces_val_full, _, x_val_full_emb = model_selection.train_test_split(\n",
    "        df_faces_val_full,\n",
    "        x_val_full_emb,\n",
    "        test_size=expected_val_full_size,\n",
    "        stratify=age_and_gender,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    \n",
    "# split off a hyper val from the val set\n",
    "age_and_gender = get_age_and_gender(df_faces_val_full)\n",
    "df_faces_val, df_faces_hyper_val, x_val_emb, x_hyper_val_emb = model_selection.train_test_split(\n",
    "    df_faces_val_full,\n",
    "    x_val_full_emb,\n",
    "    test_size=HYPER_VAL_SPLIT,\n",
    "    stratify=age_and_gender,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "del df_faces_val_full, x_val_full_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((996, 5), (996, 5), (1992, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faces_val.shape, df_faces_hyper_val.shape, df_faces_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((996, 10), (996, 10), (1992, 10))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_emb.shape, x_hyper_val_emb.shape, x_test_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_align(df, x_emb):\n",
    "    # df will have a fresh indes\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df is now sorted by what it will appear like when saved and tensorflow\n",
    "    # loads it with shuffle=False\n",
    "    df = df.sort_values(by=['gender'])\n",
    "    # reorganize x_emb based on the new ordering in df\n",
    "    x_emb = x_emb[df.index]\n",
    "    # df's index is reset because sort_values changed it\n",
    "    df = df.reset_index(drop=True)\n",
    "    # now, if we pass this df to symlink_df it will save based on gender\n",
    "    # and the index. if we load this using tf's image_dataset_from_directory\n",
    "    # x_emb will correspond properly\n",
    "    return df, x_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faces_val, x_val_emb = sort_and_align(df_faces_val, x_val_emb)\n",
    "df_faces_hyper_val, x_hyper_val_emb = sort_and_align(df_faces_hyper_val, x_hyper_val_emb)\n",
    "df_faces_test, x_test_emb = sort_and_align(df_faces_test, x_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_im_path(df, idx):\n",
    "    prefix = 'coarse_tilt_aligned_face'\n",
    "    uid = df['user_id'].loc[idx]\n",
    "    iname = df['original_image'].loc[idx]\n",
    "    fid = df['face_id'].loc[idx]\n",
    "    full_iname = f\"{prefix}.{fid}.{iname}\"\n",
    "    return os.path.join(DATA_F, \"faces\", uid, full_iname)\n",
    "\n",
    "def symlink_df(df, folder):\n",
    "    for i in notebook.tqdm(df.index):\n",
    "        src = os.path.abspath( get_im_path(df, i) )\n",
    "        gender = df['gender'].loc[i]\n",
    "        # get the file extension\n",
    "        ext = src.split('.')[-1]\n",
    "        dst_iname = f\"{i}.{ext}\"\n",
    "        dest = os.path.join(PROCESSED_DIR, folder, gender, dst_iname)\n",
    "        if os.symlink(src, dest, target_is_directory = False) != None:\n",
    "            raise ValueError(\"error creating symlink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_gender_groups = ['m', 'f']\n",
    "for f in ['val', 'hyper_val', 'test']:\n",
    "    fpath = os.path.join(PROCESSED_DIR, f)\n",
    "    os.makedirs(fpath, exist_ok=False)\n",
    "    for l in valid_gender_groups:\n",
    "        os.makedirs(os.path.join(fpath, l), exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16238f040054d55839c49d2b619ac11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=996.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "symlink_df(df_faces_val, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d34a4a858043d2be7993f3413bd175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=996.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "symlink_df(df_faces_hyper_val, \"hyper_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe08294766540539e99866b25461954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1992.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "symlink_df(df_faces_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faces_val.to_csv( os.path.join(PROCESSED_DIR, \"val.csv\"), index=False )\n",
    "df_faces_hyper_val.to_csv( os.path.join(PROCESSED_DIR, \"hyper_val.csv\"), index=False )\n",
    "df_faces_test.to_csv( os.path.join(PROCESSED_DIR, \"test.csv\"), index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_FULL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_train_full_emb\", \".npy\")\n",
    "X_VAL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_val_emb\", \".npy\")\n",
    "X_HYPER_VAL_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_hyper_val_emb\", \".npy\")\n",
    "X_TEST_EMB_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"x_test_emb\", \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper train is the same so it just gets saved\n",
    "np.save(\n",
    "    X_TRAIN_FULL_EMB_SAVEPATH,\n",
    "    x_train_full_emb,\n",
    ")\n",
    "\n",
    "# val/hyper_val/test are made on the fly\n",
    "np.save(\n",
    "    X_VAL_EMB_SAVEPATH,\n",
    "    x_val_emb,\n",
    ")\n",
    "\n",
    "np.save(\n",
    "    X_HYPER_VAL_EMB_SAVEPATH,\n",
    "    x_hyper_val_emb,\n",
    ")\n",
    "\n",
    "np.save(\n",
    "    X_TEST_EMB_SAVEPATH,\n",
    "    x_test_emb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

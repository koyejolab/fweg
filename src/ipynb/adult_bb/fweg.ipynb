{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "from utils.fweg import FWEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "BATCH_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"batch_size\"]\n",
    "EVAL_GROUPS = CONFIG['experiment_configs'][DATASET]['eval_groups']\n",
    "\n",
    "print(RANDOM_SEED)\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}')\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, DATASET, \".pkl\")\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"base\") # mt = model_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"train.csv\"))\n",
    "hyper_train_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"hyper_train.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"val.csv\"))\n",
    "# in this setting val = hyper_val. the separation is purely for consistency with\n",
    "# other experiments and using FWEG\n",
    "hyper_val_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"hyper_val.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"test.csv\"))\n",
    "\n",
    "# concat the two for train\n",
    "train_full_df = pd.concat([train_df, hyper_train_df])\n",
    "\n",
    "del train_df, hyper_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = train_full_df.drop([*EVAL_GROUPS, 'label'], axis=1).values\n",
    "y_train_full = train_full_df['label'].values\n",
    "\n",
    "x_val = val_df.drop([*EVAL_GROUPS, 'label'], axis=1).values\n",
    "y_val = val_df['label'].values\n",
    "\n",
    "x_hyper_val = hyper_val_df.drop([*EVAL_GROUPS, 'label'], axis=1).values\n",
    "y_hyper_val = hyper_val_df['label'].values\n",
    "\n",
    "x_test = test_df.drop([*EVAL_GROUPS, 'label'], axis=1).values\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_train_full.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_full = model.predict(x_train_full)\n",
    "preds_val = model.predict(x_val)\n",
    "preds_hyper_val = model.predict(x_hyper_val)\n",
    "preds_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basis_fns(\n",
    "    groups,\n",
    "    train_full_df,\n",
    "    val_df,\n",
    "    hyper_val_df,\n",
    "    test_df,\n",
    "    add_all\n",
    "    ):\n",
    "    \"\"\"\n",
    "    TODO:\n",
    "    \"\"\"\n",
    "    all_groups = [\n",
    "        [],\n",
    "        ['relationship_Husband', 'relationship_Wife'],\n",
    "        ['private_workforce', 'non_private_workforce'],\n",
    "        ['relationship_Husband', 'relationship_Wife', 'private_workforce', 'non_private_workforce']\n",
    "    ]\n",
    "    assert groups in all_groups\n",
    "    if len(groups) == 0:\n",
    "        assert add_all is True\n",
    "        \n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    if len(groups) == 0:\n",
    "        basis_train_full = pd.DataFrame(np.ones(len(train_full_df)), columns=[\"All\"])\n",
    "        basis_val = pd.DataFrame(np.ones(len(val_df)), columns=[\"All\"])\n",
    "        basis_hyper_val = pd.DataFrame(np.ones(len(hyper_val_df)), columns=[\"All\"])\n",
    "        basis_test = pd.DataFrame(np.ones(len(test_df)), columns=[\"All\"])\n",
    "    else:\n",
    "        basis_train_full = train_full_df[groups].copy()\n",
    "        basis_val = val_df[groups].copy()\n",
    "        basis_hyper_val = hyper_val_df[groups].copy()\n",
    "        basis_test = test_df[groups].copy()\n",
    "    \n",
    "        if add_all:\n",
    "            basis_train_full['All'] = 1.0\n",
    "            basis_val['All'] = 1.0\n",
    "            basis_hyper_val['All'] = 1.0\n",
    "            basis_test['All'] = 1.0\n",
    "        \n",
    "    return basis_train_full, basis_val, basis_hyper_val, basis_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_groups = val_df[EVAL_GROUPS]\n",
    "METRIC_VAL = utils.metrics.AdultBBMetric(\n",
    "    protected_groups['gender_Male'].values,\n",
    "    protected_groups['gender_Female'].values\n",
    ")\n",
    "\n",
    "protected_groups = hyper_val_df[EVAL_GROUPS]\n",
    "METRIC_HYPER_VAL = utils.metrics.AdultBBMetric(\n",
    "    protected_groups['gender_Male'].values,\n",
    "    protected_groups['gender_Female'].values\n",
    ")\n",
    "\n",
    "protected_groups = test_df[EVAL_GROUPS]\n",
    "METRIC_TEST = utils.metrics.AdultBBMetric(\n",
    "    protected_groups['gender_Male'].values,\n",
    "    protected_groups['gender_Female'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 2\n",
    "\n",
    "# must be one of:\n",
    "# []\n",
    "# ['relationship_Husband', 'relationship_Wife']\n",
    "# ['private_workforce', 'non_private_workforce'],\n",
    "# ['relationship_Husband', 'relationship_Wife', 'private_workforce', 'non_private_workforce']\n",
    "GROUPS = ['relationship_Husband', 'relationship_Wife', 'private_workforce', 'non_private_workforce']\n",
    "\n",
    "ADD_ALL = True\n",
    "EPSILON = 1e-4\n",
    "\n",
    "NUM_ITERS = 100\n",
    "\n",
    "USE_LINEAR_VAL_METRIC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_train_full, basis_val, basis_hyper_val, basis_test = get_basis_fns(\n",
    "    GROUPS,\n",
    "    train_full_df,\n",
    "    val_df,\n",
    "    hyper_val_df,\n",
    "    test_df,\n",
    "    ADD_ALL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val : 0.827: 100%|██████████| 100/100 [00:06<00:00, 16.65it/s]\n"
     ]
    }
   ],
   "source": [
    "fweg = utils.fweg.FWEG(\n",
    "    METRIC_VAL,\n",
    "    NUM_ITERS,\n",
    "    EPSILON,\n",
    "    CLASSES,\n",
    "    USE_LINEAR_VAL_METRIC,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "\n",
    "val_train_list, grad_norm_list, cond_list = fweg.fit(\n",
    "    preds_train_full,\n",
    "    y_train_full,\n",
    "    basis_train_full,\n",
    "    preds_val,\n",
    "    y_val,\n",
    "    basis_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val: 0.827409029882225\n"
     ]
    }
   ],
   "source": [
    "# apply to hyper val set\n",
    "preds_hyper_val_list, mval_hyper_val_list = fweg.predict(\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    basis_hyper_val,\n",
    "    deterministic=False,\n",
    "    metric=METRIC_HYPER_VAL,\n",
    ")\n",
    "\n",
    "# we check the latter half for better convergence estimates\n",
    "start = len(mval_hyper_val_list)//2\n",
    "best_idx = start + np.argmax(mval_hyper_val_list[start:])\n",
    "print(f\"Hyper Val: {mval_hyper_val_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.8229357961064586\n"
     ]
    }
   ],
   "source": [
    "# apply to test set\n",
    "preds_test_list, mval_test_list = fweg.predict(\n",
    "    preds_test,\n",
    "    y_test,\n",
    "    basis_test,\n",
    "    deterministic=False,\n",
    "    metric=METRIC_TEST,\n",
    ")\n",
    "print(f\"Test: {mval_test_list[best_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file exists, appending to it...\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "savepath = os.path.join(RESULTS_DIR, f\"results_{DATASET}.csv\")\n",
    "saver = utils.record.Results_Recorder(savepath, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = 2\n",
    "NUM_ITERS = 100\n",
    "\n",
    "groups_list = [\n",
    "#     [],\n",
    "#     ['relationship_Husband', 'relationship_Wife'],\n",
    "#     ['private_workforce', 'non_private_workforce'],\n",
    "    ['relationship_Husband', 'relationship_Wife', 'private_workforce', 'non_private_workforce']\n",
    "]\n",
    "groups_descr_list = [\n",
    "#     \"single_group\",\n",
    "#     \"relationship_Husband, relationship_Wife\",\n",
    "#     'private_workforce, non_private_workforce',\n",
    "    'relationship_Husband, relationship_Wife, private_workforce, non_private_workforce'\n",
    "]\n",
    "add_all_list = [True]\n",
    "epsilon_list = [0.0001, 0.001, 0.01, 0.1]\n",
    "use_linear_val_metric_list = [False]\n",
    "\n",
    "# this fills in most of the arguments for our basis function creator\n",
    "# it is missing the `groups` arg and `add_all`. FWEG_Hyperparameter_Search\n",
    "# is given basis_fn_generator and will fill these in as it iterates over\n",
    "# the hyperparameters.\n",
    "basis_fn_generator = functools.partial(\n",
    "    get_basis_fns,\n",
    "    train_full_df = train_full_df,\n",
    "    val_df = val_df,\n",
    "    hyper_val_df = hyper_val_df,\n",
    "    test_df = test_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "best hyper val: 0.8274, test: 0.8229: 100%|██████████| 4/4 [00:22<00:00,  5.72s/it]\n"
     ]
    }
   ],
   "source": [
    "fweg_hp_s = utils.fweg.FWEG_Hyperparameter_Search(\n",
    "    saver,\n",
    "    CLASSES,\n",
    "    NUM_ITERS,\n",
    "    METRIC_VAL,\n",
    "    basis_fn_generator,\n",
    "    groups_list,\n",
    "    groups_descr_list,\n",
    "    add_all_list,\n",
    "    epsilon_list,\n",
    "    use_linear_val_metric_list,\n",
    "    RANDOM_SEED,\n",
    "    # G-mean black-box metric benefits from more convergence-sensitive\n",
    "    # pickings of the best hyperparameters\n",
    "    use_convergence=True\n",
    ")\n",
    "\n",
    "(best_groups, best_add_all, best_epsilon, best_use_linear_val_metric) = fweg_hp_s.search(\n",
    "    preds_train_full,\n",
    "    y_train_full,\n",
    "    preds_val,\n",
    "    y_val,\n",
    "    preds_hyper_val,\n",
    "    y_hyper_val,\n",
    "    preds_test,\n",
    "    y_test,\n",
    "    metric_hyper_val=METRIC_HYPER_VAL,\n",
    "    metric_test=METRIC_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

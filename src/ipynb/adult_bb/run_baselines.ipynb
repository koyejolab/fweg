{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "import utils.papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "EVAL_GROUPS: ['gender_Male', 'gender_Female']\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "GROUPS = CONFIG['experiment_configs']['adult_bb']['groups']\n",
    "EVAL_GROUPS = CONFIG['experiment_configs']['adult_bb']['eval_groups']\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(RANDOM_SEED)\n",
    "print(f\"EVAL_GROUPS: {EVAL_GROUPS}\")\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/adult_bb/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/adult_bb/rs={RANDOM_SEED}')\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"adult_bb\", \".pkl\", g=GROUPS, eg=EVAL_GROUPS)\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_bb\", \".h5\", mt=\"base\") # mt = model_type\n",
    "\n",
    "# models saved here\n",
    "if not os.path.exists(BASE_MODEL_SAVEPATH):\n",
    "    print(f\"warning: model has not been done for rs={RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = None\n",
    "# load processed data. we pass groups = [] because processing is done per group choice\n",
    "# and we can use any\n",
    "with open(PROCESSED_SAVEPATH, 'rb') as f:\n",
    "    dat = pickle.load(f)\n",
    "\n",
    "x_train = dat['x_train']\n",
    "y_train = dat['y_train']\n",
    "\n",
    "x_hyper_train = dat['x_hyper_train']\n",
    "y_hyper_train = dat['y_hyper_train']\n",
    "\n",
    "x_val = dat['x_val']\n",
    "y_val = dat['y_val']\n",
    "\n",
    "x_test = dat['x_test']\n",
    "y_test = dat['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_hyper_train = tf.keras.utils.to_categorical(y_hyper_train)\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_train.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload save weights, in case being run out-of-order\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a \"train\" and \"test\" on the valid set\n",
    "x_val_train, x_val_test, y_val_train, y_val_test = model_selection.train_test_split(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    test_size=0.33,\n",
    "    stratify=y_val,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to save the best model by validation loss\n",
    "FT_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult\", \".h5\", mt=\"ft\")\n",
    "\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=FT_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.3152 - accuracy: 0.8438\n",
      "Epoch 00001: val_loss improved from inf to 0.30103, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3067 - accuracy: 0.8495 - val_loss: 0.3010 - val_accuracy: 0.8699\n",
      "Epoch 2/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3009 - accuracy: 0.8538\n",
      "Epoch 00002: val_loss improved from 0.30103 to 0.30086, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3065 - accuracy: 0.8505 - val_loss: 0.3009 - val_accuracy: 0.8680\n",
      "Epoch 3/100\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.2941 - accuracy: 0.8530\n",
      "Epoch 00003: val_loss did not improve from 0.30086\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8514 - val_loss: 0.3018 - val_accuracy: 0.8680\n",
      "Epoch 4/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3041 - accuracy: 0.8594\n",
      "Epoch 00004: val_loss did not improve from 0.30086\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8569 - val_loss: 0.3009 - val_accuracy: 0.8680\n",
      "Epoch 5/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3071 - accuracy: 0.8500\n",
      "Epoch 00005: val_loss improved from 0.30086 to 0.30070, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8532 - val_loss: 0.3007 - val_accuracy: 0.8643\n",
      "Epoch 6/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3096 - accuracy: 0.8521\n",
      "Epoch 00006: val_loss improved from 0.30070 to 0.30067, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8505 - val_loss: 0.3007 - val_accuracy: 0.8643\n",
      "Epoch 7/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3056 - accuracy: 0.8594\n",
      "Epoch 00007: val_loss improved from 0.30067 to 0.30063, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8550 - val_loss: 0.3006 - val_accuracy: 0.8643\n",
      "Epoch 8/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2981 - accuracy: 0.8556\n",
      "Epoch 00008: val_loss improved from 0.30063 to 0.30035, saving model to ../../../models/adult_bb/rs=55/adult_mt=ft.h5\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.8560 - val_loss: 0.3003 - val_accuracy: 0.8680\n",
      "Epoch 9/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3055 - accuracy: 0.8460\n",
      "Epoch 00009: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8477 - val_loss: 0.3005 - val_accuracy: 0.8643\n",
      "Epoch 10/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.2983 - accuracy: 0.8516\n",
      "Epoch 00010: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8532 - val_loss: 0.3005 - val_accuracy: 0.8643\n",
      "Epoch 11/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3024 - accuracy: 0.8538\n",
      "Epoch 00011: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8550 - val_loss: 0.3005 - val_accuracy: 0.8643\n",
      "Epoch 12/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3015 - accuracy: 0.8531\n",
      "Epoch 00012: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8532 - val_loss: 0.3006 - val_accuracy: 0.8643\n",
      "Epoch 13/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3089 - accuracy: 0.8510\n",
      "Epoch 00013: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8550 - val_loss: 0.3008 - val_accuracy: 0.8643\n",
      "Epoch 14/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3058 - accuracy: 0.8604\n",
      "Epoch 00014: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8587 - val_loss: 0.3006 - val_accuracy: 0.8643\n",
      "Epoch 15/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3019 - accuracy: 0.8573\n",
      "Epoch 00015: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8550 - val_loss: 0.3007 - val_accuracy: 0.8643\n",
      "Epoch 16/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3130 - accuracy: 0.8491\n",
      "Epoch 00016: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8578 - val_loss: 0.3004 - val_accuracy: 0.8680\n",
      "Epoch 17/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3012 - accuracy: 0.8521\n",
      "Epoch 00017: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8560 - val_loss: 0.3006 - val_accuracy: 0.8662\n",
      "Epoch 18/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3017 - accuracy: 0.8625\n",
      "Epoch 00018: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8596 - val_loss: 0.3011 - val_accuracy: 0.8643\n",
      "Epoch 19/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2900 - accuracy: 0.8696\n",
      "Epoch 00019: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8587 - val_loss: 0.3008 - val_accuracy: 0.8643\n",
      "Epoch 20/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3137 - accuracy: 0.8531\n",
      "Epoch 00020: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8596 - val_loss: 0.3013 - val_accuracy: 0.8662\n",
      "Epoch 21/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2989 - accuracy: 0.8631\n",
      "Epoch 00021: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8596 - val_loss: 0.3016 - val_accuracy: 0.8662\n",
      "Epoch 22/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.2995 - accuracy: 0.8627\n",
      "Epoch 00022: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8587 - val_loss: 0.3010 - val_accuracy: 0.8643\n",
      "Epoch 23/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2992 - accuracy: 0.8635\n",
      "Epoch 00023: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8615 - val_loss: 0.3008 - val_accuracy: 0.8643\n",
      "Epoch 24/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2925 - accuracy: 0.8567\n",
      "Epoch 00024: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8578 - val_loss: 0.3006 - val_accuracy: 0.8680\n",
      "Epoch 25/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3021 - accuracy: 0.8567\n",
      "Epoch 00025: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8587 - val_loss: 0.3007 - val_accuracy: 0.8680\n",
      "Epoch 26/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2960 - accuracy: 0.8642\n",
      "Epoch 00026: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8615 - val_loss: 0.3005 - val_accuracy: 0.8680\n",
      "Epoch 27/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2907 - accuracy: 0.8646\n",
      "Epoch 00027: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8578 - val_loss: 0.3010 - val_accuracy: 0.8662\n",
      "Epoch 28/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3004 - accuracy: 0.8594\n",
      "Epoch 00028: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8606 - val_loss: 0.3009 - val_accuracy: 0.8662\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2954 - accuracy: 0.8653\n",
      "Epoch 00029: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8606 - val_loss: 0.3014 - val_accuracy: 0.8662\n",
      "Epoch 30/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8573\n",
      "Epoch 00030: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8606 - val_loss: 0.3014 - val_accuracy: 0.8662\n",
      "Epoch 31/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2992 - accuracy: 0.8656\n",
      "Epoch 00031: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8606 - val_loss: 0.3020 - val_accuracy: 0.8662\n",
      "Epoch 32/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2997 - accuracy: 0.8567\n",
      "Epoch 00032: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8606 - val_loss: 0.3015 - val_accuracy: 0.8643\n",
      "Epoch 33/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3024 - accuracy: 0.8578\n",
      "Epoch 00033: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8606 - val_loss: 0.3014 - val_accuracy: 0.8643\n",
      "Epoch 34/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2959 - accuracy: 0.8610\n",
      "Epoch 00034: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8606 - val_loss: 0.3017 - val_accuracy: 0.8662\n",
      "Epoch 35/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3018 - accuracy: 0.8650\n",
      "Epoch 00035: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8615 - val_loss: 0.3011 - val_accuracy: 0.8643\n",
      "Epoch 36/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2948 - accuracy: 0.8621\n",
      "Epoch 00036: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8615 - val_loss: 0.3013 - val_accuracy: 0.8643\n",
      "Epoch 37/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2915 - accuracy: 0.8664\n",
      "Epoch 00037: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8633 - val_loss: 0.3011 - val_accuracy: 0.8680\n",
      "Epoch 38/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2948 - accuracy: 0.8653\n",
      "Epoch 00038: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8633 - val_loss: 0.3012 - val_accuracy: 0.8643\n",
      "Epoch 39/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3025 - accuracy: 0.8621\n",
      "Epoch 00039: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8624 - val_loss: 0.3012 - val_accuracy: 0.8662\n",
      "Epoch 40/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2962 - accuracy: 0.8642\n",
      "Epoch 00040: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8651 - val_loss: 0.3014 - val_accuracy: 0.8662\n",
      "Epoch 41/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3026 - accuracy: 0.8675\n",
      "Epoch 00041: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8642 - val_loss: 0.3014 - val_accuracy: 0.8662\n",
      "Epoch 42/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2926 - accuracy: 0.8685\n",
      "Epoch 00042: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8651 - val_loss: 0.3015 - val_accuracy: 0.8662\n",
      "Epoch 43/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2931 - accuracy: 0.8698\n",
      "Epoch 00043: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8642 - val_loss: 0.3020 - val_accuracy: 0.8662\n",
      "Epoch 44/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3008 - accuracy: 0.8638\n",
      "Epoch 00044: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8624 - val_loss: 0.3030 - val_accuracy: 0.8643\n",
      "Epoch 45/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3044 - accuracy: 0.8653\n",
      "Epoch 00045: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8624 - val_loss: 0.3021 - val_accuracy: 0.8680\n",
      "Epoch 46/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3009 - accuracy: 0.8661\n",
      "Epoch 00046: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8642 - val_loss: 0.3018 - val_accuracy: 0.8662\n",
      "Epoch 47/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2914 - accuracy: 0.8664\n",
      "Epoch 00047: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8624 - val_loss: 0.3029 - val_accuracy: 0.8662\n",
      "Epoch 48/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3078 - accuracy: 0.8588\n",
      "Epoch 00048: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8624 - val_loss: 0.3025 - val_accuracy: 0.8699\n",
      "Epoch 49/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3076 - accuracy: 0.8604\n",
      "Epoch 00049: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8633 - val_loss: 0.3023 - val_accuracy: 0.8699\n",
      "Epoch 50/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3011 - accuracy: 0.8625\n",
      "Epoch 00050: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8624 - val_loss: 0.3021 - val_accuracy: 0.8662\n",
      "Epoch 51/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3054 - accuracy: 0.8631\n",
      "Epoch 00051: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8661 - val_loss: 0.3026 - val_accuracy: 0.8699\n",
      "Epoch 52/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3015 - accuracy: 0.8646\n",
      "Epoch 00052: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8642 - val_loss: 0.3024 - val_accuracy: 0.8680\n",
      "Epoch 53/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2982 - accuracy: 0.8675\n",
      "Epoch 00053: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8661 - val_loss: 0.3025 - val_accuracy: 0.8699\n",
      "Epoch 54/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2998 - accuracy: 0.8664\n",
      "Epoch 00054: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8661 - val_loss: 0.3025 - val_accuracy: 0.8680\n",
      "Epoch 55/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3041 - accuracy: 0.8616\n",
      "Epoch 00055: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8651 - val_loss: 0.3028 - val_accuracy: 0.8699\n",
      "Epoch 56/100\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.2920 - accuracy: 0.8737\n",
      "Epoch 00056: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8651 - val_loss: 0.3025 - val_accuracy: 0.8662\n",
      "Epoch 57/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2983 - accuracy: 0.8685\n",
      "Epoch 00057: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8679 - val_loss: 0.3031 - val_accuracy: 0.8680\n",
      "Epoch 58/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3048 - accuracy: 0.8599\n",
      "Epoch 00058: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8651 - val_loss: 0.3028 - val_accuracy: 0.8662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2957 - accuracy: 0.8675\n",
      "Epoch 00059: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8661 - val_loss: 0.3028 - val_accuracy: 0.8662\n",
      "Epoch 60/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2990 - accuracy: 0.8696\n",
      "Epoch 00060: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8661 - val_loss: 0.3028 - val_accuracy: 0.8662\n",
      "Epoch 61/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2983 - accuracy: 0.8675\n",
      "Epoch 00061: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8670 - val_loss: 0.3028 - val_accuracy: 0.8662\n",
      "Epoch 62/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2916 - accuracy: 0.8677\n",
      "Epoch 00062: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8661 - val_loss: 0.3028 - val_accuracy: 0.8662\n",
      "Epoch 63/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3002 - accuracy: 0.8683\n",
      "Epoch 00063: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8670 - val_loss: 0.3029 - val_accuracy: 0.8662\n",
      "Epoch 64/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3022 - accuracy: 0.8642\n",
      "Epoch 00064: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.8661 - val_loss: 0.3033 - val_accuracy: 0.8662\n",
      "Epoch 65/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3082 - accuracy: 0.8588\n",
      "Epoch 00065: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8670 - val_loss: 0.3033 - val_accuracy: 0.8662\n",
      "Epoch 66/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3043 - accuracy: 0.8675\n",
      "Epoch 00066: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8670 - val_loss: 0.3031 - val_accuracy: 0.8662\n",
      "Epoch 67/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2881 - accuracy: 0.8707\n",
      "Epoch 00067: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8670 - val_loss: 0.3032 - val_accuracy: 0.8662\n",
      "Epoch 68/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2968 - accuracy: 0.8696\n",
      "Epoch 00068: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8670 - val_loss: 0.3030 - val_accuracy: 0.8643\n",
      "Epoch 69/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3093 - accuracy: 0.8627\n",
      "Epoch 00069: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8679 - val_loss: 0.3036 - val_accuracy: 0.8662\n",
      "Epoch 70/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.2994 - accuracy: 0.8627\n",
      "Epoch 00070: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8661 - val_loss: 0.3033 - val_accuracy: 0.8662\n",
      "Epoch 71/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.2898 - accuracy: 0.8739\n",
      "Epoch 00071: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8679 - val_loss: 0.3034 - val_accuracy: 0.8662\n",
      "Epoch 72/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2987 - accuracy: 0.8642\n",
      "Epoch 00072: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8661 - val_loss: 0.3035 - val_accuracy: 0.8662\n",
      "Epoch 73/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.2873 - accuracy: 0.8739\n",
      "Epoch 00073: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8670 - val_loss: 0.3036 - val_accuracy: 0.8662\n",
      "Epoch 74/100\n",
      "21/35 [=================>............] - ETA: 0s - loss: 0.3027 - accuracy: 0.8601\n",
      "Epoch 00074: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8670 - val_loss: 0.3036 - val_accuracy: 0.8662\n",
      "Epoch 75/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2867 - accuracy: 0.8687\n",
      "Epoch 00075: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8661 - val_loss: 0.3043 - val_accuracy: 0.8643\n",
      "Epoch 76/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2977 - accuracy: 0.8667\n",
      "Epoch 00076: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8670 - val_loss: 0.3040 - val_accuracy: 0.8662\n",
      "Epoch 77/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3068 - accuracy: 0.8631\n",
      "Epoch 00077: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8688 - val_loss: 0.3038 - val_accuracy: 0.8643\n",
      "Epoch 78/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3024 - accuracy: 0.8627\n",
      "Epoch 00078: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8688 - val_loss: 0.3038 - val_accuracy: 0.8643\n",
      "Epoch 79/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2875 - accuracy: 0.8707\n",
      "Epoch 00079: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8679 - val_loss: 0.3046 - val_accuracy: 0.8625\n",
      "Epoch 80/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3005 - accuracy: 0.8653\n",
      "Epoch 00080: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8670 - val_loss: 0.3044 - val_accuracy: 0.8625\n",
      "Epoch 81/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3051 - accuracy: 0.8685\n",
      "Epoch 00081: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.8688 - val_loss: 0.3041 - val_accuracy: 0.8643\n",
      "Epoch 82/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3083 - accuracy: 0.8610\n",
      "Epoch 00082: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8697 - val_loss: 0.3041 - val_accuracy: 0.8643\n",
      "Epoch 83/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2938 - accuracy: 0.8728\n",
      "Epoch 00083: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8688 - val_loss: 0.3038 - val_accuracy: 0.8606\n",
      "Epoch 84/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2929 - accuracy: 0.8740\n",
      "Epoch 00084: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8697 - val_loss: 0.3040 - val_accuracy: 0.8643\n",
      "Epoch 85/100\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2974 - accuracy: 0.8667\n",
      "Epoch 00085: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8688 - val_loss: 0.3041 - val_accuracy: 0.8643\n",
      "Epoch 86/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2901 - accuracy: 0.8718\n",
      "Epoch 00086: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8688 - val_loss: 0.3047 - val_accuracy: 0.8606\n",
      "Epoch 87/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3090 - accuracy: 0.8621\n",
      "Epoch 00087: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8697 - val_loss: 0.3050 - val_accuracy: 0.8625\n",
      "Epoch 88/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3007 - accuracy: 0.8631\n",
      "Epoch 00088: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8679 - val_loss: 0.3048 - val_accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3044 - accuracy: 0.8653\n",
      "Epoch 00089: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8688 - val_loss: 0.3044 - val_accuracy: 0.8606\n",
      "Epoch 90/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2982 - accuracy: 0.8642\n",
      "Epoch 00090: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8688 - val_loss: 0.3047 - val_accuracy: 0.8625\n",
      "Epoch 91/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2935 - accuracy: 0.8696\n",
      "Epoch 00091: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8688 - val_loss: 0.3048 - val_accuracy: 0.8606\n",
      "Epoch 92/100\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.2766 - accuracy: 0.8737\n",
      "Epoch 00092: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8697 - val_loss: 0.3051 - val_accuracy: 0.8625\n",
      "Epoch 93/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2956 - accuracy: 0.8675\n",
      "Epoch 00093: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8661 - val_loss: 0.3057 - val_accuracy: 0.8606\n",
      "Epoch 94/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3024 - accuracy: 0.8642\n",
      "Epoch 00094: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8651 - val_loss: 0.3058 - val_accuracy: 0.8606\n",
      "Epoch 95/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2965 - accuracy: 0.8675\n",
      "Epoch 00095: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8651 - val_loss: 0.3053 - val_accuracy: 0.8606\n",
      "Epoch 96/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3039 - accuracy: 0.8610\n",
      "Epoch 00096: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8661 - val_loss: 0.3051 - val_accuracy: 0.8606\n",
      "Epoch 97/100\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3033 - accuracy: 0.8650\n",
      "Epoch 00097: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8679 - val_loss: 0.3047 - val_accuracy: 0.8643\n",
      "Epoch 98/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2958 - accuracy: 0.8696\n",
      "Epoch 00098: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8688 - val_loss: 0.3047 - val_accuracy: 0.8643\n",
      "Epoch 99/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2971 - accuracy: 0.8707\n",
      "Epoch 00099: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8688 - val_loss: 0.3048 - val_accuracy: 0.8643\n",
      "Epoch 100/100\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2895 - accuracy: 0.8718\n",
      "Epoch 00100: val_loss did not improve from 0.30035\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8688 - val_loss: 0.3048 - val_accuracy: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6f83159dd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_val_train,\n",
    "    y_val_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_val_test, y_val_test),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: Forward Correct\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1609.03683.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload trained weights\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full = np.concatenate([x_train, x_hyper_train])\n",
    "y_train_full = np.concatenate([y_train, y_hyper_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T[i,j] means the probabilty that class i is flipped to class j.\n",
    "T_hat = utils.papers.forward_correct_est_T(\n",
    "    model,\n",
    "    x_train_full,\n",
    "    nc=2,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  ],\n",
       "       [0.04, 0.96]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(T_hat, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = utils.papers.make_forward_correct_loss(T_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to save the best model by validation loss\n",
    "FC_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult\", \".h5\", mt=\"fc\")\n",
    "\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=FC_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_hyper_train, y_hyper_train),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 3: Learn to Weigh Examples\n",
    "Paper: https://arxiv.org/pdf/1803.09050.pdf\n",
    "\n",
    "This is a type of meta-learning, which doesn't quite work with the keras API. We will need to manually implement the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction.NONE means the cross entropy is computed per entry in the batch\n",
    "# but is not aggregated. Traditional cross entropy will average the results.\n",
    "ce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "LRW_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_bb\", \".h5\", mt=\"lrw\")\n",
    "\n",
    "total_batches = len(x_train) // BATCH_SIZE \n",
    "if total_batches * BATCH_SIZE < len(x_train):\n",
    "    # this usually happens as // operator rounds down\n",
    "    total_batches += 1\n",
    "    \n",
    "# custom train loop\n",
    "for epoch in range(epochs):\n",
    "    # implements a train loop\n",
    "    print(f\"Epoch {epoch}:\\n----------\")\n",
    "    \n",
    "    loss_sum = 0\n",
    "    for i in tqdm(range(total_batches)):\n",
    "        # grab the batch and labels\n",
    "        batch = x_train[i * BATCH_SIZE : i * BATCH_SIZE + BATCH_SIZE]\n",
    "        labels = y_train[i * BATCH_SIZE : i * BATCH_SIZE + BATCH_SIZE]\n",
    "        \n",
    "        # most of the details are abstracted away in this function\n",
    "        loss = utils.papers.train_step(model, batch, labels, x_val, y_val, ce, optimizer)\n",
    "        loss_sum += loss\n",
    "\n",
    "        # print ongoing avg loss\n",
    "        print(f\"Loss: {loss_sum / i}\", end='\\r')\n",
    "    \n",
    "    # compute validation accuracy\n",
    "    preds = utils.utils.compute_preds(\n",
    "        model,\n",
    "        x_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    val_acc = (np.argmax(preds, axis=1) == np.argwhere(y_val)[:,1]).mean()\n",
    "    loss_avg = loss_sum / total_batches\n",
    "    \n",
    "    print(f\"Val Acc: {val_acc}\")\n",
    "    print(f\"Val Loss: {loss_avg}\", end='\\n\\n')\n",
    "        \n",
    "    # implements save best logic\n",
    "    if loss_avg < best_loss:\n",
    "        best_loss = loss_avg\n",
    "        print(f\"Saving new best weights to {LRW_MODEL_SAVEPATH}\")\n",
    "        model.save_weights(\n",
    "            filepath=LRW_MODEL_SAVEPATH,\n",
    "            save_format=\"h5\",\n",
    "        )\n",
    "        last_best_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 4: Kernel Mean Matching\n",
    "\n",
    "Paper: https://papers.nips.cc/paper/2006/file/a2186aa7c086b46ad4e8bf81e2a3a19b-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-1000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6536e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6347e+06 -2.6405e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6340e+06 -2.6354e+06  2e+03  6e-04  4e-16\n",
      " 4: -2.6337e+06 -2.6343e+06  9e+02  2e-04  4e-16\n",
      " 5: -2.6337e+06 -2.6339e+06  3e+02  5e-05  4e-16\n",
      " 6: -2.6337e+06 -2.6337e+06  4e+01  9e-16  4e-16\n",
      " 7: -2.6337e+06 -2.6337e+06  2e+00  2e-16  4e-16\n",
      "Optimal solution found.\n",
      "(1000-2000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6529e+06  3e+04  1e-02  4e-16\n",
      " 2: -2.6349e+06 -2.6412e+06  1e+04  3e-03  4e-16\n",
      " 3: -2.6343e+06 -2.6361e+06  3e+03  9e-04  4e-16\n",
      " 4: -2.6339e+06 -2.6343e+06  8e+02  2e-04  4e-16\n",
      " 5: -2.6338e+06 -2.6339e+06  1e+02  2e-05  4e-16\n",
      " 6: -2.6338e+06 -2.6338e+06  3e+00  5e-07  4e-16\n",
      " 7: -2.6338e+06 -2.6338e+06  5e-02  7e-09  3e-16\n",
      "Optimal solution found.\n",
      "(2000-3000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6533e+06  3e+04  9e-03  3e-16\n",
      " 2: -2.6349e+06 -2.6397e+06  7e+03  2e-03  4e-16\n",
      " 3: -2.6346e+06 -2.6359e+06  2e+03  5e-04  4e-16\n",
      " 4: -2.6344e+06 -2.6348e+06  5e+02  7e-05  4e-16\n",
      " 5: -2.6344e+06 -2.6346e+06  2e+02  2e-05  4e-16\n",
      " 6: -2.6344e+06 -2.6345e+06  1e+01  4e-07  4e-16\n",
      " 7: -2.6345e+06 -2.6345e+06  3e-01  7e-09  5e-16\n",
      "Optimal solution found.\n",
      "(3000-4000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  6e-02  4e-16\n",
      " 1: -2.6355e+06 -2.6523e+06  3e+04  1e-02  3e-16\n",
      " 2: -2.6346e+06 -2.6404e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6334e+06 -2.6349e+06  3e+03  8e-04  4e-16\n",
      " 4: -2.6330e+06 -2.6332e+06  4e+02  8e-05  4e-16\n",
      " 5: -2.6329e+06 -2.6330e+06  8e+01  1e-05  4e-16\n",
      " 6: -2.6329e+06 -2.6329e+06  5e+00  6e-07  4e-16\n",
      " 7: -2.6329e+06 -2.6329e+06  1e-01  2e-08  5e-16\n",
      "Optimal solution found.\n",
      "(4000-5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6354e+06 -2.6526e+06  3e+04  1e-02  3e-16\n",
      " 2: -2.6346e+06 -2.6405e+06  1e+04  3e-03  4e-16\n",
      " 3: -2.6337e+06 -2.6354e+06  3e+03  8e-04  3e-16\n",
      " 4: -2.6333e+06 -2.6339e+06  1e+03  2e-04  4e-16\n",
      " 5: -2.6332e+06 -2.6333e+06  2e+02  2e-05  4e-16\n",
      " 6: -2.6332e+06 -2.6332e+06  4e+01  4e-06  4e-16\n",
      " 7: -2.6332e+06 -2.6332e+06  2e+00  8e-16  4e-16\n",
      "Optimal solution found.\n",
      "(5000-6000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6678e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6354e+06 -2.6526e+06  3e+04  1e-02  3e-16\n",
      " 2: -2.6345e+06 -2.6399e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6338e+06 -2.6353e+06  3e+03  7e-04  4e-16\n",
      " 4: -2.6336e+06 -2.6338e+06  5e+02  1e-04  4e-16\n",
      " 5: -2.6335e+06 -2.6335e+06  2e+01  3e-06  4e-16\n",
      " 6: -2.6335e+06 -2.6335e+06  3e-01  3e-08  4e-16\n",
      "Optimal solution found.\n",
      "(6000-7000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6674e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6356e+06 -2.6536e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6348e+06 -2.6407e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6339e+06 -2.6357e+06  4e+03  9e-04  4e-16\n",
      " 4: -2.6334e+06 -2.6339e+06  1e+03  2e-04  3e-16\n",
      " 5: -2.6332e+06 -2.6334e+06  3e+02  6e-05  4e-16\n",
      " 6: -2.6332e+06 -2.6332e+06  2e+01  4e-06  4e-16\n",
      " 7: -2.6332e+06 -2.6332e+06  4e-01  7e-08  4e-16\n",
      "Optimal solution found.\n",
      "(7000-8000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6680e+06  2e+05  7e-02  4e-16\n",
      " 1: -2.6355e+06 -2.6544e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6346e+06 -2.6408e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6341e+06 -2.6356e+06  2e+03  6e-04  3e-16\n",
      " 4: -2.6339e+06 -2.6343e+06  5e+02  4e-05  4e-16\n",
      " 5: -2.6339e+06 -2.6342e+06  3e+02  2e-05  3e-16\n",
      " 6: -2.6339e+06 -2.6341e+06  2e+02  1e-06  4e-16\n",
      " 7: -2.6340e+06 -2.6340e+06  3e+01  3e-08  4e-16\n",
      " 8: -2.6340e+06 -2.6340e+06  6e+00  4e-09  4e-16\n",
      " 9: -2.6340e+06 -2.6340e+06  4e-01  2e-10  4e-16\n",
      "Optimal solution found.\n",
      "(8000-9000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  7e-02  5e-16\n",
      " 1: -2.6354e+06 -2.6533e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6342e+06 -2.6408e+06  1e+04  4e-03  3e-16\n",
      " 3: -2.6330e+06 -2.6349e+06  5e+03  1e-03  4e-16\n",
      " 4: -2.6323e+06 -2.6333e+06  2e+03  5e-04  3e-16\n",
      " 5: -2.6320e+06 -2.6321e+06  3e+02  7e-05  4e-16\n",
      " 6: -2.6319e+06 -2.6319e+06  2e+01  3e-06  4e-16\n",
      " 7: -2.6319e+06 -2.6319e+06  7e-01  1e-07  4e-16\n",
      "Optimal solution found.\n",
      "(9000-10000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6525e+06  3e+04  1e-02  4e-16\n",
      " 2: -2.6347e+06 -2.6413e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6338e+06 -2.6356e+06  4e+03  1e-03  4e-16\n",
      " 4: -2.6333e+06 -2.6341e+06  1e+03  3e-04  4e-16\n",
      " 5: -2.6333e+06 -2.6333e+06  1e+02  2e-05  3e-16\n",
      " 6: -2.6333e+06 -2.6333e+06  9e+00  1e-06  4e-16\n",
      " 7: -2.6333e+06 -2.6333e+06  2e-01  3e-08  4e-16\n",
      "Optimal solution found.\n",
      "(10000-11000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6535e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6347e+06 -2.6403e+06  1e+04  3e-03  4e-16\n",
      " 3: -2.6340e+06 -2.6358e+06  3e+03  8e-04  3e-16\n",
      " 4: -2.6338e+06 -2.6342e+06  7e+02  2e-04  4e-16\n",
      " 5: -2.6337e+06 -2.6338e+06  1e+02  1e-05  4e-16\n",
      " 6: -2.6338e+06 -2.6338e+06  1e+01  1e-06  4e-16\n",
      " 7: -2.6338e+06 -2.6338e+06  7e-01  4e-16  4e-16\n",
      "Optimal solution found.\n",
      "(11000-12000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6678e+06  2e+05  7e-02  5e-16\n",
      " 1: -2.6356e+06 -2.6533e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6349e+06 -2.6425e+06  1e+04  4e-03  3e-16\n",
      " 3: -2.6338e+06 -2.6356e+06  3e+03  8e-04  3e-16\n",
      " 4: -2.6333e+06 -2.6342e+06  1e+03  2e-04  3e-16\n",
      " 5: -2.6334e+06 -2.6336e+06  2e+02  3e-05  3e-16\n",
      " 6: -2.6334e+06 -2.6334e+06  5e+01  7e-16  4e-16\n",
      " 7: -2.6334e+06 -2.6334e+06  5e+00  8e-16  4e-16\n",
      " 8: -2.6334e+06 -2.6334e+06  9e-02  1e-16  4e-16\n",
      "Optimal solution found.\n",
      "(12000-13000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6680e+06  2e+05  7e-02  4e-16\n",
      " 1: -2.6354e+06 -2.6544e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6343e+06 -2.6415e+06  1e+04  4e-03  3e-16\n",
      " 3: -2.6326e+06 -2.6344e+06  4e+03  1e-03  3e-16\n",
      " 4: -2.6319e+06 -2.6324e+06  1e+03  2e-04  4e-16\n",
      " 5: -2.6317e+06 -2.6318e+06  2e+02  2e-05  4e-16\n",
      " 6: -2.6317e+06 -2.6317e+06  1e+01  1e-06  4e-16\n",
      " 7: -2.6317e+06 -2.6317e+06  3e-01  4e-08  4e-16\n",
      "Optimal solution found.\n",
      "(13000-14000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6675e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6530e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6344e+06 -2.6408e+06  1e+04  4e-03  4e-16\n",
      " 3: -2.6332e+06 -2.6348e+06  4e+03  1e-03  4e-16\n",
      " 4: -2.6326e+06 -2.6332e+06  1e+03  4e-04  3e-16\n",
      " 5: -2.6323e+06 -2.6325e+06  4e+02  7e-05  3e-16\n",
      " 6: -2.6323e+06 -2.6323e+06  7e+01  1e-05  4e-16\n",
      " 7: -2.6323e+06 -2.6323e+06  5e+00  6e-07  4e-16\n",
      " 8: -2.6323e+06 -2.6323e+06  8e-02  8e-09  3e-16\n",
      "Optimal solution found.\n",
      "(14000-15000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  4e-16\n",
      " 1: -2.6355e+06 -2.6534e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6345e+06 -2.6405e+06  1e+04  2e-03  3e-16\n",
      " 3: -2.6339e+06 -2.6353e+06  2e+03  5e-04  3e-16\n",
      " 4: -2.6337e+06 -2.6343e+06  8e+02  1e-04  3e-16\n",
      " 5: -2.6337e+06 -2.6339e+06  3e+02  3e-05  4e-16\n",
      " 6: -2.6337e+06 -2.6338e+06  4e+01  3e-16  4e-16\n",
      " 7: -2.6337e+06 -2.6338e+06  9e+00  2e-17  3e-16\n",
      " 8: -2.6338e+06 -2.6338e+06  2e+00  9e-16  3e-16\n",
      "Optimal solution found.\n",
      "(15000-16000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6540e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6348e+06 -2.6398e+06  9e+03  2e-03  4e-16\n",
      " 3: -2.6341e+06 -2.6354e+06  2e+03  6e-04  4e-16\n",
      " 4: -2.6338e+06 -2.6341e+06  4e+02  8e-05  4e-16\n",
      " 5: -2.6338e+06 -2.6339e+06  8e+01  1e-05  4e-16\n",
      " 6: -2.6338e+06 -2.6338e+06  9e+00  1e-06  4e-16\n",
      " 7: -2.6338e+06 -2.6338e+06  2e-01  2e-08  4e-16\n",
      "Optimal solution found.\n",
      "(16000-17000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6533e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6345e+06 -2.6415e+06  1e+04  4e-03  3e-16\n",
      " 3: -2.6332e+06 -2.6348e+06  4e+03  1e-03  4e-16\n",
      " 4: -2.6325e+06 -2.6332e+06  1e+03  3e-04  4e-16\n",
      " 5: -2.6323e+06 -2.6324e+06  1e+02  2e-05  4e-16\n",
      " 6: -2.6323e+06 -2.6323e+06  3e+00  3e-07  4e-16\n",
      " 7: -2.6323e+06 -2.6323e+06  8e-02  7e-09  4e-16\n",
      "Optimal solution found.\n",
      "(17000-18000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6679e+06  2e+05  7e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6533e+06  4e+04  1e-02  4e-16\n",
      " 2: -2.6346e+06 -2.6410e+06  1e+04  3e-03  3e-16\n",
      " 3: -2.6338e+06 -2.6355e+06  3e+03  9e-04  3e-16\n",
      " 4: -2.6334e+06 -2.6337e+06  7e+02  2e-04  4e-16\n",
      " 5: -2.6333e+06 -2.6333e+06  5e+01  1e-05  4e-16\n",
      " 6: -2.6333e+06 -2.6333e+06  6e+00  1e-06  4e-16\n",
      " 7: -2.6333e+06 -2.6333e+06  1e-01  3e-08  4e-16\n",
      "Optimal solution found.\n",
      "(18000-19000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6676e+06  2e+05  6e-02  4e-16\n",
      " 1: -2.6356e+06 -2.6518e+06  3e+04  7e-03  4e-16\n",
      " 2: -2.6350e+06 -2.6393e+06  6e+03  2e-03  3e-16\n",
      " 3: -2.6347e+06 -2.6359e+06  2e+03  4e-04  4e-16\n",
      " 4: -2.6345e+06 -2.6347e+06  1e+02  1e-15  4e-16\n",
      " 5: -2.6346e+06 -2.6346e+06  5e+01  7e-17  3e-16\n",
      " 6: -2.6346e+06 -2.6346e+06  1e+01  9e-16  4e-16\n",
      " 7: -2.6346e+06 -2.6346e+06  4e-01  8e-16  4e-16\n",
      "Optimal solution found.\n",
      "(19000-20000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6677e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6518e+06  3e+04  8e-03  4e-16\n",
      " 2: -2.6348e+06 -2.6395e+06  8e+03  2e-03  4e-16\n",
      " 3: -2.6342e+06 -2.6356e+06  3e+03  6e-04  3e-16\n",
      " 4: -2.6338e+06 -2.6342e+06  5e+02  1e-04  4e-16\n",
      " 5: -2.6338e+06 -2.6339e+06  9e+01  6e-06  4e-16\n",
      " 6: -2.6338e+06 -2.6338e+06  9e+00  6e-07  4e-16\n",
      " 7: -2.6338e+06 -2.6338e+06  2e-01  8e-09  5e-16\n",
      "Optimal solution found.\n",
      "(20000-21000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6357e+06 -2.6678e+06  2e+05  6e-02  3e-16\n",
      " 1: -2.6355e+06 -2.6530e+06  4e+04  1e-02  3e-16\n",
      " 2: -2.6345e+06 -2.6421e+06  1e+04  4e-03  4e-16\n",
      " 3: -2.6330e+06 -2.6354e+06  5e+03  1e-03  4e-16\n",
      " 4: -2.6325e+06 -2.6333e+06  1e+03  3e-04  3e-16\n",
      " 5: -2.6324e+06 -2.6327e+06  4e+02  5e-05  3e-16\n",
      " 6: -2.6324e+06 -2.6325e+06  1e+02  8e-06  4e-16\n",
      " 7: -2.6324e+06 -2.6325e+06  2e+01  1e-06  4e-16\n",
      " 8: -2.6324e+06 -2.6324e+06  7e-01  2e-08  4e-16\n",
      "Optimal solution found.\n",
      "(21000-22000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.7507e+06 -1.7743e+06  1e+05  7e-02  3e-16\n",
      " 1: -1.7505e+06 -1.7630e+06  2e+04  1e-02  3e-16\n",
      " 2: -1.7496e+06 -1.7539e+06  8e+03  3e-03  3e-16\n",
      " 3: -1.7489e+06 -1.7503e+06  3e+03  1e-03  3e-16\n",
      " 4: -1.7487e+06 -1.7491e+06  7e+02  2e-04  3e-16\n",
      " 5: -1.7486e+06 -1.7487e+06  1e+02  3e-05  4e-16\n",
      " 6: -1.7486e+06 -1.7486e+06  5e+00  1e-06  4e-16\n",
      " 7: -1.7486e+06 -1.7486e+06  8e-02  2e-08  4e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# the KMM algorithm does not scale well as inputs grow\n",
    "# if we were to use the full train and test set, I don't even know\n",
    "# how long it would take. Instead, we bunch the train into groups (randomly)\n",
    "# of 1000 and apply KMM to the group and the full test set\n",
    "# we then stitch together the estimated betas for the full train set\n",
    "group_size = 1000\n",
    "# these are a random arangement of indices\n",
    "rand_inds = np.random.RandomState(seed=RANDOM_SEED).permutation( np.arange(len(x_train)) )\n",
    "# these are the betas but ordered with respect to x_train\n",
    "betas_ordered = np.zeros(len(x_train))\n",
    "\n",
    "start_i = 0\n",
    "end_i = start_i + group_size\n",
    "while start_i < len(x_train):\n",
    "    print(f\"({start_i}-{end_i})\")\n",
    "    \n",
    "    # grab the current group\n",
    "    inds = rand_inds[start_i : end_i]\n",
    "    \n",
    "    kmm = utils.papers.KMM()\n",
    "    # fit the group with the entire test data\n",
    "    betas = kmm.fit(x_train[inds], x_test)\n",
    "    # fill in betas_ordered at the indices in the current group\n",
    "    betas_ordered[inds] = betas.reshape(-1) # flatten\n",
    "    \n",
    "    start_i = end_i\n",
    "    end_i = start_i + group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save betas for later analysis, if any\n",
    "KMM_BETAS_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_kmm_betas\", \".npy\")\n",
    "np.save(\n",
    "    file = KMM_BETAS_SAVEPATH,\n",
    "    arr = betas_ordered,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fresh model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_train.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to save the best model by validation loss\n",
    "KMM_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_bb\", \".h5\", mt=\"kmm\")\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=KMM_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 5: Just Train on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fresh model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_train.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a \"train\" and \"test\" on the valid set\n",
    "x_val_train, x_val_test, y_val_train, y_val_test = model_selection.train_test_split(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    test_size=0.33,\n",
    "    stratify=y_val,\n",
    "    random_state=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to save the best model by validation loss\n",
    "JV_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_bb\", \".h5\", mt=\"jv\")\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=JV_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "669/682 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.7802\n",
      "Epoch 00001: val_loss improved from inf to 0.40212, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.4556 - accuracy: 0.7808 - val_loss: 0.4021 - val_accuracy: 0.8146\n",
      "Epoch 2/100\n",
      "670/682 [============================>.] - ETA: 0s - loss: 0.3735 - accuracy: 0.8309\n",
      "Epoch 00002: val_loss improved from 0.40212 to 0.37190, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3731 - accuracy: 0.8312 - val_loss: 0.3719 - val_accuracy: 0.8340\n",
      "Epoch 3/100\n",
      "667/682 [============================>.] - ETA: 0s - loss: 0.3520 - accuracy: 0.8408\n",
      "Epoch 00003: val_loss improved from 0.37190 to 0.35947, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3524 - accuracy: 0.8402 - val_loss: 0.3595 - val_accuracy: 0.8374\n",
      "Epoch 4/100\n",
      "677/682 [============================>.] - ETA: 0s - loss: 0.3416 - accuracy: 0.8448\n",
      "Epoch 00004: val_loss improved from 0.35947 to 0.35244, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.8443 - val_loss: 0.3524 - val_accuracy: 0.8379\n",
      "Epoch 5/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.8460\n",
      "Epoch 00005: val_loss improved from 0.35244 to 0.34742, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3359 - accuracy: 0.8463 - val_loss: 0.3474 - val_accuracy: 0.8397\n",
      "Epoch 6/100\n",
      "676/682 [============================>.] - ETA: 0s - loss: 0.3315 - accuracy: 0.8492\n",
      "Epoch 00006: val_loss improved from 0.34742 to 0.34404, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3314 - accuracy: 0.8492 - val_loss: 0.3440 - val_accuracy: 0.8399\n",
      "Epoch 7/100\n",
      "669/682 [============================>.] - ETA: 0s - loss: 0.3280 - accuracy: 0.8510\n",
      "Epoch 00007: val_loss improved from 0.34404 to 0.34126, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3282 - accuracy: 0.8507 - val_loss: 0.3413 - val_accuracy: 0.8412\n",
      "Epoch 8/100\n",
      "681/682 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8519\n",
      "Epoch 00008: val_loss improved from 0.34126 to 0.33932, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3255 - accuracy: 0.8520 - val_loss: 0.3393 - val_accuracy: 0.8425\n",
      "Epoch 9/100\n",
      "680/682 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8519\n",
      "Epoch 00009: val_loss improved from 0.33932 to 0.33758, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3235 - accuracy: 0.8521 - val_loss: 0.3376 - val_accuracy: 0.8436\n",
      "Epoch 10/100\n",
      "671/682 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8529\n",
      "Epoch 00010: val_loss improved from 0.33758 to 0.33621, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3218 - accuracy: 0.8528 - val_loss: 0.3362 - val_accuracy: 0.8439\n",
      "Epoch 11/100\n",
      "658/682 [===========================>..] - ETA: 0s - loss: 0.3205 - accuracy: 0.8530\n",
      "Epoch 00011: val_loss improved from 0.33621 to 0.33501, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3203 - accuracy: 0.8529 - val_loss: 0.3350 - val_accuracy: 0.8440\n",
      "Epoch 12/100\n",
      "662/682 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8536\n",
      "Epoch 00012: val_loss improved from 0.33501 to 0.33401, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3191 - accuracy: 0.8535 - val_loss: 0.3340 - val_accuracy: 0.8449\n",
      "Epoch 13/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.8539\n",
      "Epoch 00013: val_loss improved from 0.33401 to 0.33321, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3180 - accuracy: 0.8540 - val_loss: 0.3332 - val_accuracy: 0.8448\n",
      "Epoch 14/100\n",
      "679/682 [============================>.] - ETA: 0s - loss: 0.3170 - accuracy: 0.8542\n",
      "Epoch 00014: val_loss improved from 0.33321 to 0.33236, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3170 - accuracy: 0.8540 - val_loss: 0.3324 - val_accuracy: 0.8449\n",
      "Epoch 15/100\n",
      "679/682 [============================>.] - ETA: 0s - loss: 0.3161 - accuracy: 0.8536\n",
      "Epoch 00015: val_loss improved from 0.33236 to 0.33165, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3162 - accuracy: 0.8534 - val_loss: 0.3316 - val_accuracy: 0.8457\n",
      "Epoch 16/100\n",
      "656/682 [===========================>..] - ETA: 0s - loss: 0.3154 - accuracy: 0.8537\n",
      "Epoch 00016: val_loss improved from 0.33165 to 0.33133, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3155 - accuracy: 0.8540 - val_loss: 0.3313 - val_accuracy: 0.8465\n",
      "Epoch 17/100\n",
      "666/682 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.8543\n",
      "Epoch 00017: val_loss improved from 0.33133 to 0.33069, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3149 - accuracy: 0.8545 - val_loss: 0.3307 - val_accuracy: 0.8469\n",
      "Epoch 18/100\n",
      "657/682 [===========================>..] - ETA: 0s - loss: 0.3137 - accuracy: 0.8546\n",
      "Epoch 00018: val_loss improved from 0.33069 to 0.33021, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3143 - accuracy: 0.8545 - val_loss: 0.3302 - val_accuracy: 0.8464\n",
      "Epoch 19/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3137 - accuracy: 0.8548\n",
      "Epoch 00019: val_loss improved from 0.33021 to 0.32997, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3137 - accuracy: 0.8546 - val_loss: 0.3300 - val_accuracy: 0.8465\n",
      "Epoch 20/100\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8547\n",
      "Epoch 00020: val_loss improved from 0.32997 to 0.32942, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3132 - accuracy: 0.8547 - val_loss: 0.3294 - val_accuracy: 0.8481\n",
      "Epoch 21/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3129 - accuracy: 0.8555\n",
      "Epoch 00021: val_loss improved from 0.32942 to 0.32903, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3128 - accuracy: 0.8555 - val_loss: 0.3290 - val_accuracy: 0.8474\n",
      "Epoch 22/100\n",
      "676/682 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.8550\n",
      "Epoch 00022: val_loss improved from 0.32903 to 0.32872, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3123 - accuracy: 0.8550 - val_loss: 0.3287 - val_accuracy: 0.8472\n",
      "Epoch 23/100\n",
      "662/682 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8566\n",
      "Epoch 00023: val_loss improved from 0.32872 to 0.32836, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3119 - accuracy: 0.8563 - val_loss: 0.3284 - val_accuracy: 0.8481\n",
      "Epoch 24/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3123 - accuracy: 0.8568\n",
      "Epoch 00024: val_loss did not improve from 0.32836\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3115 - accuracy: 0.8574 - val_loss: 0.3285 - val_accuracy: 0.8483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "662/682 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.8567\n",
      "Epoch 00025: val_loss improved from 0.32836 to 0.32835, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3112 - accuracy: 0.8568 - val_loss: 0.3284 - val_accuracy: 0.8481\n",
      "Epoch 26/100\n",
      "664/682 [============================>.] - ETA: 0s - loss: 0.3113 - accuracy: 0.8561\n",
      "Epoch 00026: val_loss improved from 0.32835 to 0.32763, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3109 - accuracy: 0.8563 - val_loss: 0.3276 - val_accuracy: 0.8494\n",
      "Epoch 27/100\n",
      "654/682 [===========================>..] - ETA: 0s - loss: 0.3115 - accuracy: 0.8558\n",
      "Epoch 00027: val_loss improved from 0.32763 to 0.32744, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3106 - accuracy: 0.8563 - val_loss: 0.3274 - val_accuracy: 0.8491\n",
      "Epoch 28/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.8563\n",
      "Epoch 00028: val_loss improved from 0.32744 to 0.32720, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3104 - accuracy: 0.8564 - val_loss: 0.3272 - val_accuracy: 0.8497\n",
      "Epoch 29/100\n",
      "663/682 [============================>.] - ETA: 0s - loss: 0.3100 - accuracy: 0.8578\n",
      "Epoch 00029: val_loss improved from 0.32720 to 0.32712, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3100 - accuracy: 0.8576 - val_loss: 0.3271 - val_accuracy: 0.8496\n",
      "Epoch 30/100\n",
      "674/682 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8573\n",
      "Epoch 00030: val_loss improved from 0.32712 to 0.32689, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3099 - accuracy: 0.8571 - val_loss: 0.3269 - val_accuracy: 0.8492\n",
      "Epoch 31/100\n",
      "657/682 [===========================>..] - ETA: 0s - loss: 0.3101 - accuracy: 0.8571\n",
      "Epoch 00031: val_loss improved from 0.32689 to 0.32682, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3097 - accuracy: 0.8571 - val_loss: 0.3268 - val_accuracy: 0.8492\n",
      "Epoch 32/100\n",
      "667/682 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8569\n",
      "Epoch 00032: val_loss improved from 0.32682 to 0.32665, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3095 - accuracy: 0.8571 - val_loss: 0.3267 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3091 - accuracy: 0.8569\n",
      "Epoch 00033: val_loss improved from 0.32665 to 0.32656, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3092 - accuracy: 0.8571 - val_loss: 0.3266 - val_accuracy: 0.8490\n",
      "Epoch 34/100\n",
      "664/682 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.8582\n",
      "Epoch 00034: val_loss improved from 0.32656 to 0.32645, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3091 - accuracy: 0.8580 - val_loss: 0.3264 - val_accuracy: 0.8495\n",
      "Epoch 35/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8579\n",
      "Epoch 00035: val_loss improved from 0.32645 to 0.32618, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3089 - accuracy: 0.8576 - val_loss: 0.3262 - val_accuracy: 0.8499\n",
      "Epoch 36/100\n",
      "667/682 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8578\n",
      "Epoch 00036: val_loss improved from 0.32618 to 0.32611, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3088 - accuracy: 0.8579 - val_loss: 0.3261 - val_accuracy: 0.8492\n",
      "Epoch 37/100\n",
      "655/682 [===========================>..] - ETA: 0s - loss: 0.3086 - accuracy: 0.8584\n",
      "Epoch 00037: val_loss improved from 0.32611 to 0.32599, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3086 - accuracy: 0.8581 - val_loss: 0.3260 - val_accuracy: 0.8493\n",
      "Epoch 38/100\n",
      "673/682 [============================>.] - ETA: 0s - loss: 0.3085 - accuracy: 0.8586\n",
      "Epoch 00038: val_loss improved from 0.32599 to 0.32586, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3085 - accuracy: 0.8583 - val_loss: 0.3259 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.8578\n",
      "Epoch 00039: val_loss improved from 0.32586 to 0.32579, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3083 - accuracy: 0.8578 - val_loss: 0.3258 - val_accuracy: 0.8499\n",
      "Epoch 40/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3089 - accuracy: 0.8577\n",
      "Epoch 00040: val_loss improved from 0.32579 to 0.32566, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3081 - accuracy: 0.8580 - val_loss: 0.3257 - val_accuracy: 0.8496\n",
      "Epoch 41/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8578\n",
      "Epoch 00041: val_loss improved from 0.32566 to 0.32554, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3080 - accuracy: 0.8579 - val_loss: 0.3255 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "682/682 [==============================] - ETA: 0s - loss: 0.3079 - accuracy: 0.8585\n",
      "Epoch 00042: val_loss improved from 0.32554 to 0.32547, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3079 - accuracy: 0.8585 - val_loss: 0.3255 - val_accuracy: 0.8501\n",
      "Epoch 43/100\n",
      "681/682 [============================>.] - ETA: 0s - loss: 0.3076 - accuracy: 0.8589\n",
      "Epoch 00043: val_loss improved from 0.32547 to 0.32539, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3075 - accuracy: 0.8590 - val_loss: 0.3254 - val_accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "673/682 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.8583\n",
      "Epoch 00044: val_loss did not improve from 0.32539\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3076 - accuracy: 0.8583 - val_loss: 0.3259 - val_accuracy: 0.8502\n",
      "Epoch 45/100\n",
      "676/682 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.8585\n",
      "Epoch 00045: val_loss improved from 0.32539 to 0.32529, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3076 - accuracy: 0.8587 - val_loss: 0.3253 - val_accuracy: 0.8501\n",
      "Epoch 46/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3076 - accuracy: 0.8591\n",
      "Epoch 00046: val_loss improved from 0.32529 to 0.32516, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3074 - accuracy: 0.8592 - val_loss: 0.3252 - val_accuracy: 0.8505\n",
      "Epoch 47/100\n",
      "662/682 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8584\n",
      "Epoch 00047: val_loss did not improve from 0.32516\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3074 - accuracy: 0.8586 - val_loss: 0.3253 - val_accuracy: 0.8501\n",
      "Epoch 48/100\n",
      "666/682 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8579\n",
      "Epoch 00048: val_loss improved from 0.32516 to 0.32500, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3071 - accuracy: 0.8582 - val_loss: 0.3250 - val_accuracy: 0.8504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "675/682 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8589\n",
      "Epoch 00049: val_loss did not improve from 0.32500\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3072 - accuracy: 0.8590 - val_loss: 0.3251 - val_accuracy: 0.8506\n",
      "Epoch 50/100\n",
      "657/682 [===========================>..] - ETA: 0s - loss: 0.3060 - accuracy: 0.8590\n",
      "Epoch 00050: val_loss improved from 0.32500 to 0.32496, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3071 - accuracy: 0.8581 - val_loss: 0.3250 - val_accuracy: 0.8508\n",
      "Epoch 51/100\n",
      "655/682 [===========================>..] - ETA: 0s - loss: 0.3058 - accuracy: 0.8595\n",
      "Epoch 00051: val_loss improved from 0.32496 to 0.32481, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3070 - accuracy: 0.8587 - val_loss: 0.3248 - val_accuracy: 0.8506\n",
      "Epoch 52/100\n",
      "665/682 [============================>.] - ETA: 0s - loss: 0.3076 - accuracy: 0.8587\n",
      "Epoch 00052: val_loss did not improve from 0.32481\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3068 - accuracy: 0.8590 - val_loss: 0.3254 - val_accuracy: 0.8503\n",
      "Epoch 53/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 0.8584\n",
      "Epoch 00053: val_loss improved from 0.32481 to 0.32477, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3069 - accuracy: 0.8583 - val_loss: 0.3248 - val_accuracy: 0.8509\n",
      "Epoch 54/100\n",
      "663/682 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.8585\n",
      "Epoch 00054: val_loss improved from 0.32477 to 0.32469, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3068 - accuracy: 0.8591 - val_loss: 0.3247 - val_accuracy: 0.8505\n",
      "Epoch 55/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.8584\n",
      "Epoch 00055: val_loss did not improve from 0.32469\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3067 - accuracy: 0.8588 - val_loss: 0.3250 - val_accuracy: 0.8509\n",
      "Epoch 56/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3062 - accuracy: 0.8601\n",
      "Epoch 00056: val_loss did not improve from 0.32469\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3067 - accuracy: 0.8597 - val_loss: 0.3248 - val_accuracy: 0.8504\n",
      "Epoch 57/100\n",
      "663/682 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8591\n",
      "Epoch 00057: val_loss did not improve from 0.32469\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3065 - accuracy: 0.8597 - val_loss: 0.3248 - val_accuracy: 0.8505\n",
      "Epoch 58/100\n",
      "658/682 [===========================>..] - ETA: 0s - loss: 0.3068 - accuracy: 0.8592\n",
      "Epoch 00058: val_loss improved from 0.32469 to 0.32451, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3065 - accuracy: 0.8594 - val_loss: 0.3245 - val_accuracy: 0.8507\n",
      "Epoch 59/100\n",
      "654/682 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.8588\n",
      "Epoch 00059: val_loss did not improve from 0.32451\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3064 - accuracy: 0.8591 - val_loss: 0.3246 - val_accuracy: 0.8508\n",
      "Epoch 60/100\n",
      "665/682 [============================>.] - ETA: 0s - loss: 0.3062 - accuracy: 0.8596\n",
      "Epoch 00060: val_loss improved from 0.32451 to 0.32446, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3064 - accuracy: 0.8596 - val_loss: 0.3245 - val_accuracy: 0.8501\n",
      "Epoch 61/100\n",
      "679/682 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8599\n",
      "Epoch 00061: val_loss did not improve from 0.32446\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3063 - accuracy: 0.8598 - val_loss: 0.3245 - val_accuracy: 0.8506\n",
      "Epoch 62/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8593\n",
      "Epoch 00062: val_loss improved from 0.32446 to 0.32439, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3063 - accuracy: 0.8599 - val_loss: 0.3244 - val_accuracy: 0.8508\n",
      "Epoch 63/100\n",
      "667/682 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8596\n",
      "Epoch 00063: val_loss improved from 0.32439 to 0.32435, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3063 - accuracy: 0.8593 - val_loss: 0.3244 - val_accuracy: 0.8510\n",
      "Epoch 64/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8599\n",
      "Epoch 00064: val_loss improved from 0.32435 to 0.32431, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3062 - accuracy: 0.8595 - val_loss: 0.3243 - val_accuracy: 0.8508\n",
      "Epoch 65/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3067 - accuracy: 0.8590\n",
      "Epoch 00065: val_loss improved from 0.32431 to 0.32430, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3062 - accuracy: 0.8591 - val_loss: 0.3243 - val_accuracy: 0.8512\n",
      "Epoch 66/100\n",
      "678/682 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8598\n",
      "Epoch 00066: val_loss did not improve from 0.32430\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3061 - accuracy: 0.8598 - val_loss: 0.3243 - val_accuracy: 0.8509\n",
      "Epoch 67/100\n",
      "675/682 [============================>.] - ETA: 0s - loss: 0.3065 - accuracy: 0.8594\n",
      "Epoch 00067: val_loss improved from 0.32430 to 0.32425, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3060 - accuracy: 0.8596 - val_loss: 0.3243 - val_accuracy: 0.8512\n",
      "Epoch 68/100\n",
      "679/682 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8595\n",
      "Epoch 00068: val_loss did not improve from 0.32425\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3060 - accuracy: 0.8598 - val_loss: 0.3247 - val_accuracy: 0.8510\n",
      "Epoch 69/100\n",
      "679/682 [============================>.] - ETA: 0s - loss: 0.3058 - accuracy: 0.8600\n",
      "Epoch 00069: val_loss improved from 0.32425 to 0.32424, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3059 - accuracy: 0.8597 - val_loss: 0.3242 - val_accuracy: 0.8510\n",
      "Epoch 70/100\n",
      "658/682 [===========================>..] - ETA: 0s - loss: 0.3041 - accuracy: 0.8611\n",
      "Epoch 00070: val_loss improved from 0.32424 to 0.32421, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3060 - accuracy: 0.8597 - val_loss: 0.3242 - val_accuracy: 0.8509\n",
      "Epoch 71/100\n",
      "667/682 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8602\n",
      "Epoch 00071: val_loss did not improve from 0.32421\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3059 - accuracy: 0.8601 - val_loss: 0.3243 - val_accuracy: 0.8505\n",
      "Epoch 72/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.8603\n",
      "Epoch 00072: val_loss improved from 0.32421 to 0.32418, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8597 - val_loss: 0.3242 - val_accuracy: 0.8512\n",
      "Epoch 73/100\n",
      "661/682 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.8605\n",
      "Epoch 00073: val_loss did not improve from 0.32418\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8604 - val_loss: 0.3243 - val_accuracy: 0.8506\n",
      "Epoch 74/100\n",
      "668/682 [============================>.] - ETA: 0s - loss: 0.3050 - accuracy: 0.8597\n",
      "Epoch 00074: val_loss improved from 0.32418 to 0.32412, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8596 - val_loss: 0.3241 - val_accuracy: 0.8512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3066 - accuracy: 0.8601\n",
      "Epoch 00075: val_loss did not improve from 0.32412\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3057 - accuracy: 0.8604 - val_loss: 0.3242 - val_accuracy: 0.8505\n",
      "Epoch 76/100\n",
      "655/682 [===========================>..] - ETA: 0s - loss: 0.3049 - accuracy: 0.8607\n",
      "Epoch 00076: val_loss did not improve from 0.32412\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3057 - accuracy: 0.8600 - val_loss: 0.3241 - val_accuracy: 0.8510\n",
      "Epoch 77/100\n",
      "671/682 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8597\n",
      "Epoch 00077: val_loss did not improve from 0.32412\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3057 - accuracy: 0.8601 - val_loss: 0.3241 - val_accuracy: 0.8511\n",
      "Epoch 78/100\n",
      "674/682 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8598\n",
      "Epoch 00078: val_loss improved from 0.32412 to 0.32408, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3057 - accuracy: 0.8602 - val_loss: 0.3241 - val_accuracy: 0.8506\n",
      "Epoch 79/100\n",
      "656/682 [===========================>..] - ETA: 0s - loss: 0.3069 - accuracy: 0.8594\n",
      "Epoch 00079: val_loss improved from 0.32408 to 0.32403, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3056 - accuracy: 0.8599 - val_loss: 0.3240 - val_accuracy: 0.8506\n",
      "Epoch 80/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3045 - accuracy: 0.8607\n",
      "Epoch 00080: val_loss did not improve from 0.32403\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3054 - accuracy: 0.8606 - val_loss: 0.3242 - val_accuracy: 0.8510\n",
      "Epoch 81/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3049 - accuracy: 0.8613\n",
      "Epoch 00081: val_loss did not improve from 0.32403\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3055 - accuracy: 0.8606 - val_loss: 0.3244 - val_accuracy: 0.8512\n",
      "Epoch 82/100\n",
      "658/682 [===========================>..] - ETA: 0s - loss: 0.3051 - accuracy: 0.8607\n",
      "Epoch 00082: val_loss improved from 0.32403 to 0.32401, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3056 - accuracy: 0.8604 - val_loss: 0.3240 - val_accuracy: 0.8510\n",
      "Epoch 83/100\n",
      "670/682 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8599\n",
      "Epoch 00083: val_loss improved from 0.32401 to 0.32398, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3055 - accuracy: 0.8599 - val_loss: 0.3240 - val_accuracy: 0.8505\n",
      "Epoch 84/100\n",
      "672/682 [============================>.] - ETA: 0s - loss: 0.3056 - accuracy: 0.8600\n",
      "Epoch 00084: val_loss did not improve from 0.32398\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3055 - accuracy: 0.8603 - val_loss: 0.3240 - val_accuracy: 0.8508\n",
      "Epoch 85/100\n",
      "670/682 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8602\n",
      "Epoch 00085: val_loss did not improve from 0.32398\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3054 - accuracy: 0.8605 - val_loss: 0.3244 - val_accuracy: 0.8505\n",
      "Epoch 86/100\n",
      "677/682 [============================>.] - ETA: 0s - loss: 0.3052 - accuracy: 0.8610\n",
      "Epoch 00086: val_loss improved from 0.32398 to 0.32395, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 2ms/step - loss: 0.3055 - accuracy: 0.8607 - val_loss: 0.3239 - val_accuracy: 0.8506\n",
      "Epoch 87/100\n",
      "662/682 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.8611\n",
      "Epoch 00087: val_loss improved from 0.32395 to 0.32389, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3054 - accuracy: 0.8606 - val_loss: 0.3239 - val_accuracy: 0.8505\n",
      "Epoch 88/100\n",
      "658/682 [===========================>..] - ETA: 0s - loss: 0.3049 - accuracy: 0.8608\n",
      "Epoch 00088: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3054 - accuracy: 0.8606 - val_loss: 0.3240 - val_accuracy: 0.8507\n",
      "Epoch 89/100\n",
      "666/682 [============================>.] - ETA: 0s - loss: 0.3052 - accuracy: 0.8602\n",
      "Epoch 00089: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3054 - accuracy: 0.8604 - val_loss: 0.3239 - val_accuracy: 0.8509\n",
      "Epoch 90/100\n",
      "670/682 [============================>.] - ETA: 0s - loss: 0.3047 - accuracy: 0.8611\n",
      "Epoch 00090: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3053 - accuracy: 0.8605 - val_loss: 0.3241 - val_accuracy: 0.8508\n",
      "Epoch 91/100\n",
      "677/682 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.8602\n",
      "Epoch 00091: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3053 - accuracy: 0.8602 - val_loss: 0.3241 - val_accuracy: 0.8506\n",
      "Epoch 92/100\n",
      "668/682 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.8608\n",
      "Epoch 00092: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3053 - accuracy: 0.8609 - val_loss: 0.3241 - val_accuracy: 0.8504\n",
      "Epoch 93/100\n",
      "665/682 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8609\n",
      "Epoch 00093: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3053 - accuracy: 0.8604 - val_loss: 0.3239 - val_accuracy: 0.8508\n",
      "Epoch 94/100\n",
      "669/682 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.8609\n",
      "Epoch 00094: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3052 - accuracy: 0.8610 - val_loss: 0.3242 - val_accuracy: 0.8505\n",
      "Epoch 95/100\n",
      "664/682 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.8600\n",
      "Epoch 00095: val_loss did not improve from 0.32389\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3052 - accuracy: 0.8601 - val_loss: 0.3240 - val_accuracy: 0.8508\n",
      "Epoch 96/100\n",
      "659/682 [===========================>..] - ETA: 0s - loss: 0.3049 - accuracy: 0.8604\n",
      "Epoch 00096: val_loss improved from 0.32389 to 0.32388, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3051 - accuracy: 0.8602 - val_loss: 0.3239 - val_accuracy: 0.8504\n",
      "Epoch 97/100\n",
      "674/682 [============================>.] - ETA: 0s - loss: 0.3049 - accuracy: 0.8606\n",
      "Epoch 00097: val_loss improved from 0.32388 to 0.32384, saving model to ../../../models/adult_bb/rs=55/adult_bb_mt=jv.h5\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3052 - accuracy: 0.8605 - val_loss: 0.3238 - val_accuracy: 0.8507\n",
      "Epoch 98/100\n",
      "674/682 [============================>.] - ETA: 0s - loss: 0.3054 - accuracy: 0.8602\n",
      "Epoch 00098: val_loss did not improve from 0.32384\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3051 - accuracy: 0.8605 - val_loss: 0.3243 - val_accuracy: 0.8510\n",
      "Epoch 99/100\n",
      "669/682 [============================>.] - ETA: 0s - loss: 0.3055 - accuracy: 0.8604\n",
      "Epoch 00099: val_loss did not improve from 0.32384\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3051 - accuracy: 0.8606 - val_loss: 0.3239 - val_accuracy: 0.8509\n",
      "Epoch 100/100\n",
      "670/682 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.8598\n",
      "Epoch 00100: val_loss did not improve from 0.32384\n",
      "682/682 [==============================] - 2s 3ms/step - loss: 0.3051 - accuracy: 0.8599 - val_loss: 0.3239 - val_accuracy: 0.8510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6efc7bcad0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 100,\n",
    "    validation_data = (x_hyper_train, y_hyper_train),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

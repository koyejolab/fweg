{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "import utils.papers\n",
    "import utils.bbox\n",
    "import utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "EVAL_GROUPS: ['gender_Male', 'gender_Female']\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "GROUPS = CONFIG['experiment_configs']['adult_bb']['groups']\n",
    "EVAL_GROUPS = CONFIG['experiment_configs']['adult_bb']['eval_groups']\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(RANDOM_SEED)\n",
    "print(f\"EVAL_GROUPS: {EVAL_GROUPS}\")\n",
    "\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/adult_bb/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/adult_bb/rs={RANDOM_SEED}')\n",
    "\n",
    "PROCESSED_SAVEPATH = utils.utils.get_savepath(PROCESSED_DIR, \"adult_bb\", \".pkl\", g=GROUPS, eg=EVAL_GROUPS)\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, \"adult_bb\", \".h5\", mt=\"base\") # mt = model_type\n",
    "\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "\n",
    "# models saved here\n",
    "if not os.path.exists(BASE_MODEL_SAVEPATH):\n",
    "    print(f\"warning: model has been done for rs={RANDOM_SEED}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = None\n",
    "# load processed data\n",
    "with open(PROCESSED_SAVEPATH, 'rb') as f:\n",
    "    dat = pickle.load(f)\n",
    "    \n",
    "z_train = dat['z_train_full']\n",
    "z_eval_train = dat['z_eval_train_full']\n",
    "z_val = dat['z_val']\n",
    "z_eval_val = dat['z_eval_val']\n",
    "z_test = dat['z_test']\n",
    "z_eval_test = dat['z_eval_test']\n",
    "\n",
    "x_val = dat['x_val']\n",
    "y_val = dat['y_val']\n",
    "\n",
    "x_test = dat['x_test']\n",
    "y_test = dat['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\n",
    "    \"base\",\n",
    "    \"ft\",\n",
    "    \"fc\",\n",
    "    \"lrw\",\n",
    "    \"kmm\",\n",
    "    \"jv\"\n",
    "]\n",
    "\n",
    "metric_list = [\n",
    "    'Accuracy',\n",
    "    'G-mean',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"dataset\", \"subset\", \"seed\", \"model_type\", \"metric\", \"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file does not exist, creating it...\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(RESULTS_DIR, \"results_baselines.csv\")\n",
    "\n",
    "writer = None\n",
    "if os.path.exists(save_path):\n",
    "    print(\"Results file exists, appending to it...\")\n",
    "    fp = open(save_path, mode='a')\n",
    "    writer = csv.writer(fp)\n",
    "else:\n",
    "    print(\"Results file does not exist, creating it...\")\n",
    "    fp = open(save_path, mode='w')\n",
    "    writer = csv.writer(fp)\n",
    "    writer.writerow(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis functions are  ['All']\n",
      "Evaluation groups are  ['gender_Male', 'gender_Female']\n"
     ]
    }
   ],
   "source": [
    "(basis_train, eval_train, basis_val, eval_val, basis_test, eval_test, grp_id_arr, eval_grp_id_arr) = \\\n",
    "    utils.bbox.get_basis_fns(\n",
    "    GROUPS,\n",
    "    EVAL_GROUPS, \n",
    "    z_train,\n",
    "    z_eval_train,\n",
    "    z_val,\n",
    "    z_eval_val,\n",
    "    z_test,\n",
    "    z_eval_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=x_val.shape[1]),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: base\n",
      "METRIC: Accuracy, val: (0.8093922651933702, 'gender_Male'), test: (0.8219766728054021, 'gender_Male')\n",
      "METRIC: G-mean, val: (0.7330878355969046, 'race_White'), test: (0.7331294391980918, 'race_White')\n",
      "Model Type: lrw\n",
      "METRIC: Accuracy, val: (0.8204419889502762, 'gender_Male'), test: (0.8207489257213014, 'gender_Male')\n",
      "METRIC: G-mean, val: (0.751267101761173, 'race_White'), test: (0.735274486451107, 'race_White')\n",
      "Model Type: kmm\n",
      "METRIC: Accuracy, val: (0.8093922651933703, 'gender_Male'), test: (0.8220789850624105, 'gender_Male')\n",
      "METRIC: G-mean, val: (0.7338176544655202, 'race_White'), test: (0.7342915429553992, 'race_White')\n"
     ]
    }
   ],
   "source": [
    "classes = 2\n",
    "for mt in model_types:\n",
    "    print(f\"Model Type: {mt}\")\n",
    "    modelpath = utils.utils.get_savepath(MODELS_DIR, \"adult\", \".h5\", mt=mt)\n",
    "    model.load_weights(modelpath)\n",
    "    preds_valid = utils.utils.compute_preds(\n",
    "        model,\n",
    "        x_val,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    preds_test = utils.utils.compute_preds(\n",
    "        model,\n",
    "        x_test,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    preds_v = np.argmax(preds_valid, axis=1)\n",
    "    preds_t = np.argmax(preds_test, axis=1)\n",
    "    \n",
    "    pred_val_one_hot = np.zeros((preds_v.size, classes))\n",
    "    pred_val_one_hot[np.arange(preds_v.size), preds_v] = 1\n",
    "    \n",
    "    pred_test_one_hot = np.zeros((preds_t.size, classes))\n",
    "    pred_test_one_hot[np.arange(preds_t.size), preds_t] = 1\n",
    "\n",
    "    _, conf_val, _ = utils.bbox.get_confs_frm_scr(\n",
    "        y_val,\n",
    "        basis_val,\n",
    "        eval_val,\n",
    "        pred_val_one_hot,\n",
    "        classes,\n",
    "    )\n",
    "    _, conf_test, _ = utils.bbox.get_confs_frm_scr(\n",
    "        y_test,\n",
    "        basis_test,\n",
    "        eval_test,\n",
    "        pred_test_one_hot,\n",
    "        classes,\n",
    "    )\n",
    "    \n",
    "    for metric in metric_list:\n",
    "        valid_score = utils.metrics.eval_metric_bb(conf_val, metric)\n",
    "        test_score = utils.metrics.eval_metric_bb(conf_test, metric)\n",
    "        \n",
    "        print(f\"METRIC: {metric}, val: {valid_score}, test: {test_score}\")\n",
    "                \n",
    "        writer.writerow( [f\"adult_bb_g={GROUPS}\", \"val\", RANDOM_SEED, mt, metric, valid_score] )\n",
    "        writer.writerow( [f\"adult_bb_g={GROUPS}\", \"test\", RANDOM_SEED, mt, metric, test_score] )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

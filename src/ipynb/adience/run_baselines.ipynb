{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from tqdm.notebook import tqdm\n",
    "import umap\n",
    "import time\n",
    "\n",
    "BASE_DIR = '../../../'\n",
    "import sys\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "# custom code\n",
    "import utils.utils\n",
    "CONFIG = utils.utils.load_config(\"../../config.json\")\n",
    "import utils.papers\n",
    "import utils.custom_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adience 55\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.path.basename(os.getcwd()) # name of folder this file is in\n",
    "RANDOM_SEED = CONFIG['random_seed']\n",
    "EPOCHS = CONFIG[\"experiment_configs\"][DATASET][\"epochs\"]\n",
    "BATCH_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"batch_size\"]\n",
    "IMAGE_X_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"image_x_size\"]\n",
    "IMAGE_Y_SIZE = CONFIG[\"experiment_configs\"][DATASET][\"image_y_size\"]\n",
    "IMAGE_SIZE = (IMAGE_Y_SIZE, IMAGE_X_SIZE)\n",
    "HYPER_VAL_SPLIT = CONFIG['experiment_configs'][DATASET]['hyper_val_split']\n",
    "\n",
    "print(DATASET, RANDOM_SEED)\n",
    "\n",
    "# folders for processed, models\n",
    "DATA_F = os.path.join(BASE_DIR, f\"data/{DATASET}/\")\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, f'processed/{DATASET}/rs={RANDOM_SEED}')\n",
    "MODELS_DIR = os.path.join(BASE_DIR, f'models/{DATASET}/rs={RANDOM_SEED}')\n",
    "\n",
    "BASE_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"base\") # mt = model_type\n",
    "\n",
    "# base model saved here\n",
    "if not os.path.exists(BASE_MODEL_SAVEPATH):\n",
    "    print(f\"warning: no model has been run for rs={RANDOM_SEED}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9795 files belonging to 2 classes.\n",
      "Found 2449 files belonging to 2 classes.\n",
      "Found 199 files belonging to 2 classes.\n",
      "Found 200 files belonging to 2 classes.\n",
      "Found 3585 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    seed = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "hyper_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"hyper_train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    seed = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"val\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    seed = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "hyper_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"hyper_val\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    seed = RANDOM_SEED,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"test\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    seed = RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will standardize the pixel data\n",
    "'''\n",
    "def preprocess(imgs, labels):\n",
    "    # turn from <0..255> to <0..1>\n",
    "    imgs = imgs / 255.0\n",
    "    means = np.array( [0.5, 0.5, 0.5] )\n",
    "    stds = np.array( [0.5, 0.5, 0.5] )\n",
    "    imgs = (imgs - means) / stds\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(preprocess)\n",
    "hyper_train_ds = hyper_train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "hyper_val_ds = hyper_val_ds.map(preprocess)\n",
    "test_ds = test_ds.map(preprocess)\n",
    "\n",
    "# create a full validation set for baselines that need it\n",
    "val_full_ds = val_ds.concatenate(hyper_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.utils.make_resnet(\n",
    "    depth=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=2,\n",
    ")\n",
    "\n",
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:18<00:00,  4.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7897100857492855"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper train acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    hyper_train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:03<00:00,  4.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7493734335839599"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    val_full_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:23<00:00,  4.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7403068340306834"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: Fine Tune\n",
    "This is a very widely used technique in deep learning. The idea is simple: do a little bit more training on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=5e-6, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"ft\")\n",
    "\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=FT_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.7525\n",
      "Epoch 00001: val_loss improved from inf to 0.55712, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 8s 408ms/step - loss: 0.6480 - accuracy: 0.7525 - val_loss: 0.5571 - val_accuracy: 0.7943\n",
      "Epoch 2/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.7575\n",
      "Epoch 00002: val_loss improved from 0.55712 to 0.55485, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 383ms/step - loss: 0.6284 - accuracy: 0.7575 - val_loss: 0.5548 - val_accuracy: 0.8077\n",
      "Epoch 3/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.7575\n",
      "Epoch 00003: val_loss improved from 0.55485 to 0.54945, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 380ms/step - loss: 0.6207 - accuracy: 0.7575 - val_loss: 0.5495 - val_accuracy: 0.8127\n",
      "Epoch 4/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.7793\n",
      "Epoch 00004: val_loss improved from 0.54945 to 0.54769, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 378ms/step - loss: 0.6057 - accuracy: 0.7793 - val_loss: 0.5477 - val_accuracy: 0.8177\n",
      "Epoch 5/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5917 - accuracy: 0.7642\n",
      "Epoch 00005: val_loss did not improve from 0.54769\n",
      "19/19 [==============================] - 7s 374ms/step - loss: 0.5917 - accuracy: 0.7642 - val_loss: 0.5501 - val_accuracy: 0.8161\n",
      "Epoch 6/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.7826\n",
      "Epoch 00006: val_loss improved from 0.54769 to 0.54472, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 8s 398ms/step - loss: 0.5761 - accuracy: 0.7826 - val_loss: 0.5447 - val_accuracy: 0.8127\n",
      "Epoch 7/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.7726\n",
      "Epoch 00007: val_loss did not improve from 0.54472\n",
      "19/19 [==============================] - 7s 374ms/step - loss: 0.5733 - accuracy: 0.7726 - val_loss: 0.5458 - val_accuracy: 0.8194\n",
      "Epoch 8/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7910\n",
      "Epoch 00008: val_loss improved from 0.54472 to 0.54377, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 377ms/step - loss: 0.5654 - accuracy: 0.7910 - val_loss: 0.5438 - val_accuracy: 0.8110\n",
      "Epoch 9/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8127\n",
      "Epoch 00009: val_loss improved from 0.54377 to 0.54228, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.5472 - accuracy: 0.8127 - val_loss: 0.5423 - val_accuracy: 0.8194\n",
      "Epoch 10/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8110\n",
      "Epoch 00010: val_loss improved from 0.54228 to 0.53919, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.5263 - accuracy: 0.8110 - val_loss: 0.5392 - val_accuracy: 0.8194\n",
      "Epoch 11/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.8328\n",
      "Epoch 00011: val_loss improved from 0.53919 to 0.53822, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 378ms/step - loss: 0.5140 - accuracy: 0.8328 - val_loss: 0.5382 - val_accuracy: 0.8177\n",
      "Epoch 12/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8161\n",
      "Epoch 00012: val_loss did not improve from 0.53822\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.5245 - accuracy: 0.8161 - val_loss: 0.5407 - val_accuracy: 0.8177\n",
      "Epoch 13/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.8244\n",
      "Epoch 00013: val_loss did not improve from 0.53822\n",
      "19/19 [==============================] - 7s 374ms/step - loss: 0.5016 - accuracy: 0.8244 - val_loss: 0.5388 - val_accuracy: 0.8161\n",
      "Epoch 14/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4962 - accuracy: 0.8211\n",
      "Epoch 00014: val_loss improved from 0.53822 to 0.53594, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 379ms/step - loss: 0.4962 - accuracy: 0.8211 - val_loss: 0.5359 - val_accuracy: 0.8161\n",
      "Epoch 15/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.8227\n",
      "Epoch 00015: val_loss did not improve from 0.53594\n",
      "19/19 [==============================] - 7s 373ms/step - loss: 0.4985 - accuracy: 0.8227 - val_loss: 0.5389 - val_accuracy: 0.8127\n",
      "Epoch 16/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.8261\n",
      "Epoch 00016: val_loss did not improve from 0.53594\n",
      "19/19 [==============================] - 7s 372ms/step - loss: 0.4952 - accuracy: 0.8261 - val_loss: 0.5374 - val_accuracy: 0.8161\n",
      "Epoch 17/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.8278\n",
      "Epoch 00017: val_loss improved from 0.53594 to 0.53439, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 377ms/step - loss: 0.4926 - accuracy: 0.8278 - val_loss: 0.5344 - val_accuracy: 0.8177\n",
      "Epoch 18/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.8311\n",
      "Epoch 00018: val_loss did not improve from 0.53439\n",
      "19/19 [==============================] - 7s 373ms/step - loss: 0.4867 - accuracy: 0.8311 - val_loss: 0.5373 - val_accuracy: 0.8094\n",
      "Epoch 19/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.8361\n",
      "Epoch 00019: val_loss did not improve from 0.53439\n",
      "19/19 [==============================] - 7s 375ms/step - loss: 0.4771 - accuracy: 0.8361 - val_loss: 0.5346 - val_accuracy: 0.8144\n",
      "Epoch 20/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.8445\n",
      "Epoch 00020: val_loss did not improve from 0.53439\n",
      "19/19 [==============================] - 7s 375ms/step - loss: 0.4689 - accuracy: 0.8445 - val_loss: 0.5357 - val_accuracy: 0.8110\n",
      "Epoch 21/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4735 - accuracy: 0.8445\n",
      "Epoch 00021: val_loss improved from 0.53439 to 0.53424, saving model to ../../../models/adience/rs=15/adience_mt=ft.h5\n",
      "19/19 [==============================] - 7s 377ms/step - loss: 0.4735 - accuracy: 0.8445 - val_loss: 0.5342 - val_accuracy: 0.8161\n",
      "Epoch 22/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.8462\n",
      "Epoch 00022: val_loss did not improve from 0.53424\n",
      "19/19 [==============================] - 7s 373ms/step - loss: 0.4532 - accuracy: 0.8462 - val_loss: 0.5361 - val_accuracy: 0.8110\n",
      "Epoch 23/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8361\n",
      "Epoch 00023: val_loss did not improve from 0.53424\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.4517 - accuracy: 0.8361 - val_loss: 0.5354 - val_accuracy: 0.8077\n",
      "Epoch 24/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.8462\n",
      "Epoch 00024: val_loss did not improve from 0.53424\n",
      "19/19 [==============================] - 7s 373ms/step - loss: 0.4474 - accuracy: 0.8462 - val_loss: 0.5343 - val_accuracy: 0.8094\n",
      "Epoch 25/25\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.8579\n",
      "Epoch 00025: val_loss did not improve from 0.53424\n",
      "19/19 [==============================] - 7s 376ms/step - loss: 0.4372 - accuracy: 0.8579 - val_loss: 0.5368 - val_accuracy: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f24903bb350>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        x=val_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=hyper_val_ds,\n",
    "        callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(FT_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7969924812030075"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper val acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    hyper_val_ds,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7806714778788829"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    test_ds,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: Learn to Weigh Examples\n",
    "Paper: https://arxiv.org/pdf/1803.09050.pdf\n",
    "\n",
    "This is a type of meta-learning, which doesn't quite work with the keras API. We will need to manually implement the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(BASE_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=5e-5, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction.NONE means the cross entropy is computed per entry in the batch\n",
    "# but is not aggregated. Traditional cross entropy will average the results.\n",
    "ce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_batches_indef(ds):\n",
    "    # keep yielding batches from `val_ds` indefinitely; loop around when finishing a dataset\n",
    "    while True:\n",
    "        for x_val, y_val in ds:\n",
    "            yield x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_gen = yield_batches_indef(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c212927c8f4e1884b3e18f3839d2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.21759152412414555\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.21688276529312134\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7568922305764411\n",
      "Hyper Val Loss: 0.21688276529312134\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 1:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9742883889794ec5b1d404ff9fa7ac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20383436977863312\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20317041873931885\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7619047619047619\n",
      "Hyper Val Loss: 0.20317041873931885\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 2:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd4e44f108043ab992832d5735a5108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17989750206470497\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17931151390075684\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7493734335839599\n",
      "Hyper Val Loss: 0.17931151390075684\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 3:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54861dc8354410d9c0b970a869b4f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18651047348976135\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18665733933448792\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7694235588972431\n",
      "Hyper Val Loss: 0.18665733933448792\n",
      "\n",
      "Epoch 4:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5e946e38ab442fbae41e25720118f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19130821526050568\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19103917479515076\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7769423558897243\n",
      "Hyper Val Loss: 0.19103917479515076\n",
      "\n",
      "Epoch 5:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc6023427ed413994a0d78444df75ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.21711790561676025\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.21659691631793976\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7593984962406015\n",
      "Hyper Val Loss: 0.21659691631793976\n",
      "\n",
      "Epoch 6:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe2866ab7ce477a8811a4b1fd87d2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19805613160133362\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19741100072860718\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7669172932330827\n",
      "Hyper Val Loss: 0.19741100072860718\n",
      "\n",
      "Epoch 7:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e4bee6e1a24914b18b0ec2a0f29185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.172115981578826945\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17155534029006958\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7669172932330827\n",
      "Hyper Val Loss: 0.17155534029006958\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 8:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dff4953a2d4932b50a20e3e74b8746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18839119374752045\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1877775341272354\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7619047619047619\n",
      "Hyper Val Loss: 0.1877775341272354\n",
      "\n",
      "Epoch 9:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef0bbcbd62848799f529ece20f99cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17725113034248352\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17681726813316345\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7493734335839599\n",
      "Hyper Val Loss: 0.17681726813316345\n",
      "\n",
      "Epoch 10:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c460e621e45af8459b85206288970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17868730425834656\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17840944230556488\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7619047619047619\n",
      "Hyper Val Loss: 0.17840944230556488\n",
      "\n",
      "Epoch 11:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01693628881413eb0e21d7f16a07c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19441524147987366\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19378195703029633\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7593984962406015\n",
      "Hyper Val Loss: 0.19378195703029633\n",
      "\n",
      "Epoch 12:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475de967642046b3876c3140268c55dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18723870813846588\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1866288036108017\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7744360902255639\n",
      "Hyper Val Loss: 0.1866288036108017\n",
      "\n",
      "Epoch 13:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a87d422f53473583f1bfbb78553c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17335519194602966\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1727905124425888\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7543859649122807\n",
      "Hyper Val Loss: 0.1727905124425888\n",
      "\n",
      "Epoch 14:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81572520cf74991b9fb608a221afdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16737031936645508\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16716289520263672\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7644110275689223\n",
      "Hyper Val Loss: 0.16716289520263672\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 15:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f82dc096d646c4a50ee204e5027902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16387143731117249\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16333766281604767\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7518796992481203\n",
      "Hyper Val Loss: 0.16333766281604767\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 16:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269e12fe879049869f081dafd3051f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18798233568668365\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18737001717090607\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7669172932330827\n",
      "Hyper Val Loss: 0.18737001717090607\n",
      "\n",
      "Epoch 17:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f745e41481b34c11aec893f7da8b878d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15981453657150269\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15929396450519562\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7619047619047619\n",
      "Hyper Val Loss: 0.15929396450519562\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 18:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0315f8e4174b4c039b2a45a93f8623cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16343134641647344\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16366778314113617\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7644110275689223\n",
      "Hyper Val Loss: 0.16366778314113617\n",
      "\n",
      "Epoch 19:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4571c4df6a426c9cb9e6c00e069034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19355389475822456\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.19302715361118317\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7518796992481203\n",
      "Hyper Val Loss: 0.19302715361118317\n",
      "\n",
      "Epoch 20:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2b1eba74b341068867fcfa3944e36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16845244169235235\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16790373623371124\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7543859649122807\n",
      "Hyper Val Loss: 0.16790373623371124\n",
      "\n",
      "Epoch 21:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04d6e057c7e4bb4b142c39d930f6526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15247532725334167\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15346217155456543\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7744360902255639\n",
      "Hyper Val Loss: 0.15346217155456543\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 22:\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6419b55d03924d97a43df1cf2cba765b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15086673200130463\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15037532150745392\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7769423558897243\n",
      "Hyper Val Loss: 0.15037532150745392\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n",
      "Epoch 23:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47c0515129a4bcfb4f99b502cc4d148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16070169210433967\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16017822921276093\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7769423558897243\n",
      "Hyper Val Loss: 0.16017822921276093\n",
      "\n",
      "Epoch 24:\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1000ad1fd74c4f1d97ea49ed27f152c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=307.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14117944240570068\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14152872562408447\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper Val Acc: 0.7744360902255639\n",
      "Hyper Val Loss: 0.14152872562408447\n",
      "\n",
      "Saving new best weights to ../../../models/adience/rs=55/adience_mt=lrw.h5\n"
     ]
    }
   ],
   "source": [
    "best_loss = float('inf')\n",
    "LRW_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"lrw\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # implements a train loop\n",
    "    print(f\"Epoch {epoch}:\\n----------\")\n",
    "    \n",
    "    total_batches = len(train_ds)\n",
    "    batch_c = 0\n",
    "    loss_sum = 0\n",
    "    for batch, labels in tqdm(train_ds):\n",
    "        x_val, y_val = next(val_batch_gen)\n",
    "        # most of the details are abstracted away in this function\n",
    "        loss = utils.papers.train_step(model, batch, labels, x_val, y_val, ce, optimizer)\n",
    "        loss_sum += loss\n",
    "        batch_c += 1\n",
    "        # print ongoing avg loss\n",
    "        print(f\"Loss: {loss_sum / batch_c}\", end='\\r')\n",
    "        \n",
    "        # we need to tally this ourselves because the iterator simply restarts another epoch\n",
    "        if batch_c >= total_batches:\n",
    "            break\n",
    "    \n",
    "    # compute validation accuracy\n",
    "    preds, labels = utils.utils.compute_preds(\n",
    "        model,\n",
    "        hyper_val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    val_acc = (np.argmax(preds, axis=1) == labels).mean()\n",
    "    loss_avg = loss_sum / total_batches\n",
    "    \n",
    "    print(f\"Hyper Val Acc: {val_acc}\")\n",
    "    print(f\"Hyper Val Loss: {loss_avg}\", end='\\n\\n')\n",
    "        \n",
    "    # implements save best logic\n",
    "    if loss_avg < best_loss:\n",
    "        best_loss = loss_avg\n",
    "        print(f\"Saving new best weights to {LRW_MODEL_SAVEPATH}\")\n",
    "        model.save_weights(\n",
    "            filepath=LRW_MODEL_SAVEPATH,\n",
    "            save_format=\"h5\",\n",
    "        )\n",
    "        last_best_epoch = epoch\n",
    "        \n",
    "    # because this takes a long time (roughly 3x the normal train time)\n",
    "    # we use early stopping \n",
    "    early_stop = 10\n",
    "    if last_best_epoch + early_stop <= epoch:\n",
    "        print(f\"no improvement for {early_stop} epochs, ending training\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(LRW_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7744360902255639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    hyper_val_ds,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7565108252274867"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    test_ds,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 3: KMM\n",
    "Paper: https://papers.nips.cc/paper/2006/file/a2186aa7c086b46ad4e8bf81e2a3a19b-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMGNET_PREDS = utils.utils.get_savepath(PROCESSED_DIR, \"adience_imgnet_preds_train\", \".npy\")\n",
    "VAL_IMGNET_PREDS = utils.utils.get_savepath(PROCESSED_DIR, \"adience_imgnet_preds_val\", \".npy\")\n",
    "\n",
    "x_train = np.load(TRAIN_IMGNET_PREDS)\n",
    "x_val = np.load(VAL_IMGNET_PREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9795, 2048), (398, 2048))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 47.68 seconds\n"
     ]
    }
   ],
   "source": [
    "n_neighbors = 10\n",
    "dim = 10\n",
    "\n",
    "umap_emb = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=0.5, \n",
    "    n_components=dim,\n",
    "    metric='euclidean',\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "umap_emb.fit(x_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"took { np.round(end - start, decimals=2) } seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_emb = umap_emb.transform(x_train)\n",
    "x_val_emb = umap_emb.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9795, 10), (398, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_emb.shape, x_val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer needed, delete to save memory\n",
    "del x_train, x_val, umap_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-2500)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2453e+09 -1.2454e+09  1e+06  9e-02  5e-16\n",
      " 1: -1.2453e+09 -1.2454e+09  6e+05  3e-02  5e-16\n",
      " 2: -1.2453e+09 -1.2452e+09  4e+05  2e-02  5e-16\n",
      " 3: -1.2453e+09 -1.2450e+09  4e+05  1e-02  5e-16\n",
      " 4: -1.2452e+09 -1.2449e+09  4e+05  1e-02  5e-16\n",
      " 5: -1.2452e+09 -1.2447e+09  4e+05  1e-02  5e-16\n",
      " 6: -1.2452e+09 -1.2446e+09  4e+05  1e-02  5e-16\n",
      " 7: -1.2451e+09 -1.2445e+09  5e+05  1e-02  5e-16\n",
      " 8: -1.2451e+09 -1.2444e+09  5e+05  1e-02  5e-16\n",
      " 9: -1.2450e+09 -1.2443e+09  5e+05  1e-02  5e-16\n",
      "10: -1.2450e+09 -1.2442e+09  6e+05  1e-02  4e-16\n",
      "11: -1.2450e+09 -1.2442e+09  6e+05  9e-03  5e-16\n",
      "12: -1.2449e+09 -1.2440e+09  6e+05  9e-03  5e-16\n",
      "13: -1.2449e+09 -1.2439e+09  6e+05  8e-03  5e-16\n",
      "14: -1.2448e+09 -1.2437e+09  7e+05  8e-03  5e-16\n",
      "15: -1.2447e+09 -1.2436e+09  7e+05  7e-03  5e-16\n",
      "16: -1.2446e+09 -1.2434e+09  7e+05  7e-03  5e-16\n",
      "17: -1.2445e+09 -1.2433e+09  8e+05  6e-03  4e-16\n",
      "18: -1.2444e+09 -1.2432e+09  8e+05  6e-03  4e-16\n",
      "19: -1.2443e+09 -1.2431e+09  8e+05  5e-03  4e-16\n",
      "20: -1.2442e+09 -1.2430e+09  8e+05  5e-03  5e-16\n",
      "21: -1.2441e+09 -1.2429e+09  9e+05  5e-03  4e-16\n",
      "22: -1.2439e+09 -1.2428e+09  9e+05  4e-03  5e-16\n",
      "23: -1.2438e+09 -1.2427e+09  9e+05  4e-03  4e-16\n",
      "24: -1.2437e+09 -1.2426e+09  9e+05  4e-03  4e-16\n",
      "25: -1.2436e+09 -1.2426e+09  9e+05  3e-03  4e-16\n",
      "26: -1.2434e+09 -1.2425e+09  9e+05  3e-03  4e-16\n",
      "27: -1.2433e+09 -1.2424e+09  8e+05  2e-03  5e-16\n",
      "28: -1.2432e+09 -1.2424e+09  8e+05  2e-03  4e-16\n",
      "29: -1.2430e+09 -1.2424e+09  8e+05  2e-03  4e-16\n",
      "30: -1.2429e+09 -1.2423e+09  8e+05  2e-03  4e-16\n",
      "31: -1.2428e+09 -1.2423e+09  7e+05  2e-03  4e-16\n",
      "32: -1.2427e+09 -1.2423e+09  7e+05  1e-03  4e-16\n",
      "33: -1.2426e+09 -1.2422e+09  6e+05  1e-03  4e-16\n",
      "34: -1.2425e+09 -1.2422e+09  6e+05  9e-04  5e-16\n",
      "35: -1.2425e+09 -1.2422e+09  5e+05  8e-04  4e-16\n",
      "36: -1.2424e+09 -1.2422e+09  5e+05  7e-04  4e-16\n",
      "37: -1.2424e+09 -1.2422e+09  5e+05  7e-04  4e-16\n",
      "38: -1.2423e+09 -1.2422e+09  4e+05  6e-04  4e-16\n",
      "39: -1.2423e+09 -1.2422e+09  4e+05  5e-04  4e-16\n",
      "40: -1.2422e+09 -1.2422e+09  4e+05  4e-04  5e-16\n",
      "41: -1.2422e+09 -1.2421e+09  3e+05  3e-04  5e-16\n",
      "42: -1.2421e+09 -1.2421e+09  3e+05  2e-04  5e-16\n",
      "43: -1.2421e+09 -1.2421e+09  2e+05  2e-04  5e-16\n",
      "44: -1.2421e+09 -1.2421e+09  1e+05  1e-04  5e-16\n",
      "45: -1.2421e+09 -1.2421e+09  6e+04  5e-05  5e-16\n",
      "46: -1.2420e+09 -1.2420e+09  6e+03  4e-06  6e-16\n",
      "47: -1.2420e+09 -1.2420e+09  6e+01  4e-08  6e-16\n",
      "Optimal solution found.\n",
      "(2500-5000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2453e+09 -1.2454e+09  9e+05  6e-02  5e-16\n",
      " 1: -1.2453e+09 -1.2454e+09  5e+05  2e-02  5e-16\n",
      " 2: -1.2453e+09 -1.2452e+09  3e+05  1e-02  5e-16\n",
      " 3: -1.2453e+09 -1.2450e+09  3e+05  1e-02  5e-16\n",
      " 4: -1.2452e+09 -1.2448e+09  3e+05  1e-02  5e-16\n",
      " 5: -1.2452e+09 -1.2448e+09  3e+05  1e-02  5e-16\n",
      " 6: -1.2452e+09 -1.2447e+09  4e+05  1e-02  5e-16\n",
      " 7: -1.2452e+09 -1.2446e+09  4e+05  1e-02  5e-16\n",
      " 8: -1.2451e+09 -1.2445e+09  4e+05  1e-02  5e-16\n",
      " 9: -1.2451e+09 -1.2444e+09  5e+05  9e-03  5e-16\n",
      "10: -1.2450e+09 -1.2443e+09  5e+05  9e-03  5e-16\n",
      "11: -1.2450e+09 -1.2442e+09  5e+05  9e-03  5e-16\n",
      "12: -1.2450e+09 -1.2441e+09  6e+05  8e-03  5e-16\n",
      "13: -1.2449e+09 -1.2440e+09  6e+05  8e-03  5e-16\n",
      "14: -1.2448e+09 -1.2439e+09  6e+05  7e-03  4e-16\n",
      "15: -1.2448e+09 -1.2438e+09  6e+05  7e-03  5e-16\n",
      "16: -1.2447e+09 -1.2436e+09  7e+05  6e-03  4e-16\n",
      "17: -1.2446e+09 -1.2435e+09  7e+05  6e-03  4e-16\n",
      "18: -1.2445e+09 -1.2434e+09  7e+05  6e-03  4e-16\n",
      "19: -1.2444e+09 -1.2433e+09  7e+05  5e-03  4e-16\n",
      "20: -1.2443e+09 -1.2432e+09  8e+05  5e-03  4e-16\n",
      "21: -1.2442e+09 -1.2432e+09  8e+05  5e-03  5e-16\n",
      "22: -1.2441e+09 -1.2431e+09  8e+05  4e-03  4e-16\n",
      "23: -1.2440e+09 -1.2430e+09  8e+05  4e-03  4e-16\n",
      "24: -1.2439e+09 -1.2429e+09  8e+05  4e-03  4e-16\n",
      "25: -1.2438e+09 -1.2429e+09  8e+05  3e-03  4e-16\n",
      "26: -1.2437e+09 -1.2428e+09  8e+05  3e-03  4e-16\n",
      "27: -1.2436e+09 -1.2428e+09  8e+05  3e-03  4e-16\n",
      "28: -1.2434e+09 -1.2427e+09  8e+05  2e-03  4e-16\n",
      "29: -1.2433e+09 -1.2427e+09  7e+05  2e-03  5e-16\n",
      "30: -1.2432e+09 -1.2426e+09  7e+05  2e-03  4e-16\n",
      "31: -1.2431e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "32: -1.2430e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "33: -1.2429e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "34: -1.2428e+09 -1.2425e+09  5e+05  1e-03  5e-16\n",
      "35: -1.2427e+09 -1.2425e+09  5e+05  8e-04  4e-16\n",
      "36: -1.2427e+09 -1.2425e+09  4e+05  7e-04  5e-16\n",
      "37: -1.2426e+09 -1.2425e+09  4e+05  6e-04  5e-16\n",
      "38: -1.2426e+09 -1.2425e+09  4e+05  5e-04  4e-16\n",
      "39: -1.2426e+09 -1.2425e+09  3e+05  4e-04  4e-16\n",
      "40: -1.2425e+09 -1.2425e+09  3e+05  4e-04  5e-16\n",
      "41: -1.2425e+09 -1.2425e+09  3e+05  3e-04  4e-16\n",
      "42: -1.2425e+09 -1.2424e+09  2e+05  3e-04  4e-16\n",
      "43: -1.2424e+09 -1.2424e+09  2e+05  2e-04  4e-16\n",
      "44: -1.2424e+09 -1.2424e+09  2e+05  2e-04  4e-16\n",
      "45: -1.2424e+09 -1.2424e+09  1e+05  9e-05  5e-16\n",
      "46: -1.2424e+09 -1.2424e+09  3e+04  2e-05  5e-16\n",
      "47: -1.2424e+09 -1.2424e+09  2e+03  1e-06  6e-16\n",
      "48: -1.2424e+09 -1.2424e+09  4e+01  1e-08  6e-16\n",
      "Optimal solution found.\n",
      "(5000-7500)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2453e+09 -1.2454e+09  1e+06  7e-02  6e-16\n",
      " 1: -1.2453e+09 -1.2454e+09  6e+05  3e-02  5e-16\n",
      " 2: -1.2453e+09 -1.2452e+09  3e+05  2e-02  5e-16\n",
      " 3: -1.2453e+09 -1.2450e+09  3e+05  1e-02  5e-16\n",
      " 4: -1.2452e+09 -1.2450e+09  3e+05  1e-02  5e-16\n",
      " 5: -1.2452e+09 -1.2448e+09  4e+05  1e-02  5e-16\n",
      " 6: -1.2452e+09 -1.2447e+09  4e+05  1e-02  5e-16\n",
      " 7: -1.2451e+09 -1.2446e+09  4e+05  1e-02  5e-16\n",
      " 8: -1.2451e+09 -1.2445e+09  4e+05  1e-02  5e-16\n",
      " 9: -1.2451e+09 -1.2444e+09  5e+05  9e-03  4e-16\n",
      "10: -1.2451e+09 -1.2444e+09  5e+05  9e-03  5e-16\n",
      "11: -1.2450e+09 -1.2443e+09  5e+05  9e-03  5e-16\n",
      "12: -1.2450e+09 -1.2441e+09  5e+05  8e-03  5e-16\n",
      "13: -1.2449e+09 -1.2441e+09  6e+05  8e-03  5e-16\n",
      "14: -1.2449e+09 -1.2440e+09  6e+05  8e-03  5e-16\n",
      "15: -1.2448e+09 -1.2439e+09  6e+05  7e-03  5e-16\n",
      "16: -1.2447e+09 -1.2437e+09  6e+05  7e-03  5e-16\n",
      "17: -1.2446e+09 -1.2436e+09  7e+05  6e-03  4e-16\n",
      "18: -1.2446e+09 -1.2435e+09  7e+05  6e-03  5e-16\n",
      "19: -1.2445e+09 -1.2434e+09  7e+05  5e-03  5e-16\n",
      "20: -1.2444e+09 -1.2433e+09  7e+05  5e-03  4e-16\n",
      "21: -1.2443e+09 -1.2432e+09  8e+05  5e-03  4e-16\n",
      "22: -1.2442e+09 -1.2432e+09  8e+05  4e-03  4e-16\n",
      "23: -1.2441e+09 -1.2431e+09  8e+05  4e-03  4e-16\n",
      "24: -1.2440e+09 -1.2430e+09  8e+05  4e-03  5e-16\n",
      "25: -1.2439e+09 -1.2429e+09  8e+05  3e-03  4e-16\n",
      "26: -1.2438e+09 -1.2429e+09  8e+05  3e-03  4e-16\n",
      "27: -1.2437e+09 -1.2428e+09  8e+05  3e-03  4e-16\n",
      "28: -1.2436e+09 -1.2428e+09  8e+05  3e-03  5e-16\n",
      "29: -1.2435e+09 -1.2428e+09  8e+05  2e-03  4e-16\n",
      "30: -1.2434e+09 -1.2427e+09  7e+05  2e-03  4e-16\n",
      "31: -1.2433e+09 -1.2427e+09  7e+05  2e-03  4e-16\n",
      "32: -1.2432e+09 -1.2427e+09  7e+05  2e-03  4e-16\n",
      "33: -1.2431e+09 -1.2426e+09  7e+05  2e-03  4e-16\n",
      "34: -1.2430e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "35: -1.2429e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "36: -1.2429e+09 -1.2426e+09  6e+05  1e-03  4e-16\n",
      "37: -1.2428e+09 -1.2426e+09  5e+05  9e-04  4e-16\n",
      "38: -1.2427e+09 -1.2425e+09  5e+05  8e-04  5e-16\n",
      "39: -1.2427e+09 -1.2425e+09  5e+05  7e-04  4e-16\n",
      "40: -1.2426e+09 -1.2425e+09  4e+05  6e-04  4e-16\n",
      "41: -1.2426e+09 -1.2425e+09  4e+05  5e-04  4e-16\n",
      "42: -1.2425e+09 -1.2425e+09  3e+05  4e-04  5e-16\n",
      "43: -1.2425e+09 -1.2425e+09  2e+05  2e-04  5e-16\n",
      "44: -1.2424e+09 -1.2424e+09  2e+05  2e-04  5e-16\n",
      "45: -1.2424e+09 -1.2424e+09  9e+04  7e-05  5e-16\n",
      "46: -1.2424e+09 -1.2424e+09  5e+04  4e-05  5e-16\n",
      "47: -1.2424e+09 -1.2424e+09  7e+02  5e-07  6e-16\n",
      "48: -1.2424e+09 -1.2424e+09  7e+00  5e-09  6e-16\n",
      "Optimal solution found.\n",
      "(7500-10000)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0494e+09 -1.0496e+09  9e+05  7e-02  5e-16\n",
      " 1: -1.0494e+09 -1.0495e+09  4e+05  2e-02  5e-16\n",
      " 2: -1.0494e+09 -1.0493e+09  3e+05  2e-02  5e-16\n",
      " 3: -1.0494e+09 -1.0491e+09  3e+05  1e-02  5e-16\n",
      " 4: -1.0494e+09 -1.0491e+09  3e+05  1e-02  5e-16\n",
      " 5: -1.0494e+09 -1.0490e+09  3e+05  1e-02  5e-16\n",
      " 6: -1.0493e+09 -1.0489e+09  4e+05  1e-02  4e-16\n",
      " 7: -1.0493e+09 -1.0488e+09  4e+05  1e-02  4e-16\n",
      " 8: -1.0493e+09 -1.0487e+09  4e+05  1e-02  4e-16\n",
      " 9: -1.0492e+09 -1.0486e+09  4e+05  1e-02  4e-16\n",
      "10: -1.0492e+09 -1.0485e+09  5e+05  9e-03  4e-16\n",
      "11: -1.0491e+09 -1.0484e+09  5e+05  9e-03  4e-16\n",
      "12: -1.0491e+09 -1.0482e+09  5e+05  8e-03  4e-16\n",
      "13: -1.0490e+09 -1.0481e+09  6e+05  7e-03  4e-16\n",
      "14: -1.0489e+09 -1.0480e+09  6e+05  7e-03  4e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15: -1.0488e+09 -1.0479e+09  6e+05  7e-03  4e-16\n",
      "16: -1.0488e+09 -1.0478e+09  6e+05  6e-03  4e-16\n",
      "17: -1.0487e+09 -1.0477e+09  7e+05  6e-03  4e-16\n",
      "18: -1.0486e+09 -1.0476e+09  7e+05  5e-03  4e-16\n",
      "19: -1.0485e+09 -1.0475e+09  7e+05  5e-03  4e-16\n",
      "20: -1.0484e+09 -1.0475e+09  7e+05  5e-03  4e-16\n",
      "21: -1.0483e+09 -1.0474e+09  7e+05  4e-03  4e-16\n",
      "22: -1.0482e+09 -1.0473e+09  7e+05  4e-03  4e-16\n",
      "23: -1.0481e+09 -1.0473e+09  7e+05  4e-03  4e-16\n",
      "24: -1.0480e+09 -1.0472e+09  7e+05  3e-03  4e-16\n",
      "25: -1.0479e+09 -1.0472e+09  7e+05  3e-03  4e-16\n",
      "26: -1.0478e+09 -1.0471e+09  7e+05  3e-03  4e-16\n",
      "27: -1.0477e+09 -1.0471e+09  7e+05  2e-03  4e-16\n",
      "28: -1.0476e+09 -1.0471e+09  7e+05  2e-03  4e-16\n",
      "29: -1.0475e+09 -1.0470e+09  6e+05  2e-03  4e-16\n",
      "30: -1.0474e+09 -1.0470e+09  6e+05  2e-03  4e-16\n",
      "31: -1.0474e+09 -1.0470e+09  6e+05  1e-03  4e-16\n",
      "32: -1.0473e+09 -1.0470e+09  5e+05  1e-03  4e-16\n",
      "33: -1.0472e+09 -1.0470e+09  5e+05  1e-03  4e-16\n",
      "34: -1.0472e+09 -1.0469e+09  5e+05  9e-04  4e-16\n",
      "35: -1.0471e+09 -1.0469e+09  5e+05  8e-04  4e-16\n",
      "36: -1.0471e+09 -1.0469e+09  4e+05  7e-04  4e-16\n",
      "37: -1.0470e+09 -1.0469e+09  4e+05  7e-04  4e-16\n",
      "38: -1.0470e+09 -1.0469e+09  4e+05  6e-04  4e-16\n",
      "39: -1.0469e+09 -1.0469e+09  3e+05  4e-04  4e-16\n",
      "40: -1.0469e+09 -1.0469e+09  2e+05  3e-04  5e-16\n",
      "41: -1.0468e+09 -1.0468e+09  2e+05  2e-04  4e-16\n",
      "42: -1.0468e+09 -1.0468e+09  1e+05  1e-04  5e-16\n",
      "43: -1.0468e+09 -1.0468e+09  1e+04  9e-06  5e-16\n",
      "44: -1.0468e+09 -1.0468e+09  2e+03  1e-06  5e-16\n",
      "45: -1.0468e+09 -1.0468e+09  7e+02  4e-07  5e-16\n",
      "46: -1.0468e+09 -1.0468e+09  2e+01  5e-16  6e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this will take a couple minutes\n",
    "# the KMM algorithm does not scale well as inputs grow\n",
    "# if we were to use the full train and test set, I don't even know\n",
    "# how long it would take. Instead, we bunch the train into groups (randomly)\n",
    "# and apply KMM to the group and the full test set\n",
    "# we then stitch together the estimated betas for the full train set\n",
    "group_size = 2500\n",
    "rand_inds = np.random.RandomState(seed=RANDOM_SEED).permutation( np.arange(len(x_train_emb)) )\n",
    "betas_ordered = np.zeros(len(x_train_emb))\n",
    "\n",
    "start_i = 0\n",
    "end_i = start_i + group_size\n",
    "while start_i < len(x_train_emb):\n",
    "    print(f\"({start_i}-{end_i})\")\n",
    "    \n",
    "    inds = rand_inds[start_i : end_i]\n",
    "    \n",
    "    kmm = utils.papers.KMM()\n",
    "    betas = kmm.fit(x_train_emb[inds], x_val_emb)\n",
    "    betas_ordered[inds] = betas.reshape(-1) # flatten\n",
    "    \n",
    "    start_i = end_i\n",
    "    end_i = start_i + group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = utils.utils.load_sorted_df(PROCESSED_DIR, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7464014@N04</td>\n",
       "      <td>10218534135_6c73e2982d_o.jpg</td>\n",
       "      <td>961</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10897942@N03</td>\n",
       "      <td>8403758902_a1d5ba65e7_o.jpg</td>\n",
       "      <td>636</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>113445054@N07</td>\n",
       "      <td>11764107793_5ec337a088_o.jpg</td>\n",
       "      <td>1325</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>7398884@N04</td>\n",
       "      <td>8725912445_166a5ba9d1_o.jpg</td>\n",
       "      <td>1649</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>f</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>11008464@N06</td>\n",
       "      <td>11345824903_e6355034f8_o.jpg</td>\n",
       "      <td>970</td>\n",
       "      <td>(0, 2)</td>\n",
       "      <td>f</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                original_image  face_id       age gender  \\\n",
       "0       7464014@N04  10218534135_6c73e2982d_o.jpg      961  (25, 32)      f   \n",
       "100    10897942@N03   8403758902_a1d5ba65e7_o.jpg      636  (25, 32)      f   \n",
       "1000  113445054@N07  11764107793_5ec337a088_o.jpg     1325  (25, 32)      f   \n",
       "1002    7398884@N04   8725912445_166a5ba9d1_o.jpg     1649  (15, 20)      f   \n",
       "1003   11008464@N06  11345824903_e6355034f8_o.jpg      970    (0, 2)      f   \n",
       "\n",
       "          beta  \n",
       "0     0.999999  \n",
       "100   0.999999  \n",
       "1000  1.000000  \n",
       "1002  1.000000  \n",
       "1003  1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['beta'] = betas_ordered\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_paths_to_df_rows(train_paths):\n",
    "    rns = []\n",
    "    for path in train_paths:\n",
    "        int_str = path.split('/')[-1].split('.')[0]\n",
    "        try:\n",
    "            rn = int( int_str )\n",
    "        except:\n",
    "            print(f\"failed to convert {int_str}, path: {path}\")\n",
    "            \n",
    "        rns.append(rn)\n",
    "    return rns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9795 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# see docstring of this function for details\n",
    "kmm_train_ds, kmm_train_paths = utils.custom_tf.image_dataset_from_directory(\n",
    "    directory=os.path.join(PROCESSED_DIR, \"train\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    label_mode='categorical',\n",
    "    follow_links=True,\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "kmm_train_ds = kmm_train_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_nums = train_paths_to_df_rows(kmm_train_paths)\n",
    "\n",
    "# grab the sample weights corresponding to shuffled data\n",
    "sample_weights = train_df.loc[row_nums]['beta'].values.reshape(-1, 1)\n",
    "sample_weights = tf.convert_to_tensor(sample_weights, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fresh model\n",
    "model = utils.utils.make_resnet(\n",
    "    depth=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_with_sample_weight_and_tfds(loss_f, sample_weight, batch_size):\n",
    "    '''\n",
    "    Compute loss of `loss_f` using sample weights and a tf.data.Dataset input.\n",
    "    Keras API does not allow sample weights with tf.data.Dataset.\n",
    "    '''\n",
    "    start_i = 0\n",
    "    end_i = start_i + batch_size\n",
    "    \n",
    "    def loss_inner(y_true, y_pred):\n",
    "        # each time this is called, we are at the next batch so we increment the indices\n",
    "        nonlocal start_i, end_i\n",
    "        \n",
    "        batch_weight = sample_weight[start_i : end_i]\n",
    "        loss = tf.math.reduce_mean( loss_f(y_true, y_pred) * batch_weight )\n",
    "        start_i = end_i\n",
    "        end_i = start_i + batch_size\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    return loss_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_with_sample_weight_and_tfds(\n",
    "    loss_f=ce,\n",
    "    sample_weight=sample_weights,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch > 10:\n",
    "        return 5e-5\n",
    "    else:\n",
    "        return 1e-4\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "KMM_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"kmm\")\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=KMM_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [lr_scheduler, save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.8433 - accuracy: 0.6658\n",
      "Epoch 00001: val_loss improved from inf to 1.11998, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 91s 296ms/step - loss: 0.8434 - accuracy: 0.6657 - val_loss: 1.1200 - val_accuracy: 0.6491\n",
      "Epoch 2/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.7182 - accuracy: 0.7140\n",
      "Epoch 00002: val_loss improved from 1.11998 to 0.76467, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 295ms/step - loss: 0.7183 - accuracy: 0.7138 - val_loss: 0.7647 - val_accuracy: 0.6817\n",
      "Epoch 3/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.6888 - accuracy: 0.7315\n",
      "Epoch 00003: val_loss did not improve from 0.76467\n",
      "307/307 [==============================] - 90s 295ms/step - loss: 0.6888 - accuracy: 0.7315 - val_loss: 0.8216 - val_accuracy: 0.6566\n",
      "Epoch 4/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.6344 - accuracy: 0.7605\n",
      "Epoch 00004: val_loss improved from 0.76467 to 0.72075, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.6344 - accuracy: 0.7605 - val_loss: 0.7208 - val_accuracy: 0.6717\n",
      "Epoch 5/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.6381 - accuracy: 0.7600\n",
      "Epoch 00005: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.6381 - accuracy: 0.7600 - val_loss: 1.0829 - val_accuracy: 0.6316\n",
      "Epoch 6/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.6393 - accuracy: 0.7610\n",
      "Epoch 00006: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.6393 - accuracy: 0.7610 - val_loss: 0.8792 - val_accuracy: 0.6717\n",
      "Epoch 7/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.7766\n",
      "Epoch 00007: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.6038 - accuracy: 0.7766 - val_loss: 1.0211 - val_accuracy: 0.6617\n",
      "Epoch 8/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.5988 - accuracy: 0.7855\n",
      "Epoch 00008: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.5990 - accuracy: 0.7855 - val_loss: 0.7919 - val_accuracy: 0.7243\n",
      "Epoch 9/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.5943 - accuracy: 0.7803\n",
      "Epoch 00009: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.5942 - accuracy: 0.7804 - val_loss: 0.8389 - val_accuracy: 0.7068\n",
      "Epoch 10/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.5584 - accuracy: 0.7991\n",
      "Epoch 00010: val_loss did not improve from 0.72075\n",
      "307/307 [==============================] - 90s 293ms/step - loss: 0.5583 - accuracy: 0.7992 - val_loss: 0.8040 - val_accuracy: 0.7068\n",
      "Epoch 11/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.5224 - accuracy: 0.8138\n",
      "Epoch 00011: val_loss improved from 0.72075 to 0.68409, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.5224 - accuracy: 0.8138 - val_loss: 0.6841 - val_accuracy: 0.7444\n",
      "Epoch 12/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.8344\n",
      "Epoch 00012: val_loss did not improve from 0.68409\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4859 - accuracy: 0.8344 - val_loss: 0.9568 - val_accuracy: 0.6742\n",
      "Epoch 13/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8440\n",
      "Epoch 00013: val_loss improved from 0.68409 to 0.67605, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 295ms/step - loss: 0.4662 - accuracy: 0.8438 - val_loss: 0.6761 - val_accuracy: 0.7569\n",
      "Epoch 14/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8467\n",
      "Epoch 00014: val_loss did not improve from 0.67605\n",
      "307/307 [==============================] - 90s 293ms/step - loss: 0.4604 - accuracy: 0.8468 - val_loss: 0.7069 - val_accuracy: 0.7243\n",
      "Epoch 15/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4559 - accuracy: 0.8541\n",
      "Epoch 00015: val_loss improved from 0.67605 to 0.65866, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4558 - accuracy: 0.8541 - val_loss: 0.6587 - val_accuracy: 0.7318\n",
      "Epoch 16/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4547 - accuracy: 0.8481\n",
      "Epoch 00016: val_loss did not improve from 0.65866\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4547 - accuracy: 0.8482 - val_loss: 0.6689 - val_accuracy: 0.7469\n",
      "Epoch 17/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.8522\n",
      "Epoch 00017: val_loss improved from 0.65866 to 0.65006, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4480 - accuracy: 0.8523 - val_loss: 0.6501 - val_accuracy: 0.7444\n",
      "Epoch 18/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8565\n",
      "Epoch 00018: val_loss did not improve from 0.65006\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4403 - accuracy: 0.8565 - val_loss: 0.6799 - val_accuracy: 0.7444\n",
      "Epoch 19/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4383 - accuracy: 0.8565\n",
      "Epoch 00019: val_loss did not improve from 0.65006\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4384 - accuracy: 0.8565 - val_loss: 0.6537 - val_accuracy: 0.7519\n",
      "Epoch 20/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4428 - accuracy: 0.8555\n",
      "Epoch 00020: val_loss did not improve from 0.65006\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4428 - accuracy: 0.8555 - val_loss: 0.6643 - val_accuracy: 0.7419\n",
      "Epoch 21/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4199 - accuracy: 0.8692\n",
      "Epoch 00021: val_loss did not improve from 0.65006\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4199 - accuracy: 0.8691 - val_loss: 0.6791 - val_accuracy: 0.7419\n",
      "Epoch 22/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8613\n",
      "Epoch 00022: val_loss did not improve from 0.65006\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4272 - accuracy: 0.8613 - val_loss: 0.6715 - val_accuracy: 0.7519\n",
      "Epoch 23/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4156 - accuracy: 0.8748\n",
      "Epoch 00023: val_loss improved from 0.65006 to 0.64963, saving model to ../../../models/adience/rs=55/adience_mt=kmm.h5\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4156 - accuracy: 0.8748 - val_loss: 0.6496 - val_accuracy: 0.7569\n",
      "Epoch 24/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4237 - accuracy: 0.8649\n",
      "Epoch 00024: val_loss did not improve from 0.64963\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4238 - accuracy: 0.8648 - val_loss: 0.6587 - val_accuracy: 0.7569\n",
      "Epoch 25/25\n",
      "306/307 [============================>.] - ETA: 0s - loss: 0.4149 - accuracy: 0.8714\n",
      "Epoch 00025: val_loss did not improve from 0.64963\n",
      "307/307 [==============================] - 90s 294ms/step - loss: 0.4149 - accuracy: 0.8715 - val_loss: 0.6501 - val_accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=kmm_train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=hyper_val_ds,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "model.load_weights(KMM_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7568922305764411"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    hyper_val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7455287103859429"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 4: Just Train on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fresh instance\n",
    "model = utils.utils.make_resnet(\n",
    "    depth=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    input_shape=(*IMAGE_SIZE, 3),\n",
    "    nc=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 256, 256, 16) 448         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256, 256, 16) 64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 256, 256, 16) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 256, 256, 16) 2320        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256, 256, 16) 64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 256, 16) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 256, 256, 16) 2320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256, 256, 16) 0           activation_26[0][0]              \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256, 256, 16) 64          add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 256, 256, 16) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 256, 256, 16) 2320        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 256, 16) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 256, 256, 16) 2320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 256, 256, 16) 0           add_12[0][0]                     \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 16) 64          add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 256, 16) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 32) 4640        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 128, 128, 32) 128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 32) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 32) 544         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 32) 9248        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 128, 128, 32) 0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 128, 32) 128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 32) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 32) 9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128, 128, 32) 128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 32) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 32) 9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 128, 128, 32) 0           add_14[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128, 128, 32) 128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128, 128, 32) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 64)   18496       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 64, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 64, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 64)   2112        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 64, 64, 64)   0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 64, 64)   256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 64, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 64, 64)   36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 64, 64, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 64, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 64, 64, 64)   36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 64, 64, 64)   0           add_16[0][0]                     \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 64, 64, 64)   256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 64, 64, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 57, 57, 64)   0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 207936)       0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            415874      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 591,778\n",
      "Trainable params: 590,850\n",
      "Non-trainable params: 928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch > 10:\n",
    "        return 5e-5\n",
    "    else:\n",
    "        return 1e-4\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "JV_MODEL_SAVEPATH = utils.utils.get_savepath(MODELS_DIR, DATASET, \".h5\", mt=\"jv\")\n",
    "save_best = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=JV_MODEL_SAVEPATH,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "callbacks = [lr_scheduler, save_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9015 - accuracy: 0.5678\n",
      "Epoch 00001: val_loss improved from inf to 2.22663, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 6s 426ms/step - loss: 0.9015 - accuracy: 0.5678 - val_loss: 2.2266 - val_accuracy: 0.5840\n",
      "Epoch 2/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.7035\n",
      "Epoch 00002: val_loss improved from 2.22663 to 1.13196, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 389ms/step - loss: 0.6968 - accuracy: 0.7035 - val_loss: 1.1320 - val_accuracy: 0.6266\n",
      "Epoch 3/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.7387\n",
      "Epoch 00003: val_loss did not improve from 1.13196\n",
      "13/13 [==============================] - 5s 381ms/step - loss: 0.6334 - accuracy: 0.7387 - val_loss: 1.4976 - val_accuracy: 0.6291\n",
      "Epoch 4/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.7889\n",
      "Epoch 00004: val_loss did not improve from 1.13196\n",
      "13/13 [==============================] - 5s 384ms/step - loss: 0.5734 - accuracy: 0.7889 - val_loss: 1.3583 - val_accuracy: 0.6040\n",
      "Epoch 5/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.7839\n",
      "Epoch 00005: val_loss did not improve from 1.13196\n",
      "13/13 [==============================] - 5s 383ms/step - loss: 0.5403 - accuracy: 0.7839 - val_loss: 2.4569 - val_accuracy: 0.5764\n",
      "Epoch 6/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8141\n",
      "Epoch 00006: val_loss improved from 1.13196 to 1.11807, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 385ms/step - loss: 0.5002 - accuracy: 0.8141 - val_loss: 1.1181 - val_accuracy: 0.6090\n",
      "Epoch 7/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8568\n",
      "Epoch 00007: val_loss did not improve from 1.11807\n",
      "13/13 [==============================] - 5s 384ms/step - loss: 0.4394 - accuracy: 0.8568 - val_loss: 1.3784 - val_accuracy: 0.6040\n",
      "Epoch 8/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.8869\n",
      "Epoch 00008: val_loss did not improve from 1.11807\n",
      "13/13 [==============================] - 5s 379ms/step - loss: 0.4021 - accuracy: 0.8869 - val_loss: 1.1994 - val_accuracy: 0.6341\n",
      "Epoch 9/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8995\n",
      "Epoch 00009: val_loss improved from 1.11807 to 1.03408, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 393ms/step - loss: 0.3764 - accuracy: 0.8995 - val_loss: 1.0341 - val_accuracy: 0.5915\n",
      "Epoch 10/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.9196\n",
      "Epoch 00010: val_loss did not improve from 1.03408\n",
      "13/13 [==============================] - 5s 382ms/step - loss: 0.3351 - accuracy: 0.9196 - val_loss: 1.1055 - val_accuracy: 0.6416\n",
      "Epoch 11/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.9171\n",
      "Epoch 00011: val_loss did not improve from 1.03408\n",
      "13/13 [==============================] - 5s 382ms/step - loss: 0.3479 - accuracy: 0.9171 - val_loss: 1.0605 - val_accuracy: 0.5965\n",
      "Epoch 12/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.9322\n",
      "Epoch 00012: val_loss improved from 1.03408 to 0.97201, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 397ms/step - loss: 0.3133 - accuracy: 0.9322 - val_loss: 0.9720 - val_accuracy: 0.6316\n",
      "Epoch 13/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.9523\n",
      "Epoch 00013: val_loss improved from 0.97201 to 0.96512, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 391ms/step - loss: 0.2951 - accuracy: 0.9523 - val_loss: 0.9651 - val_accuracy: 0.6416\n",
      "Epoch 14/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.9648\n",
      "Epoch 00014: val_loss did not improve from 0.96512\n",
      "13/13 [==============================] - 5s 379ms/step - loss: 0.2865 - accuracy: 0.9648 - val_loss: 0.9935 - val_accuracy: 0.6065\n",
      "Epoch 15/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.9422\n",
      "Epoch 00015: val_loss did not improve from 0.96512\n",
      "13/13 [==============================] - 5s 385ms/step - loss: 0.2950 - accuracy: 0.9422 - val_loss: 0.9762 - val_accuracy: 0.6115\n",
      "Epoch 16/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.9623\n",
      "Epoch 00016: val_loss improved from 0.96512 to 0.92338, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 396ms/step - loss: 0.2818 - accuracy: 0.9623 - val_loss: 0.9234 - val_accuracy: 0.6591\n",
      "Epoch 17/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.9673\n",
      "Epoch 00017: val_loss improved from 0.92338 to 0.88616, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 389ms/step - loss: 0.2777 - accuracy: 0.9673 - val_loss: 0.8862 - val_accuracy: 0.6591\n",
      "Epoch 18/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9648\n",
      "Epoch 00018: val_loss improved from 0.88616 to 0.87381, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 392ms/step - loss: 0.2763 - accuracy: 0.9648 - val_loss: 0.8738 - val_accuracy: 0.6692\n",
      "Epoch 19/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9824\n",
      "Epoch 00019: val_loss did not improve from 0.87381\n",
      "13/13 [==============================] - 5s 378ms/step - loss: 0.2543 - accuracy: 0.9824 - val_loss: 0.9694 - val_accuracy: 0.6291\n",
      "Epoch 20/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.9598\n",
      "Epoch 00020: val_loss did not improve from 0.87381\n",
      "13/13 [==============================] - 5s 384ms/step - loss: 0.2660 - accuracy: 0.9598 - val_loss: 0.9181 - val_accuracy: 0.6416\n",
      "Epoch 21/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9749\n",
      "Epoch 00021: val_loss improved from 0.87381 to 0.87275, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 387ms/step - loss: 0.2552 - accuracy: 0.9749 - val_loss: 0.8728 - val_accuracy: 0.6667\n",
      "Epoch 22/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9774\n",
      "Epoch 00022: val_loss improved from 0.87275 to 0.85005, saving model to ../../../models/adience/rs=55/adience_mt=jv.h5\n",
      "13/13 [==============================] - 5s 389ms/step - loss: 0.2521 - accuracy: 0.9774 - val_loss: 0.8500 - val_accuracy: 0.6692\n",
      "Epoch 23/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9774\n",
      "Epoch 00023: val_loss did not improve from 0.85005\n",
      "13/13 [==============================] - 5s 381ms/step - loss: 0.2499 - accuracy: 0.9774 - val_loss: 0.8540 - val_accuracy: 0.6742\n",
      "Epoch 24/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9749\n",
      "Epoch 00024: val_loss did not improve from 0.85005\n",
      "13/13 [==============================] - 5s 384ms/step - loss: 0.2576 - accuracy: 0.9749 - val_loss: 0.8867 - val_accuracy: 0.6391\n",
      "Epoch 25/25\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9724\n",
      "Epoch 00025: val_loss did not improve from 0.85005\n",
      "13/13 [==============================] - 5s 382ms/step - loss: 0.2576 - accuracy: 0.9724 - val_loss: 0.9051 - val_accuracy: 0.6416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f123ed42ed0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=hyper_val_ds,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(JV_MODEL_SAVEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:03<00:00,  3.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6691729323308271"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    hyper_val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7003451521807342"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test acc\n",
    "preds, labels = utils.utils.compute_preds(\n",
    "    model,\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "(np.argmax(preds, axis=1) == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
